
2024-09-19 01:17:15,045 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-19 01:17:24,300 INFO Model and tokenizer initialized successfully.
2024-09-19 01:17:24,301 INFO Starting inference from index 2271 to 2273 on dataset datasetC_test_17000-19999.json
2024-09-19 01:17:24,301 INFO Loading dataset from datasetC_test_17000-19999.json...
2024-09-19 01:17:24,977 INFO Dataset loaded with 3000 conversations.
2024-09-19 01:17:24,979 INFO Loaded dataset datasetC_test_17000-19999.json with 3000 conversations
2024-09-19 01:17:24,981 INFO Selected subset of dataset from index 2271 to 2274
Map: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 130.31 examples/s]
2024-09-19 01:17:25,008 INFO Applied formatting prompts function to dataset
2024-09-19 01:17:25,009 INFO Total conversations to process: 3
2024-09-19 01:17:25,009 INFO Processing conversation 2271/2273
2024-09-19 01:17:25,030 INFO Input sequence length: torch.Size([1, 7885])
2024-09-19 01:19:24,507 INFO User 19273 processed in 119.50s
2024-09-19 01:19:24,511 INFO Processing conversation 2272/2273
2024-09-19 01:19:24,528 INFO Input sequence length: torch.Size([1, 6909])
**************************************************Result Report**************************************************
geobleu: 1.7796813903259925e-281
dtw: 6721.3980247299305
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-19 01:22:44,410 INFO User 19270 processed in 199.90s
2024-09-19 01:22:44,415 INFO Processing conversation 2273/2273
2024-09-19 01:22:44,427 INFO Input sequence length: torch.Size([1, 6573])
geobleu: 0.0
dtw: 10296.82276154366
*****************************************************************************************************************
2024-09-19 01:23:12,475 ERROR Exception in conversation user 19266: The length doesn't match between the generated and reference trajectories.
2024-09-19 01:23:12,475 ERROR Attempt 1/3 failed
2024-09-19 01:23:13,494 INFO Input sequence length: torch.Size([1, 6573])
**************************************************Result Report**************************************************
2024-09-19 01:23:42,310 ERROR Exception in conversation user 19266: The length doesn't match between the generated and reference trajectories.
2024-09-19 01:23:42,311 ERROR Attempt 2/3 failed
2024-09-19 01:23:43,331 INFO Input sequence length: torch.Size([1, 6573])
**************************************************Result Report**************************************************
2024-09-19 01:24:11,534 ERROR Exception in conversation user 19266: The length doesn't match between the generated and reference trajectories.
2024-09-19 01:24:11,535 ERROR Attempt 3/3 failed
2024-09-19 01:24:11,535 ERROR Failed to process conversation user 19266 after 3 attempts
2024-09-19 01:24:11,535 INFO Failed conversations: [19266]
**************************************************Result Report**************************************************
2024-09-19 01:24:12,590 INFO Saving results to generated_datasetC_test_17000-19999_range(2271, 2274).csv.gz
2024-09-19 01:24:12,591 INFO Results saved to generated_datasetC_test_17000-19999_range(2271, 2274).csv.gz