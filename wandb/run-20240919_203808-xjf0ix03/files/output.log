
2024-09-19 20:38:12,509 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-19 20:38:22,055 INFO Model and tokenizer initialized successfully.
2024-09-19 20:38:22,056 INFO Starting inference from index 2236 to 2240 on dataset datasetD_test_3000-5999.json
2024-09-19 20:38:22,056 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-19 20:38:23,271 INFO Dataset loaded with 3000 conversations.
2024-09-19 20:38:23,274 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-19 20:38:23,276 INFO Selected subset of dataset from index 2236 to 2241
Map: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 202.07 examples/s]
2024-09-19 20:38:23,308 INFO Applied formatting prompts function to dataset
2024-09-19 20:38:23,308 INFO Total conversations to process: 5
2024-09-19 20:38:23,309 INFO Processing conversation 2236/2240
2024-09-19 20:38:23,338 INFO Input sequence length: torch.Size([1, 9141])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 9065.881255476053
*****************************************************************************************************************
2024-09-19 20:45:01,453 INFO User 5236 processed in 398.14s
2024-09-19 20:45:01,458 INFO Processing conversation 2237/2240
2024-09-19 20:45:01,483 INFO Input sequence length: torch.Size([1, 9109])
**************************************************Result Report**************************************************
2024-09-19 20:52:01,878 INFO User 5237 processed in 420.42s
2024-09-19 20:52:01,883 INFO Processing conversation 2238/2240
2024-09-19 20:52:01,911 INFO Input sequence length: torch.Size([1, 14877])
geobleu: 0.0
dtw: 8735.860386914934
*****************************************************************************************************************
2024-09-19 21:10:28,834 INFO User 5238 processed in 1106.95s
2024-09-19 21:10:28,839 INFO Processing conversation 2239/2240
2024-09-19 21:10:28,870 INFO Input sequence length: torch.Size([1, 13557])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 16139.663740315305
*****************************************************************************************************************
2024-09-19 21:26:09,231 INFO User 5239 processed in 940.39s
2024-09-19 21:26:09,234 INFO Processing conversation 2240/2240
2024-09-19 21:26:09,275 INFO Input sequence length: torch.Size([1, 16741])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 15032.321445205445
*****************************************************************************************************************
2024-09-19 21:45:10,851 INFO User 5240 processed in 1141.62s
2024-09-19 21:45:10,853 INFO Failed conversations: []
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 15945.914397545728
*****************************************************************************************************************
2024-09-19 21:45:11,470 INFO Saving results to generated_datasetD_test_3000-5999_range(2236, 2241).csv.gz
2024-09-19 21:45:11,474 INFO Results saved to generated_datasetD_test_3000-5999_range(2236, 2241).csv.gz