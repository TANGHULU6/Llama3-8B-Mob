
2024-09-19 20:38:34,771 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-19 20:38:48,451 INFO Model and tokenizer initialized successfully.
2024-09-19 20:38:48,452 INFO Starting inference from index 2241 to 2245 on dataset datasetD_test_3000-5999.json
2024-09-19 20:38:48,452 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-19 20:38:49,634 INFO Dataset loaded with 3000 conversations.
2024-09-19 20:38:49,637 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-19 20:38:49,638 INFO Selected subset of dataset from index 2241 to 2246
Map: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 183.88 examples/s]
2024-09-19 20:38:49,672 INFO Applied formatting prompts function to dataset
2024-09-19 20:38:49,672 INFO Total conversations to process: 5
2024-09-19 20:38:49,672 INFO Processing conversation 2241/2245
2024-09-19 20:38:49,707 INFO Input sequence length: torch.Size([1, 20357])
**************************************************Result Report**************************************************
2024-09-19 21:07:47,434 INFO User 5241 processed in 1737.76s
2024-09-19 21:07:47,439 INFO Processing conversation 2242/2245
2024-09-19 21:07:47,460 INFO Input sequence length: torch.Size([1, 9293])
geobleu: 0.0
dtw: 21074.46184912807
*****************************************************************************************************************
2024-09-19 21:14:37,282 INFO User 5242 processed in 409.84s
2024-09-19 21:14:37,287 INFO Processing conversation 2243/2245
2024-09-19 21:14:37,309 INFO Input sequence length: torch.Size([1, 10517])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 8837.548403603112
*****************************************************************************************************************
2024-09-19 21:22:23,972 INFO User 5243 processed in 466.69s
2024-09-19 21:22:23,976 INFO Processing conversation 2244/2245
2024-09-19 21:22:24,009 INFO Input sequence length: torch.Size([1, 11861])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 9477.523013885539
*****************************************************************************************************************
2024-09-19 21:34:28,490 INFO User 5244 processed in 724.51s
2024-09-19 21:34:28,494 INFO Processing conversation 2245/2245
2024-09-19 21:34:28,536 INFO Input sequence length: torch.Size([1, 15837])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 12454.687246597157
*****************************************************************************************************************
2024-09-19 21:49:42,991 INFO User 5246 processed in 914.50s
2024-09-19 21:49:42,995 INFO Failed conversations: []
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 16893.970454016617
*****************************************************************************************************************
2024-09-19 21:49:43,631 INFO Saving results to generated_datasetD_test_3000-5999_range(2241, 2246).csv.gz
2024-09-19 21:49:43,635 INFO Results saved to generated_datasetD_test_3000-5999_range(2241, 2246).csv.gz