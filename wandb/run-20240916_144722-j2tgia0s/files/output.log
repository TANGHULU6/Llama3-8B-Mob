
2024-09-16 14:47:27,332 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-16 14:47:40,405 INFO Model and tokenizer initialized successfully.
2024-09-16 14:47:40,406 INFO Starting inference from index 0 to 199 on dataset datasetD_test_3000-5999.json
2024-09-16 14:47:40,406 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-16 14:47:41,501 INFO Dataset loaded with 3000 conversations.
2024-09-16 14:47:41,504 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-16 14:47:41,505 INFO Selected subset of dataset from index 0 to 200
Map: 100%|███████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 2345.17 examples/s]
2024-09-16 14:47:41,598 INFO Applied formatting prompts function to dataset
2024-09-16 14:47:41,598 INFO Total conversations to process: 200
2024-09-16 14:47:41,598 INFO Processing conversation 0/199
2024-09-16 14:47:41,626 INFO Input sequence length: torch.Size([1, 15837])
2024-09-16 15:16:27,514 INFO User 3003 processed in 1725.92s
2024-09-16 15:16:27,515 INFO Processing conversation 1/199
2024-09-16 15:16:27,548 INFO Input sequence length: torch.Size([1, 18325])
2024-09-16 15:47:44,412 INFO User 3002 processed in 1876.90s
2024-09-16 15:47:44,413 INFO Processing conversation 2/199
2024-09-16 15:47:44,441 INFO Input sequence length: torch.Size([1, 16109])
2024-09-16 16:22:09,284 INFO User 3004 processed in 2064.87s
2024-09-16 16:22:09,285 INFO Processing conversation 3/199
