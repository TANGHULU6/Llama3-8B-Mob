
2024-09-18 22:39:46,538 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-18 22:40:03,710 INFO Model and tokenizer initialized successfully.
2024-09-18 22:40:03,711 INFO Starting inference from index 2151 to 2160 on dataset datasetC_test_17000-19999.json
2024-09-18 22:40:03,711 INFO Loading dataset from datasetC_test_17000-19999.json...
2024-09-18 22:40:04,380 INFO Dataset loaded with 3000 conversations.
2024-09-18 22:40:04,383 INFO Loaded dataset datasetC_test_17000-19999.json with 3000 conversations
2024-09-18 22:40:04,384 INFO Selected subset of dataset from index 2151 to 2161
Map: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 382.00 examples/s]
2024-09-18 22:40:04,415 INFO Applied formatting prompts function to dataset
2024-09-18 22:40:04,415 INFO Total conversations to process: 10
2024-09-18 22:40:04,415 INFO Processing conversation 2151/2160
2024-09-18 22:40:04,426 INFO Input sequence length: torch.Size([1, 3557])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 3142.8132998884685
*****************************************************************************************************************
2024-09-18 22:42:32,010 INFO User 19150 processed in 147.60s
2024-09-18 22:42:32,015 INFO Processing conversation 2152/2160
2024-09-18 22:42:32,031 INFO Input sequence length: torch.Size([1, 6253])
2024-09-18 22:48:18,427 INFO User 19153 processed in 346.41s
2024-09-18 22:48:18,431 INFO Processing conversation 2153/2160
2024-09-18 22:48:18,455 INFO Input sequence length: torch.Size([1, 8557])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 5043.926698751895
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-18 22:58:26,357 INFO User 19155 processed in 607.93s
2024-09-18 22:58:26,362 INFO Processing conversation 2154/2160
2024-09-18 22:58:26,384 INFO Input sequence length: torch.Size([1, 5277])
geobleu: 0.0
dtw: 6999.224000982667
*****************************************************************************************************************
2024-09-18 23:03:22,993 INFO User 19154 processed in 296.63s
2024-09-18 23:03:22,999 INFO Processing conversation 2155/2160
2024-09-18 23:03:23,026 INFO Input sequence length: torch.Size([1, 4533])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 4143.45062857759
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-18 23:09:59,093 INFO User 19148 processed in 396.09s
2024-09-18 23:09:59,098 INFO Processing conversation 2156/2160
2024-09-18 23:09:59,113 INFO Input sequence length: torch.Size([1, 5461])
geobleu: 6.628127071871001e-281
dtw: 5781.843347929793
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-18 23:15:33,253 INFO User 19156 processed in 334.15s
2024-09-18 23:15:33,258 INFO Processing conversation 2157/2160
2024-09-18 23:15:33,274 INFO Input sequence length: torch.Size([1, 4941])
geobleu: 0.0
dtw: 4681.489967652375
*****************************************************************************************************************
2024-09-18 23:20:03,329 INFO User 19160 processed in 270.07s
2024-09-18 23:20:03,335 INFO Processing conversation 2158/2160
2024-09-18 23:20:03,356 INFO Input sequence length: torch.Size([1, 5229])
**************************************************Result Report**************************************************
geobleu: 1.352689689115741e-273
dtw: 4071.325214226935
*****************************************************************************************************************
2024-09-18 23:21:42,811 INFO User 19158 processed in 99.48s
2024-09-18 23:21:42,814 INFO Processing conversation 2159/2160
2024-09-18 23:21:42,830 INFO Input sequence length: torch.Size([1, 3157])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6904.598149845772
*****************************************************************************************************************
2024-09-18 23:24:56,956 INFO User 19163 processed in 194.14s
2024-09-18 23:24:56,958 INFO Processing conversation 2160/2160
2024-09-18 23:24:56,999 INFO Input sequence length: torch.Size([1, 11717])
**************************************************Result Report**************************************************
geobleu: 1.6444543615289146e-280
dtw: 3351.2785722129447
*****************************************************************************************************************
2024-09-18 23:25:05,117 ERROR Exception in conversation user 19159: CUDA out of memory. Tried to allocate 2.80 GiB. GPU
2024-09-18 23:25:05,118 ERROR Attempt 1/3 failed
2024-09-18 23:25:06,149 INFO Input sequence length: torch.Size([1, 11717])
2024-09-18 23:25:14,282 ERROR Exception in conversation user 19159: CUDA out of memory. Tried to allocate 2.80 GiB. GPU
2024-09-18 23:25:14,283 ERROR Attempt 2/3 failed
2024-09-18 23:25:15,319 INFO Input sequence length: torch.Size([1, 11717])
2024-09-18 23:25:23,492 ERROR Exception in conversation user 19159: CUDA out of memory. Tried to allocate 2.80 GiB. GPU
2024-09-18 23:25:23,493 ERROR Attempt 3/3 failed
2024-09-18 23:25:23,493 ERROR Failed to process conversation user 19159 after 3 attempts
2024-09-18 23:25:23,494 INFO Failed conversations: [19159]
2024-09-18 23:25:24,023 INFO Saving results to generated_datasetC_test_17000-19999_range(2151, 2161).csv.gz
2024-09-18 23:25:24,025 INFO Results saved to generated_datasetC_test_17000-19999_range(2151, 2161).csv.gz