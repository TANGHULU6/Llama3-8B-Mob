
2024-09-14 22:58:15,713 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-14 22:58:24,305 INFO Model and tokenizer initialized successfully.
2024-09-14 22:58:24,306 INFO Starting inference from index 0 to 2999 on dataset datasetA_test_0-9999.json
2024-09-14 22:58:24,306 INFO Loading dataset from datasetA_test_0-9999.json...
Traceback (most recent call last):
  File "/home/geo_llm/llama3-finetune/main.py", line 33, in <module>
    main()
  File "/home/geo_llm/llama3-finetune/main.py", line 29, in main
    run_inference(args.l_idx, args.r_idx, args.city)
  File "/home/geo_llm/llama3-finetune/Infer.py", line 87, in run_inference
    test_dataset = load_custom_dataset(city)
  File "/home/geo_llm/llama3-finetune/Infer.py", line 43, in load_custom_dataset
    with open(file_path, 'r', encoding='utf-8') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'datasetA_test_0-9999.json'