
2024-09-18 17:47:00,205 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-18 17:47:20,441 INFO Model and tokenizer initialized successfully.
2024-09-18 17:47:20,443 INFO Starting inference from index 2836 to 2845 on dataset datasetC_test_17000-19999.json
2024-09-18 17:47:20,443 INFO Loading dataset from datasetC_test_17000-19999.json...
2024-09-18 17:47:21,305 INFO Dataset loaded with 3000 conversations.
2024-09-18 17:47:21,307 INFO Loaded dataset datasetC_test_17000-19999.json with 3000 conversations
2024-09-18 17:47:21,309 INFO Selected subset of dataset from index 2836 to 2846
Map: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 372.05 examples/s]
2024-09-18 17:47:21,342 INFO Applied formatting prompts function to dataset
2024-09-18 17:47:21,342 INFO Total conversations to process: 10
2024-09-18 17:47:21,343 INFO Processing conversation 2836/2845
2024-09-18 17:47:21,356 INFO Input sequence length: torch.Size([1, 5205])
**************************************************Result Report**************************************************
geobleu: 1.4562516441905911e-294
dtw: 5625.621258673613
*****************************************************************************************************************
2024-09-18 17:52:21,111 INFO User 19836 processed in 299.77s
2024-09-18 17:52:21,115 INFO Processing conversation 2837/2845
2024-09-18 17:52:21,129 INFO Input sequence length: torch.Size([1, 3693])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6670.636913950211
*****************************************************************************************************************
2024-09-18 17:56:05,019 INFO User 19840 processed in 223.90s
2024-09-18 17:56:05,023 INFO Processing conversation 2838/2845
2024-09-18 17:56:05,032 INFO Input sequence length: torch.Size([1, 3101])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6414.329362985339
*****************************************************************************************************************
2024-09-18 17:59:30,861 INFO User 19838 processed in 205.84s
2024-09-18 17:59:30,866 INFO Processing conversation 2839/2845
2024-09-18 17:59:30,877 INFO Input sequence length: torch.Size([1, 3685])
**************************************************Result Report**************************************************
2024-09-18 18:01:12,995 ERROR Exception in conversation user 19841: The length doesn't match between the generated and reference trajectories.
2024-09-18 18:01:12,995 ERROR Attempt 1/3 failed
2024-09-18 18:01:14,015 INFO Input sequence length: torch.Size([1, 3685])
**************************************************Result Report**************************************************
2024-09-18 18:02:55,290 ERROR Exception in conversation user 19841: The length doesn't match between the generated and reference trajectories.
2024-09-18 18:02:55,290 ERROR Attempt 2/3 failed
2024-09-18 18:02:56,310 INFO Input sequence length: torch.Size([1, 3685])
**************************************************Result Report**************************************************
2024-09-18 18:04:38,043 ERROR Exception in conversation user 19841: The length doesn't match between the generated and reference trajectories.
2024-09-18 18:04:38,043 ERROR Attempt 3/3 failed
2024-09-18 18:04:38,043 ERROR Failed to process conversation user 19841 after 3 attempts
2024-09-18 18:04:38,044 INFO Processing conversation 2840/2845
2024-09-18 18:04:38,057 INFO Input sequence length: torch.Size([1, 5805])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6384.5084926204845
*****************************************************************************************************************
2024-09-18 18:08:34,627 INFO User 19842 processed in 236.58s
2024-09-18 18:08:34,630 INFO Processing conversation 2841/2845
2024-09-18 18:08:34,652 INFO Input sequence length: torch.Size([1, 7061])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 8477.426519467172
*****************************************************************************************************************
2024-09-18 18:17:19,684 INFO User 19837 processed in 525.05s
2024-09-18 18:17:19,688 INFO Processing conversation 2842/2845
2024-09-18 18:17:19,710 INFO Input sequence length: torch.Size([1, 8061])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 8922.62680140426
*****************************************************************************************************************
2024-09-18 18:23:52,249 INFO User 19843 processed in 392.56s
2024-09-18 18:23:52,254 INFO Processing conversation 2843/2845
2024-09-18 18:23:52,278 INFO Input sequence length: torch.Size([1, 5733])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 9687.360590010509
*****************************************************************************************************************
2024-09-18 18:26:14,587 INFO User 19845 processed in 142.33s
2024-09-18 18:26:14,591 INFO Processing conversation 2844/2845
2024-09-18 18:26:14,605 INFO Input sequence length: torch.Size([1, 3693])
**************************************************Result Report**************************************************
geobleu: 4.61531655059672e-279
dtw: 3442.571259680182
*****************************************************************************************************************
2024-09-18 18:28:43,915 INFO User 19844 processed in 149.32s
2024-09-18 18:28:43,918 INFO Processing conversation 2845/2845
2024-09-18 18:28:43,945 INFO Input sequence length: torch.Size([1, 7205])
2024-09-18 18:36:35,342 INFO User 19839 processed in 471.42s
2024-09-18 18:36:35,345 INFO Failed conversations: [19841]
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 8035.284061781022
*****************************************************************************************************************
2024-09-18 18:36:35,891 INFO Saving results to generated_datasetC_test_17000-19999_range(2836, 2846).csv.gz
2024-09-18 18:36:35,894 INFO Results saved to generated_datasetC_test_17000-19999_range(2836, 2846).csv.gz