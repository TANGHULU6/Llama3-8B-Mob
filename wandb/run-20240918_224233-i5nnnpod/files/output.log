
2024-09-18 22:42:36,705 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-18 22:42:59,078 INFO Model and tokenizer initialized successfully.
2024-09-18 22:42:59,079 INFO Starting inference from index 2164 to 2173 on dataset datasetC_test_17000-19999.json
2024-09-18 22:42:59,079 INFO Loading dataset from datasetC_test_17000-19999.json...
2024-09-18 22:42:59,737 INFO Dataset loaded with 3000 conversations.
2024-09-18 22:42:59,740 INFO Loaded dataset datasetC_test_17000-19999.json with 3000 conversations
2024-09-18 22:42:59,741 INFO Selected subset of dataset from index 2164 to 2174
Map: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 345.65 examples/s]
2024-09-18 22:42:59,774 INFO Applied formatting prompts function to dataset
2024-09-18 22:42:59,774 INFO Total conversations to process: 10
2024-09-18 22:42:59,775 INFO Processing conversation 2164/2173
2024-09-18 22:42:59,789 INFO Input sequence length: torch.Size([1, 7029])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 3701.479993604346
*****************************************************************************************************************
2024-09-18 22:45:41,818 INFO User 19164 processed in 162.04s
2024-09-18 22:45:41,822 INFO Processing conversation 2165/2173
2024-09-18 22:45:41,835 INFO Input sequence length: torch.Size([1, 2661])
2024-09-18 22:48:51,096 INFO User 19161 processed in 189.27s
2024-09-18 22:48:51,101 INFO Processing conversation 2166/2173
2024-09-18 22:48:51,125 INFO Input sequence length: torch.Size([1, 7013])
**************************************************Result Report**************************************************
geobleu: 2.8488180601856685e-283
dtw: 3998.9772862341665
*****************************************************************************************************************
2024-09-18 22:57:55,557 INFO User 19168 processed in 544.46s
2024-09-18 22:57:55,561 INFO Processing conversation 2167/2173
2024-09-18 22:57:55,580 INFO Input sequence length: torch.Size([1, 8301])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 9359.982921693874
*****************************************************************************************************************
2024-09-18 22:58:01,231 ERROR Exception in conversation user 19166: CUDA out of memory. Tried to allocate 1.98 GiB. GPU
2024-09-18 22:58:01,232 ERROR Attempt 1/3 failed
2024-09-18 22:58:02,259 INFO Input sequence length: torch.Size([1, 8301])
2024-09-18 22:58:07,920 ERROR Exception in conversation user 19166: CUDA out of memory. Tried to allocate 1.98 GiB. GPU
2024-09-18 22:58:07,921 ERROR Attempt 2/3 failed
2024-09-18 22:58:08,943 INFO Input sequence length: torch.Size([1, 8301])
2024-09-18 22:58:14,646 ERROR Exception in conversation user 19166: CUDA out of memory. Tried to allocate 1.98 GiB. GPU
2024-09-18 22:58:14,647 ERROR Attempt 3/3 failed
2024-09-18 22:58:14,647 ERROR Failed to process conversation user 19166 after 3 attempts
2024-09-18 22:58:14,648 INFO Processing conversation 2168/2173
2024-09-18 22:58:14,662 INFO Input sequence length: torch.Size([1, 6885])
2024-09-18 23:07:18,187 INFO User 19173 processed in 543.54s
2024-09-18 23:07:18,191 INFO Processing conversation 2169/2173
2024-09-18 23:07:18,207 INFO Input sequence length: torch.Size([1, 5029])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6995.5169782651765
*****************************************************************************************************************
2024-09-18 23:11:44,139 INFO User 19170 processed in 265.95s
2024-09-18 23:11:44,143 INFO Processing conversation 2170/2173
2024-09-18 23:11:44,157 INFO Input sequence length: torch.Size([1, 4765])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 3871.4384614733003
*****************************************************************************************************************
2024-09-18 23:18:10,745 INFO User 19175 processed in 386.60s
2024-09-18 23:18:10,749 INFO Processing conversation 2171/2173
2024-09-18 23:18:10,772 INFO Input sequence length: torch.Size([1, 7509])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6750.820412499216
*****************************************************************************************************************
2024-09-18 23:29:43,779 INFO User 19172 processed in 693.03s
2024-09-18 23:29:43,782 INFO Processing conversation 2172/2173
2024-09-18 23:29:43,798 INFO Input sequence length: torch.Size([1, 5413])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 10182.169794134543
*****************************************************************************************************************
2024-09-18 23:34:47,000 INFO User 19167 processed in 303.22s
2024-09-18 23:34:47,005 INFO Processing conversation 2173/2173
2024-09-18 23:34:47,018 INFO Input sequence length: torch.Size([1, 4877])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6368.21857344508
*****************************************************************************************************************
2024-09-18 23:36:06,133 ERROR Exception in conversation user 19169: The length doesn't match between the generated and reference trajectories.
2024-09-18 23:36:06,133 ERROR Attempt 1/3 failed
**************************************************Result Report**************************************************
2024-09-18 23:36:07,153 INFO Input sequence length: torch.Size([1, 4877])
2024-09-18 23:37:27,649 ERROR Exception in conversation user 19169: The length doesn't match between the generated and reference trajectories.
2024-09-18 23:37:27,649 ERROR Attempt 2/3 failed
**************************************************Result Report**************************************************
2024-09-18 23:37:28,666 INFO Input sequence length: torch.Size([1, 4877])
2024-09-18 23:38:47,965 ERROR Exception in conversation user 19169: The length doesn't match between the generated and reference trajectories.
2024-09-18 23:38:47,965 ERROR Attempt 3/3 failed
2024-09-18 23:38:47,965 ERROR Failed to process conversation user 19169 after 3 attempts
2024-09-18 23:38:47,966 INFO Failed conversations: [19166, 19169]
**************************************************Result Report**************************************************
2024-09-18 23:38:48,519 INFO Saving results to generated_datasetC_test_17000-19999_range(2164, 2174).csv.gz
2024-09-18 23:38:48,524 INFO Results saved to generated_datasetC_test_17000-19999_range(2164, 2174).csv.gz