

  0%|▎                                                                                | 1/250 [00:50<3:28:50, 50.32s/it]
{'loss': 0.3181, 'grad_norm': 0.06905952095985413, 'learning_rate': 4e-05, 'epoch': 0.0}

  1%|▋                                                                                | 2/250 [01:45<3:40:34, 53.36s/it]


  2%|█▎                                                                               | 4/250 [03:14<3:11:01, 46.59s/it]

  2%|█▌                                                                               | 5/250 [03:56<3:03:34, 44.96s/it]

  2%|█▉                                                                               | 6/250 [04:48<3:12:25, 47.32s/it]
{'loss': 0.3094, 'grad_norm': 0.07591665536165237, 'learning_rate': 0.00019918367346938775, 'epoch': 0.02}

  3%|██▎                                                                              | 7/250 [05:39<3:16:09, 48.43s/it]

  3%|██▌                                                                              | 8/250 [06:21<3:06:59, 46.36s/it]

  4%|██▉                                                                              | 9/250 [06:54<2:49:19, 42.16s/it]

  4%|███▏                                                                            | 10/250 [07:35<2:47:53, 41.97s/it]

  4%|███▌                                                                            | 11/250 [08:12<2:40:40, 40.34s/it]

  5%|███▊                                                                            | 12/250 [08:50<2:36:37, 39.49s/it]


  6%|████▍                                                                           | 14/250 [10:15<2:41:10, 40.98s/it]
{'loss': 0.3469, 'grad_norm': 0.07897509634494781, 'learning_rate': 0.0001926530612244898, 'epoch': 0.06}

  6%|████▊                                                                           | 15/250 [10:58<2:42:55, 41.60s/it]


  7%|█████▍                                                                          | 17/250 [12:25<2:45:59, 42.74s/it]
{'loss': 0.3357, 'grad_norm': 0.06302725523710251, 'learning_rate': 0.00019020408163265305, 'epoch': 0.07}

  7%|█████▊                                                                          | 18/250 [13:08<2:45:45, 42.87s/it]

  8%|██████                                                                          | 19/250 [13:59<2:53:45, 45.13s/it]

  8%|██████▍                                                                         | 20/250 [14:48<2:57:58, 46.43s/it]


  9%|███████                                                                         | 22/250 [16:03<2:38:20, 41.67s/it]
{'loss': 0.3416, 'grad_norm': 0.07737541198730469, 'learning_rate': 0.00018612244897959183, 'epoch': 0.09}

  9%|███████▎                                                                        | 23/250 [16:40<2:31:53, 40.15s/it]

 10%|███████▋                                                                        | 24/250 [17:27<2:38:38, 42.12s/it]

 10%|████████                                                                        | 25/250 [18:12<2:41:11, 42.98s/it]


 11%|████████▋                                                                       | 27/250 [19:25<2:27:22, 39.65s/it]
{'loss': 0.4321, 'grad_norm': 0.09244256466627121, 'learning_rate': 0.00018204081632653064, 'epoch': 0.11}

 11%|████████▉                                                                       | 28/250 [20:05<2:26:20, 39.55s/it]

 12%|█████████▎                                                                      | 29/250 [21:03<2:46:35, 45.23s/it]

 12%|█████████▌                                                                      | 30/250 [21:40<2:37:02, 42.83s/it]

 12%|█████████▉                                                                      | 31/250 [22:18<2:30:57, 41.36s/it]

 13%|██████████▏                                                                     | 32/250 [23:18<2:50:50, 47.02s/it]

 13%|██████████▌                                                                     | 33/250 [23:48<2:31:32, 41.90s/it]


 14%|███████████▏                                                                    | 35/250 [25:24<2:41:46, 45.15s/it]
{'loss': 0.3905, 'grad_norm': 0.06719573587179184, 'learning_rate': 0.00017551020408163265, 'epoch': 0.14}

 14%|███████████▌                                                                    | 36/250 [26:17<2:50:02, 47.68s/it]

 15%|███████████▊                                                                    | 37/250 [27:19<3:04:18, 51.92s/it]

 15%|████████████▏                                                                   | 38/250 [27:57<2:48:52, 47.79s/it]


 16%|████████████▊                                                                   | 40/250 [29:20<2:34:55, 44.26s/it]
{'loss': 0.3324, 'grad_norm': 0.06936255842447281, 'learning_rate': 0.00017142857142857143, 'epoch': 0.16}

 16%|█████████████                                                                   | 41/250 [30:02<2:31:33, 43.51s/it]

 17%|█████████████▍                                                                  | 42/250 [30:39<2:24:43, 41.75s/it]

 17%|█████████████▊                                                                  | 43/250 [31:25<2:27:40, 42.80s/it]

 18%|██████████████                                                                  | 44/250 [32:10<2:29:22, 43.51s/it]

 18%|██████████████▍                                                                 | 45/250 [32:47<2:22:18, 41.65s/it]


 19%|███████████████                                                                 | 47/250 [34:15<2:24:22, 42.67s/it]

 19%|███████████████▎                                                                | 48/250 [35:09<2:35:05, 46.07s/it]
{'loss': 0.3962, 'grad_norm': 0.06643988192081451, 'learning_rate': 0.0001648979591836735, 'epoch': 0.19}


 20%|████████████████                                                                | 50/250 [36:21<2:16:01, 40.81s/it]
 20%|████████████████                                                                | 50/250 [36:21<2:16:01, 40.81s/it]Traceback (most recent call last):
  File "/home/geo_llm/llama3-finetune/HuMob_wandb.py", line 162, in <module>
    trainer_stats = trainer.train()
  File "<string>", line 126, in train
  File "<string>", line 435, in _fast_inner_training_loop
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/trainer.py", line 2793, in _maybe_log_save_evaluate
    metrics = self._evaluate(trial, ignore_keys_for_eval)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/trainer.py", line 2750, in _evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/trainer.py", line 3641, in evaluate
    output = eval_loop(
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/trainer.py", line 3826, in evaluation_loop
    losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/trainer.py", line 4040, in prediction_step
    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/trainer.py", line 3338, in compute_loss
    outputs = model(**inputs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 16, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py", line 940, in PeftModelForCausalLM_fast_forward
    return self.base_model(
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 179, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/accelerate/hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py", line 859, in _CausalLM_fast_forward
    outputs = self.model(
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/accelerate/hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py", line 726, in LlamaModel_fast_forward
    layer_outputs = decoder_layer(
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/accelerate/hooks.py", line 169, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py", line 469, in LlamaDecoderLayer_fast_forward
    hidden_states = self.mlp(hidden_states)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/kernels/fast_lora.py", line 158, in apply_lora_mlp_swiglu
    out = LoRA_MLP.apply(X,
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/autograd/function.py", line 598, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/cuda/amp/autocast_mode.py", line 115, in decorate_fwd
    return fwd(*args, **kwargs)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/kernels/fast_lora.py", line 75, in forward
    i = matmul_lora(h, downW, downW_quant, downA, downB, downS)
  File "/home/geo_llm/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/kernels/utils.py", line 262, in matmul_lora
    out += (X @ A.to(dtype)) @ (s * B.to(dtype))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB. GPU