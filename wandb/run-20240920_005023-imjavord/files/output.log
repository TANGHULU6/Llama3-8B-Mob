
2024-09-20 00:50:27,717 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-20 00:50:41,179 INFO Model and tokenizer initialized successfully.
2024-09-20 00:50:41,180 INFO Starting inference from index 751 to 755 on dataset datasetD_test_3000-5999.json
2024-09-20 00:50:41,180 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-20 00:50:42,325 INFO Dataset loaded with 3000 conversations.
2024-09-20 00:50:42,328 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-20 00:50:42,329 INFO Selected subset of dataset from index 751 to 756
Map: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 195.68 examples/s]
2024-09-20 00:50:42,362 INFO Applied formatting prompts function to dataset
2024-09-20 00:50:42,363 INFO Total conversations to process: 5
2024-09-20 00:50:42,363 INFO Processing conversation 751/755
2024-09-20 00:50:42,394 INFO Input sequence length: torch.Size([1, 12477])
2024-09-20 01:02:20,299 INFO User 3751 processed in 697.94s
2024-09-20 01:02:20,303 INFO Processing conversation 752/755
2024-09-20 01:02:20,329 INFO Input sequence length: torch.Size([1, 9765])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 11755.80400458875
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-20 01:08:47,406 INFO User 3752 processed in 387.10s
2024-09-20 01:08:47,411 INFO Processing conversation 753/755
2024-09-20 01:08:47,446 INFO Input sequence length: torch.Size([1, 11277])
geobleu: 5.630201087434548e-280
dtw: 7908.344575517278
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-20 01:20:02,215 INFO User 3753 processed in 674.80s
2024-09-20 01:20:02,219 INFO Processing conversation 754/755
2024-09-20 01:20:02,237 INFO Input sequence length: torch.Size([1, 5245])
geobleu: 0.0
dtw: 11618.321838017988
*****************************************************************************************************************
2024-09-20 01:22:57,564 INFO User 3754 processed in 175.34s
2024-09-20 01:22:57,569 INFO Processing conversation 755/755
2024-09-20 01:22:57,603 INFO Input sequence length: torch.Size([1, 15773])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 5409.911333018535
*****************************************************************************************************************
2024-09-20 01:45:36,664 INFO User 3755 processed in 1359.09s
2024-09-20 01:45:36,666 INFO Failed conversations: []
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 18316.888510340086
*****************************************************************************************************************
2024-09-20 01:45:37,323 INFO Saving results to generated_datasetD_test_3000-5999_range(751, 756).csv.gz
2024-09-20 01:45:37,326 INFO Results saved to generated_datasetD_test_3000-5999_range(751, 756).csv.gz