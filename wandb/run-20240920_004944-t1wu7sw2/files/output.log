
2024-09-20 00:49:49,627 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-20 00:50:01,890 INFO Model and tokenizer initialized successfully.
2024-09-20 00:50:01,891 INFO Starting inference from index 701 to 705 on dataset datasetD_test_3000-5999.json
2024-09-20 00:50:01,892 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-20 00:50:03,071 INFO Dataset loaded with 3000 conversations.
2024-09-20 00:50:03,074 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-20 00:50:03,075 INFO Selected subset of dataset from index 701 to 706
Map: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 204.71 examples/s]
2024-09-20 00:50:03,109 INFO Applied formatting prompts function to dataset
2024-09-20 00:50:03,109 INFO Total conversations to process: 5
2024-09-20 00:50:03,110 INFO Processing conversation 701/705
2024-09-20 00:50:03,133 INFO Input sequence length: torch.Size([1, 7885])
2024-09-20 00:55:41,944 INFO User 3701 processed in 338.83s
2024-09-20 00:55:41,949 INFO Processing conversation 702/705
2024-09-20 00:55:41,977 INFO Input sequence length: torch.Size([1, 11085])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 8438.812409599292
*****************************************************************************************************************
2024-09-20 01:05:22,687 INFO User 3702 processed in 580.74s
2024-09-20 01:05:22,690 INFO Processing conversation 703/705
2024-09-20 01:05:22,724 INFO Input sequence length: torch.Size([1, 10997])
**************************************************Result Report**************************************************
geobleu: 1.1741767623990935e-288
dtw: 10963.503932947688
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-20 01:21:06,358 INFO User 3703 processed in 943.67s
2024-09-20 01:21:06,363 INFO Processing conversation 704/705
2024-09-20 01:21:06,387 INFO Input sequence length: torch.Size([1, 13941])
geobleu: 0.0
dtw: 11645.748336067925
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-20 01:40:55,886 INFO User 3704 processed in 1189.52s
2024-09-20 01:40:55,891 INFO Processing conversation 705/705
2024-09-20 01:40:55,914 INFO Input sequence length: torch.Size([1, 12341])
geobleu: 0.0
dtw: 14154.455323612272
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-20 01:52:00,520 INFO User 3705 processed in 664.63s
2024-09-20 01:52:00,523 INFO Failed conversations: []
geobleu: 0.0
dtw: 11504.138309443417
*****************************************************************************************************************
2024-09-20 01:52:01,162 INFO Saving results to generated_datasetD_test_3000-5999_range(701, 706).csv.gz
2024-09-20 01:52:01,168 INFO Results saved to generated_datasetD_test_3000-5999_range(701, 706).csv.gz