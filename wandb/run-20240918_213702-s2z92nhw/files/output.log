
2024-09-18 21:37:06,732 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-18 21:37:26,226 INFO Model and tokenizer initialized successfully.
2024-09-18 21:37:26,227 INFO Starting inference from index 2478 to 2487 on dataset datasetC_test_17000-19999.json
2024-09-18 21:37:26,227 INFO Loading dataset from datasetC_test_17000-19999.json...
2024-09-18 21:37:26,851 INFO Dataset loaded with 3000 conversations.
2024-09-18 21:37:26,853 INFO Loaded dataset datasetC_test_17000-19999.json with 3000 conversations
2024-09-18 21:37:26,855 INFO Selected subset of dataset from index 2478 to 2488
Map: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 409.79 examples/s]
2024-09-18 21:37:26,884 INFO Applied formatting prompts function to dataset
2024-09-18 21:37:26,884 INFO Total conversations to process: 10
2024-09-18 21:37:26,884 INFO Processing conversation 2478/2487
2024-09-18 21:37:26,901 INFO Input sequence length: torch.Size([1, 7781])
2024-09-18 21:43:24,334 INFO User 19478 processed in 357.45s
2024-09-18 21:43:24,338 INFO Processing conversation 2479/2487
2024-09-18 21:43:24,350 INFO Input sequence length: torch.Size([1, 3773])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 8212.296092988814
*****************************************************************************************************************
2024-09-18 21:47:30,499 INFO User 19483 processed in 246.16s
2024-09-18 21:47:30,504 INFO Processing conversation 2480/2487
2024-09-18 21:47:30,522 INFO Input sequence length: torch.Size([1, 8941])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 7418.064840878048
*****************************************************************************************************************
2024-09-18 21:59:12,988 INFO User 19482 processed in 702.48s
2024-09-18 21:59:12,991 INFO Processing conversation 2481/2487
2024-09-18 21:59:13,019 INFO Input sequence length: torch.Size([1, 10981])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 11253.577050008353
*****************************************************************************************************************
2024-09-18 22:14:21,260 INFO User 19480 processed in 908.27s
2024-09-18 22:14:21,264 INFO Processing conversation 2482/2487
2024-09-18 22:14:21,275 INFO Input sequence length: torch.Size([1, 5773])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 11790.552166971751
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-18 22:20:14,043 INFO User 19479 processed in 352.78s
2024-09-18 22:20:14,048 INFO Processing conversation 2483/2487
2024-09-18 22:20:14,067 INFO Input sequence length: torch.Size([1, 5469])
geobleu: 0.0
dtw: 7097.76108950334
*****************************************************************************************************************
2024-09-18 22:23:26,876 INFO User 19481 processed in 192.83s
2024-09-18 22:23:26,878 INFO Processing conversation 2484/2487
2024-09-18 22:23:26,897 INFO Input sequence length: torch.Size([1, 7429])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6306.45206577767
