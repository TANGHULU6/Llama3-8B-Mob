
2024-09-19 20:39:38,251 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-19 20:39:57,561 INFO Model and tokenizer initialized successfully.
2024-09-19 20:39:57,562 INFO Starting inference from index 1793 to 1797 on dataset datasetD_test_3000-5999.json
2024-09-19 20:39:57,563 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-19 20:39:58,760 INFO Dataset loaded with 3000 conversations.
2024-09-19 20:39:58,762 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-19 20:39:58,764 INFO Selected subset of dataset from index 1793 to 1798
Map: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 179.10 examples/s]
2024-09-19 20:39:58,799 INFO Applied formatting prompts function to dataset
2024-09-19 20:39:58,799 INFO Total conversations to process: 5
2024-09-19 20:39:58,800 INFO Processing conversation 1793/1797
2024-09-19 20:39:58,825 INFO Input sequence length: torch.Size([1, 14405])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 15359.80657439775
*****************************************************************************************************************
2024-09-19 20:53:38,323 INFO User 4793 processed in 819.52s
2024-09-19 20:53:38,328 INFO Processing conversation 1794/1797
2024-09-19 20:53:38,354 INFO Input sequence length: torch.Size([1, 12733])
2024-09-19 21:15:10,558 INFO User 4794 processed in 1292.23s
2024-09-19 21:15:10,563 INFO Processing conversation 1795/1797
2024-09-19 21:15:10,589 INFO Input sequence length: torch.Size([1, 9693])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 13531.110282821386
*****************************************************************************************************************
2024-09-19 21:38:09,851 INFO User 4795 processed in 1379.29s
2024-09-19 21:38:09,854 INFO Processing conversation 1796/1797
2024-09-19 21:38:09,897 INFO Input sequence length: torch.Size([1, 21557])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 16388.38706153197
*****************************************************************************************************************
2024-09-19 22:17:40,819 INFO User 4796 processed in 2370.97s
2024-09-19 22:17:40,825 INFO Processing conversation 1797/1797
2024-09-19 22:17:40,846 INFO Input sequence length: torch.Size([1, 11549])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 20685.232798646914
*****************************************************************************************************************
2024-09-19 22:29:57,472 INFO User 4797 processed in 736.65s
2024-09-19 22:29:57,473 INFO Failed conversations: []
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 12790.98035518319
*****************************************************************************************************************
2024-09-19 22:29:58,090 INFO Saving results to generated_datasetD_test_3000-5999_range(1793, 1798).csv.gz
2024-09-19 22:29:58,097 INFO Results saved to generated_datasetD_test_3000-5999_range(1793, 1798).csv.gz