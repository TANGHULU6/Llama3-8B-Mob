
2024-09-19 20:40:10,646 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-19 20:40:32,067 INFO Model and tokenizer initialized successfully.
2024-09-19 20:40:32,068 INFO Starting inference from index 1798 to 1802 on dataset datasetD_test_3000-5999.json
2024-09-19 20:40:32,068 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-19 20:40:33,261 INFO Dataset loaded with 3000 conversations.
2024-09-19 20:40:33,264 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-19 20:40:33,266 INFO Selected subset of dataset from index 1798 to 1803
Map: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 175.72 examples/s]
2024-09-19 20:40:33,300 INFO Applied formatting prompts function to dataset
2024-09-19 20:40:33,301 INFO Total conversations to process: 5
2024-09-19 20:40:33,301 INFO Processing conversation 1798/1802
2024-09-19 20:40:33,319 INFO Input sequence length: torch.Size([1, 8597])
2024-09-19 20:56:35,225 INFO User 4798 processed in 961.92s
2024-09-19 20:56:35,231 INFO Processing conversation 1799/1802
2024-09-19 20:56:35,269 INFO Input sequence length: torch.Size([1, 13973])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 14314.964407390416
*****************************************************************************************************************
2024-09-19 21:18:28,740 INFO User 4800 processed in 1313.51s
2024-09-19 21:18:28,745 INFO Processing conversation 1800/1802
2024-09-19 21:18:28,779 INFO Input sequence length: torch.Size([1, 16285])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 12272.872766397302
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-19 21:43:01,675 INFO User 4799 processed in 1472.93s
2024-09-19 21:43:01,678 INFO Processing conversation 1801/1802
2024-09-19 21:43:01,711 INFO Input sequence length: torch.Size([1, 12621])
geobleu: 0.0
dtw: 15673.711625399314
*****************************************************************************************************************
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 13384.293597724482
*****************************************************************************************************************
2024-09-19 21:56:26,468 INFO User 4801 processed in 804.79s
2024-09-19 21:56:26,472 INFO Processing conversation 1802/1802
2024-09-19 21:56:26,499 INFO Input sequence length: torch.Size([1, 14957])
**************************************************Result Report**************************************************
2024-09-19 22:13:54,056 INFO User 4802 processed in 1047.58s
2024-09-19 22:13:54,060 INFO Failed conversations: []
geobleu: 0.0
dtw: 15719.331177006241
*****************************************************************************************************************
2024-09-19 22:13:54,672 INFO Saving results to generated_datasetD_test_3000-5999_range(1798, 1803).csv.gz
2024-09-19 22:13:54,677 INFO Results saved to generated_datasetD_test_3000-5999_range(1798, 1803).csv.gz