
2024-09-16 15:07:22,141 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-16 15:07:42,033 INFO Model and tokenizer initialized successfully.
2024-09-16 15:07:42,034 INFO Starting inference from index 1200 to 1399 on dataset datasetD_test_3000-5999.json
2024-09-16 15:07:42,035 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-16 15:07:43,610 INFO Dataset loaded with 3000 conversations.
2024-09-16 15:07:43,614 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-16 15:07:43,616 INFO Selected subset of dataset from index 1200 to 1400
Map: 100%|███████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 1957.00 examples/s]
2024-09-16 15:07:43,728 INFO Applied formatting prompts function to dataset
2024-09-16 15:07:43,728 INFO Total conversations to process: 200
2024-09-16 15:07:43,729 INFO Processing conversation 1200/1399
2024-09-16 15:07:43,753 INFO Input sequence length: torch.Size([1, 8077])
2024-09-16 15:19:16,482 INFO User 4200 processed in 692.75s
2024-09-16 15:19:16,484 INFO Processing conversation 1201/1399
2024-09-16 15:19:16,517 INFO Input sequence length: torch.Size([1, 15805])
2024-09-16 15:36:54,638 INFO User 4201 processed in 1058.15s
2024-09-16 15:36:54,641 INFO Processing conversation 1202/1399
2024-09-16 15:36:54,657 INFO Input sequence length: torch.Size([1, 8277])
2024-09-16 15:45:14,409 INFO User 4202 processed in 499.77s
2024-09-16 15:45:14,411 INFO Processing conversation 1203/1399
2024-09-16 15:45:14,442 INFO Input sequence length: torch.Size([1, 17269])
2024-09-16 16:16:21,081 INFO User 4203 processed in 1866.67s
2024-09-16 16:16:21,083 INFO Processing conversation 1204/1399
2024-09-16 16:16:21,099 INFO Input sequence length: torch.Size([1, 9309])
2024-09-16 16:24:32,713 INFO User 4204 processed in 491.63s
2024-09-16 16:24:32,715 INFO Processing conversation 1205/1399
2024-09-16 16:24:32,745 INFO Input sequence length: torch.Size([1, 17293])
2024-09-16 16:45:35,555 INFO User 4206 processed in 1262.84s
2024-09-16 16:45:35,557 INFO Processing conversation 1206/1399
2024-09-16 16:45:35,580 INFO Input sequence length: torch.Size([1, 13349])
2024-09-16 17:08:34,274 INFO User 4205 processed in 1378.72s
2024-09-16 17:08:34,275 INFO Processing conversation 1207/1399
2024-09-16 17:08:34,295 INFO Input sequence length: torch.Size([1, 11589])
2024-09-16 17:23:40,680 INFO User 4207 processed in 906.40s
2024-09-16 17:23:40,681 INFO Processing conversation 1208/1399
2024-09-16 17:23:40,706 INFO Input sequence length: torch.Size([1, 14485])
2024-09-16 17:41:35,370 INFO User 4208 processed in 1074.69s
2024-09-16 17:41:35,372 INFO Processing conversation 1209/1399
2024-09-16 17:41:35,391 INFO Input sequence length: torch.Size([1, 11653])
2024-09-16 17:48:36,417 INFO User 4209 processed in 421.05s
2024-09-16 17:48:36,419 INFO Processing conversation 1210/1399
2024-09-16 17:48:36,454 INFO Input sequence length: torch.Size([1, 14509])
2024-09-16 18:14:57,224 INFO User 4210 processed in 1580.80s
2024-09-16 18:14:57,225 INFO Processing conversation 1211/1399
2024-09-16 18:14:57,250 INFO Input sequence length: torch.Size([1, 13861])
2024-09-16 18:39:05,965 INFO User 4211 processed in 1448.74s
2024-09-16 18:39:05,967 INFO Processing conversation 1212/1399
2024-09-16 18:39:05,983 INFO Input sequence length: torch.Size([1, 7917])
2024-09-16 18:46:54,275 INFO User 4212 processed in 468.31s
2024-09-16 18:46:54,277 INFO Processing conversation 1213/1399
2024-09-16 18:46:54,287 INFO Input sequence length: torch.Size([1, 4917])
2024-09-16 18:50:37,630 INFO User 4213 processed in 223.35s
2024-09-16 18:50:37,632 INFO Processing conversation 1214/1399
2024-09-16 18:50:37,651 INFO Input sequence length: torch.Size([1, 10773])
2024-09-16 19:05:54,659 INFO User 4215 processed in 917.03s
2024-09-16 19:05:54,662 INFO Processing conversation 1215/1399
2024-09-16 19:05:54,700 INFO Input sequence length: torch.Size([1, 16789])
2024-09-16 19:29:02,911 INFO User 4214 processed in 1388.25s
2024-09-16 19:29:02,913 INFO Processing conversation 1216/1399
2024-09-16 19:29:02,933 INFO Input sequence length: torch.Size([1, 11957])
2024-09-16 19:42:16,250 INFO User 4216 processed in 793.34s
2024-09-16 19:42:16,252 INFO Processing conversation 1217/1399
2024-09-16 19:42:16,279 INFO Input sequence length: torch.Size([1, 10717])
2024-09-16 19:53:44,862 INFO User 4217 processed in 688.61s
2024-09-16 19:53:44,864 INFO Processing conversation 1218/1399
2024-09-16 19:53:44,885 INFO Input sequence length: torch.Size([1, 12701])
2024-09-16 20:11:26,178 INFO User 4218 processed in 1061.31s
2024-09-16 20:11:26,180 INFO Processing conversation 1219/1399
2024-09-16 20:11:26,191 INFO Input sequence length: torch.Size([1, 4613])
2024-09-16 20:19:27,790 INFO User 4221 processed in 481.61s
2024-09-16 20:19:27,792 INFO Processing conversation 1220/1399
2024-09-16 20:19:27,810 INFO Input sequence length: torch.Size([1, 10053])
2024-09-16 20:29:59,596 INFO User 4219 processed in 631.80s
2024-09-16 20:29:59,598 INFO Processing conversation 1221/1399
2024-09-16 20:29:59,616 INFO Input sequence length: torch.Size([1, 8133])
2024-09-16 20:35:58,730 INFO User 4220 processed in 359.13s
2024-09-16 20:35:58,732 INFO Processing conversation 1222/1399
2024-09-16 20:35:58,752 INFO Input sequence length: torch.Size([1, 12229])
2024-09-16 20:51:26,388 INFO User 4222 processed in 927.66s
2024-09-16 20:51:26,389 INFO Processing conversation 1223/1399
2024-09-16 20:51:26,411 INFO Input sequence length: torch.Size([1, 12557])
2024-09-16 21:13:43,378 INFO User 4224 processed in 1336.99s
2024-09-16 21:13:43,379 INFO Processing conversation 1224/1399
2024-09-16 21:13:43,404 INFO Input sequence length: torch.Size([1, 13677])
2024-09-16 21:34:01,256 INFO User 4223 processed in 1217.88s
2024-09-16 21:34:01,257 INFO Processing conversation 1225/1399
2024-09-16 21:34:01,282 INFO Input sequence length: torch.Size([1, 14245])
2024-09-16 21:54:49,258 INFO User 4226 processed in 1248.00s
2024-09-16 21:54:49,260 INFO Processing conversation 1226/1399
2024-09-16 21:54:49,266 INFO Input sequence length: torch.Size([1, 2117])
2024-09-16 21:55:48,683 INFO User 4225 processed in 59.42s
2024-09-16 21:55:48,685 INFO Processing conversation 1227/1399
2024-09-16 21:55:48,708 INFO Input sequence length: torch.Size([1, 11829])
2024-09-16 22:13:36,351 INFO User 4227 processed in 1067.67s
2024-09-16 22:13:36,353 INFO Processing conversation 1228/1399
2024-09-16 22:13:36,363 INFO Input sequence length: torch.Size([1, 4221])
2024-09-16 22:18:48,975 INFO User 4229 processed in 312.62s
2024-09-16 22:18:48,976 INFO Processing conversation 1229/1399
2024-09-16 22:18:48,989 INFO Input sequence length: torch.Size([1, 6325])
2024-09-16 22:21:24,096 INFO User 4228 processed in 155.12s
2024-09-16 22:21:24,098 INFO Processing conversation 1230/1399
2024-09-16 22:21:24,117 INFO Input sequence length: torch.Size([1, 11061])
2024-09-16 22:42:34,974 INFO User 4230 processed in 1270.88s
2024-09-16 22:42:34,975 INFO Processing conversation 1231/1399
2024-09-16 22:42:34,994 INFO Input sequence length: torch.Size([1, 10645])
2024-09-16 22:58:02,672 INFO User 4231 processed in 927.70s
2024-09-16 22:58:02,673 INFO Processing conversation 1232/1399
2024-09-16 22:58:02,694 INFO Input sequence length: torch.Size([1, 11901])
2024-09-16 23:14:35,532 INFO User 4232 processed in 992.86s
2024-09-16 23:14:35,534 INFO Processing conversation 1233/1399
2024-09-16 23:14:35,556 INFO Input sequence length: torch.Size([1, 13413])
2024-09-16 23:35:41,063 INFO User 4233 processed in 1265.53s
2024-09-16 23:35:41,065 INFO Processing conversation 1234/1399
2024-09-16 23:35:41,087 INFO Input sequence length: torch.Size([1, 12989])
2024-09-17 00:00:21,432 INFO User 4234 processed in 1480.37s
2024-09-17 00:00:21,434 INFO Processing conversation 1235/1399
2024-09-17 00:00:21,452 INFO Input sequence length: torch.Size([1, 10989])
2024-09-17 00:16:37,889 INFO User 4235 processed in 976.46s
2024-09-17 00:16:37,891 INFO Processing conversation 1236/1399
2024-09-17 00:16:37,904 INFO Input sequence length: torch.Size([1, 4941])
2024-09-17 00:21:07,014 INFO User 4236 processed in 269.12s
2024-09-17 00:21:07,017 INFO Processing conversation 1237/1399
2024-09-17 00:21:07,044 INFO Input sequence length: torch.Size([1, 14549])
2024-09-17 00:46:19,968 INFO User 4237 processed in 1512.95s
2024-09-17 00:46:19,969 INFO Processing conversation 1238/1399
2024-09-17 00:46:20,002 INFO Input sequence length: torch.Size([1, 18229])
2024-09-17 01:21:12,283 INFO User 4239 processed in 2092.31s
2024-09-17 01:21:12,285 INFO Processing conversation 1239/1399
2024-09-17 01:21:12,311 INFO Input sequence length: torch.Size([1, 15021])
2024-09-17 01:42:00,598 INFO User 4240 processed in 1248.31s
2024-09-17 01:42:00,600 INFO Processing conversation 1240/1399
2024-09-17 01:42:00,612 INFO Input sequence length: torch.Size([1, 6893])
2024-09-17 01:47:31,639 INFO User 4238 processed in 331.04s
2024-09-17 01:47:31,641 INFO Processing conversation 1241/1399
2024-09-17 01:47:31,658 INFO Input sequence length: torch.Size([1, 9573])
2024-09-17 01:57:55,890 INFO User 4241 processed in 624.25s
2024-09-17 01:57:55,892 INFO Processing conversation 1242/1399
2024-09-17 01:57:55,939 INFO Input sequence length: torch.Size([1, 22005])
2024-09-17 02:52:45,665 INFO User 4242 processed in 3289.77s
2024-09-17 02:52:45,668 INFO Processing conversation 1243/1399
