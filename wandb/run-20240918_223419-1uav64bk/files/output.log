
2024-09-18 22:34:22,902 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-18 22:34:36,609 INFO Model and tokenizer initialized successfully.
2024-09-18 22:34:36,610 INFO Starting inference from index 30 to 36 on dataset datasetC_test_17000-19999.json
2024-09-18 22:34:36,610 INFO Loading dataset from datasetC_test_17000-19999.json...
2024-09-18 22:34:37,238 INFO Dataset loaded with 3000 conversations.
2024-09-18 22:34:37,241 INFO Loaded dataset datasetC_test_17000-19999.json with 3000 conversations
2024-09-18 22:34:37,242 INFO Selected subset of dataset from index 30 to 37
Map: 100%|████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 288.15 examples/s]
2024-09-18 22:34:37,271 INFO Applied formatting prompts function to dataset
2024-09-18 22:34:37,271 INFO Total conversations to process: 7
2024-09-18 22:34:37,272 INFO Processing conversation 30/36
2024-09-18 22:34:37,281 INFO Input sequence length: torch.Size([1, 3725])
2024-09-18 22:36:36,564 INFO User 17030 processed in 119.29s
2024-09-18 22:36:36,569 INFO Processing conversation 31/36
2024-09-18 22:36:36,583 INFO Input sequence length: torch.Size([1, 5029])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 4097.218386253347
*****************************************************************************************************************
2024-09-18 22:40:43,959 INFO User 17034 processed in 247.39s
2024-09-18 22:40:43,964 INFO Processing conversation 32/36
2024-09-18 22:40:43,987 INFO Input sequence length: torch.Size([1, 8517])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 6172.971374383148
*****************************************************************************************************************
2024-09-18 22:50:24,931 INFO User 17036 processed in 580.97s
2024-09-18 22:50:24,936 INFO Processing conversation 33/36
2024-09-18 22:50:24,956 INFO Input sequence length: torch.Size([1, 6853])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 7048.672433532375
*****************************************************************************************************************
2024-09-18 23:01:53,488 ERROR Exception in conversation user 17032: The length doesn't match between the generated and reference trajectories.
2024-09-18 23:01:53,488 ERROR Attempt 1/3 failed
2024-09-18 23:01:54,512 INFO Input sequence length: torch.Size([1, 6853])
**************************************************Result Report**************************************************
2024-09-18 23:13:19,466 INFO User 17032 processed in 1374.53s
2024-09-18 23:13:19,471 INFO Processing conversation 34/36
2024-09-18 23:13:19,491 INFO Input sequence length: torch.Size([1, 9341])
**************************************************Result Report**************************************************
geobleu: 2.789518772907634e-281
dtw: 9237.985472441704
*****************************************************************************************************************
2024-09-18 23:29:30,149 INFO User 17031 processed in 970.68s
2024-09-18 23:29:30,154 INFO Processing conversation 35/36
2024-09-18 23:29:30,188 INFO Input sequence length: torch.Size([1, 8237])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 11450.866546626827
*****************************************************************************************************************
**************************************************Result Report**************************************************
2024-09-18 23:34:27,265 INFO User 17035 processed in 297.11s
2024-09-18 23:34:27,268 INFO Processing conversation 36/36
2024-09-18 23:34:27,323 INFO Input sequence length: torch.Size([1, 11621])
geobleu: 2.261704978219291e-280
dtw: 3590.7931340083983
*****************************************************************************************************************
2024-09-18 23:54:32,312 INFO User 17033 processed in 1205.04s
2024-09-18 23:54:32,315 INFO Failed conversations: []
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 11522.265059587191
*****************************************************************************************************************
2024-09-18 23:54:32,846 INFO Saving results to generated_datasetC_test_17000-19999_range(30, 37).csv.gz
2024-09-18 23:54:32,853 INFO Results saved to generated_datasetC_test_17000-19999_range(30, 37).csv.gz