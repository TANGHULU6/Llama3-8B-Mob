
2024-09-16 14:49:27,516 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-16 14:49:39,163 INFO Model and tokenizer initialized successfully.
2024-09-16 14:49:39,165 INFO Starting inference from index 400 to 599 on dataset datasetD_test_3000-5999.json
2024-09-16 14:49:39,165 INFO Loading dataset from datasetD_test_3000-5999.json...
2024-09-16 14:49:40,288 INFO Dataset loaded with 3000 conversations.
2024-09-16 14:49:40,291 INFO Loaded dataset datasetD_test_3000-5999.json with 3000 conversations
2024-09-16 14:49:40,292 INFO Selected subset of dataset from index 400 to 600
Map: 100%|███████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 2849.16 examples/s]
2024-09-16 14:49:40,369 INFO Applied formatting prompts function to dataset
2024-09-16 14:49:40,369 INFO Total conversations to process: 200
2024-09-16 14:49:40,369 INFO Processing conversation 400/599
2024-09-16 14:49:40,396 INFO Input sequence length: torch.Size([1, 9869])
2024-09-16 14:58:32,174 INFO User 3400 processed in 531.81s
2024-09-16 14:58:32,176 INFO Processing conversation 401/599
2024-09-16 14:58:32,209 INFO Input sequence length: torch.Size([1, 19749])
2024-09-16 15:30:15,326 INFO User 3401 processed in 1903.15s
2024-09-16 15:30:15,328 INFO Processing conversation 402/599
2024-09-16 15:30:15,357 INFO Input sequence length: torch.Size([1, 17693])
2024-09-16 16:05:11,038 INFO User 3402 processed in 2095.71s
2024-09-16 16:05:11,039 INFO Processing conversation 403/599
2024-09-16 16:05:11,061 INFO Input sequence length: torch.Size([1, 12757])
2024-09-16 16:24:03,542 INFO User 3403 processed in 1132.50s
2024-09-16 16:24:03,544 INFO Processing conversation 404/599
2024-09-16 16:24:03,573 INFO Input sequence length: torch.Size([1, 12741])
2024-09-16 16:46:24,564 INFO User 3404 processed in 1341.02s
2024-09-16 16:46:24,566 INFO Processing conversation 405/599
2024-09-16 16:46:24,582 INFO Input sequence length: torch.Size([1, 8901])
2024-09-16 16:51:52,827 INFO User 3405 processed in 328.26s
2024-09-16 16:51:52,829 INFO Processing conversation 406/599
2024-09-16 16:51:52,854 INFO Input sequence length: torch.Size([1, 15949])
2024-09-16 17:27:37,511 INFO User 3406 processed in 2144.68s
2024-09-16 17:27:37,512 INFO Processing conversation 407/599
2024-09-16 17:27:37,537 INFO Input sequence length: torch.Size([1, 15693])
2024-09-16 18:08:32,563 INFO User 3407 processed in 2455.05s
2024-09-16 18:08:32,565 INFO Processing conversation 408/599
2024-09-16 18:08:32,582 INFO Input sequence length: torch.Size([1, 9525])
2024-09-16 18:20:14,983 INFO User 3408 processed in 702.42s
2024-09-16 18:20:14,984 INFO Processing conversation 409/599
2024-09-16 18:20:15,010 INFO Input sequence length: torch.Size([1, 15605])
2024-09-16 18:49:43,946 INFO User 3409 processed in 1768.96s
2024-09-16 18:49:43,948 INFO Processing conversation 410/599
2024-09-16 18:49:43,965 INFO Input sequence length: torch.Size([1, 9453])
2024-09-16 18:59:22,062 INFO User 3410 processed in 578.11s
2024-09-16 18:59:22,064 INFO Processing conversation 411/599
2024-09-16 18:59:22,079 INFO Input sequence length: torch.Size([1, 8285])
2024-09-16 19:08:57,314 INFO User 3411 processed in 575.25s
2024-09-16 19:08:57,316 INFO Processing conversation 412/599
2024-09-16 19:08:57,336 INFO Input sequence length: torch.Size([1, 11453])
2024-09-16 19:23:05,094 INFO User 3412 processed in 847.78s
2024-09-16 19:23:05,095 INFO Processing conversation 413/599
2024-09-16 19:23:05,125 INFO Input sequence length: torch.Size([1, 17365])
2024-09-16 19:57:14,395 INFO User 3413 processed in 2049.30s
2024-09-16 19:57:14,397 INFO Processing conversation 414/599
2024-09-16 19:57:14,419 INFO Input sequence length: torch.Size([1, 13189])
2024-09-16 20:17:29,854 INFO User 3414 processed in 1215.46s
2024-09-16 20:17:29,855 INFO Processing conversation 415/599
2024-09-16 20:17:29,866 INFO Input sequence length: torch.Size([1, 4885])
2024-09-16 20:20:55,673 INFO User 3415 processed in 205.82s
2024-09-16 20:20:55,675 INFO Processing conversation 416/599
2024-09-16 20:20:55,696 INFO Input sequence length: torch.Size([1, 12725])
2024-09-16 20:48:51,931 INFO User 3416 processed in 1676.26s
2024-09-16 20:48:51,932 INFO Processing conversation 417/599
2024-09-16 20:48:51,956 INFO Input sequence length: torch.Size([1, 14741])
2024-09-16 21:07:23,497 INFO User 3417 processed in 1111.56s
2024-09-16 21:07:23,499 INFO Processing conversation 418/599
2024-09-16 21:07:23,528 INFO Input sequence length: torch.Size([1, 16997])
2024-09-16 21:51:24,269 INFO User 3418 processed in 2640.77s
2024-09-16 21:51:24,271 INFO Processing conversation 419/599
2024-09-16 21:51:24,288 INFO Input sequence length: torch.Size([1, 10045])
2024-09-16 22:01:21,692 INFO User 3419 processed in 597.42s
2024-09-16 22:01:21,694 INFO Processing conversation 420/599
2024-09-16 22:01:21,712 INFO Input sequence length: torch.Size([1, 10373])
2024-09-16 22:14:06,242 INFO User 3420 processed in 764.55s
2024-09-16 22:14:06,243 INFO Processing conversation 421/599
2024-09-16 22:14:06,261 INFO Input sequence length: torch.Size([1, 10437])
2024-09-16 22:29:44,770 INFO User 3421 processed in 938.53s
2024-09-16 22:29:44,772 INFO Processing conversation 422/599
2024-09-16 22:29:44,788 INFO Input sequence length: torch.Size([1, 8589])
2024-09-16 22:43:05,320 INFO User 3422 processed in 800.55s
2024-09-16 22:43:05,322 INFO Processing conversation 423/599
2024-09-16 22:43:05,344 INFO Input sequence length: torch.Size([1, 13733])
2024-09-16 23:02:07,070 INFO User 3423 processed in 1141.75s
2024-09-16 23:02:07,072 INFO Processing conversation 424/599
2024-09-16 23:02:07,090 INFO Input sequence length: torch.Size([1, 10229])
2024-09-16 23:16:09,199 INFO User 3425 processed in 842.13s
2024-09-16 23:16:09,201 INFO Processing conversation 425/599
2024-09-16 23:16:09,235 INFO Input sequence length: torch.Size([1, 20157])
2024-09-16 23:52:01,888 INFO User 3424 processed in 2152.69s
2024-09-16 23:52:01,890 INFO Processing conversation 426/599
2024-09-16 23:52:01,912 INFO Input sequence length: torch.Size([1, 14045])
2024-09-17 00:15:43,520 INFO User 3426 processed in 1421.63s
2024-09-17 00:15:43,522 INFO Processing conversation 427/599
2024-09-17 00:15:43,545 INFO Input sequence length: torch.Size([1, 14629])
2024-09-17 00:39:39,106 INFO User 3427 processed in 1435.58s
2024-09-17 00:39:39,107 INFO Processing conversation 428/599
2024-09-17 00:39:39,120 INFO Input sequence length: torch.Size([1, 5269])
2024-09-17 00:43:17,002 INFO User 3428 processed in 217.89s
2024-09-17 00:43:17,004 INFO Processing conversation 429/599
2024-09-17 00:43:17,024 INFO Input sequence length: torch.Size([1, 11573])
2024-09-17 00:57:52,276 INFO User 3429 processed in 875.27s
2024-09-17 00:57:52,278 INFO Processing conversation 430/599
2024-09-17 00:57:52,293 INFO Input sequence length: torch.Size([1, 9109])
2024-09-17 01:08:15,144 INFO User 3430 processed in 622.87s
2024-09-17 01:08:15,146 INFO Processing conversation 431/599
2024-09-17 01:08:15,166 INFO Input sequence length: torch.Size([1, 12477])
2024-09-17 01:26:41,104 INFO User 3431 processed in 1105.96s
2024-09-17 01:26:41,106 INFO Processing conversation 432/599
2024-09-17 01:26:41,126 INFO Input sequence length: torch.Size([1, 11949])
2024-09-17 01:44:03,488 INFO User 3432 processed in 1042.38s
2024-09-17 01:44:03,489 INFO Processing conversation 433/599
2024-09-17 01:44:03,504 INFO Input sequence length: torch.Size([1, 8197])
2024-09-17 01:52:02,731 INFO User 3433 processed in 479.24s
2024-09-17 01:52:02,733 INFO Processing conversation 434/599
2024-09-17 01:52:02,758 INFO Input sequence length: torch.Size([1, 15589])
2024-09-17 02:10:51,654 INFO User 3434 processed in 1128.92s
2024-09-17 02:10:51,656 INFO Processing conversation 435/599
2024-09-17 02:10:51,677 INFO Input sequence length: torch.Size([1, 12413])
2024-09-17 02:33:58,308 INFO User 3435 processed in 1386.65s
2024-09-17 02:33:58,309 INFO Processing conversation 436/599
2024-09-17 02:33:58,333 INFO Input sequence length: torch.Size([1, 14765])
2024-09-17 02:58:54,896 INFO User 3436 processed in 1496.59s
2024-09-17 02:58:54,898 INFO Processing conversation 437/599
