
2024-09-14 03:59:06,522 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-14 03:59:15,467 INFO Model and tokenizer initialized successfully.
2024-09-14 03:59:15,468 INFO Starting inference from index 22 to 24 on dataset datasetC_eval_13600-16999.json
2024-09-14 03:59:15,468 INFO Loading dataset from datasetC_eval_13600-16999.json...
2024-09-14 03:59:16,277 INFO Dataset loaded with 3400 conversations.
2024-09-14 03:59:16,279 INFO Loaded dataset datasetC_eval_13600-16999.json with 3400 conversations
2024-09-14 03:59:16,281 INFO Selected subset of dataset from index 22 to 24
Map: 100%|█████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 84.47 examples/s]
2024-09-14 03:59:16,419 INFO Applied formatting prompts function to dataset
2024-09-14 03:59:16,419 INFO Total conversations to process: 2
2024-09-14 03:59:16,420 INFO Processing conversation 22/24
2024-09-14 03:59:16,434 INFO Input sequence length: torch.Size([1, 4253])
2024-09-14 04:00:49,298 INFO Conversation 22 processed in 92.88s
2024-09-14 04:00:49,299 INFO Processing conversation 23/24
2024-09-14 04:00:49,310 INFO Input sequence length: torch.Size([1, 6933])
2024-09-14 04:03:05,620 INFO Conversation 23 processed in 136.32s
2024-09-14 04:03:05,621 INFO Failed conversations: []
2024-09-14 04:03:06,240 INFO Saving results to generated_datasetC_eval_13600-16999_range(22, 24).csv.gz
2024-09-14 04:03:06,241 INFO Results saved to generated_datasetC_eval_13600-16999_range(22, 24).csv.gz