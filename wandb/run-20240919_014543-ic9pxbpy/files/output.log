
2024-09-19 01:45:47,922 INFO Initializing model and tokenizer...
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: unsloth/llama-3-8b-Instruct-bnb-4bit can only handle sequence lengths of at most 8192.
But with kaiokendev's RoPE scaling of 6.104, it can be magically be extended to 50000!
Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
2024-09-19 01:45:59,163 INFO Model and tokenizer initialized successfully.
2024-09-19 01:45:59,165 INFO Starting inference from index 2271 to 2273 on dataset datasetC_test_17000-19999.json
2024-09-19 01:45:59,165 INFO Loading dataset from datasetC_test_17000-19999.json...
2024-09-19 01:46:00,032 INFO Dataset loaded with 3000 conversations.
2024-09-19 01:46:00,035 INFO Loaded dataset datasetC_test_17000-19999.json with 3000 conversations
2024-09-19 01:46:00,037 INFO Selected subset of dataset from index 2271 to 2274
Map: 100%|█████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 85.32 examples/s]
2024-09-19 01:46:00,078 INFO Applied formatting prompts function to dataset
2024-09-19 01:46:00,078 INFO Total conversations to process: 3
2024-09-19 01:46:00,079 INFO Processing conversation 2271/2273
2024-09-19 01:46:00,098 INFO Input sequence length: torch.Size([1, 7885])
**************************************************Result Report**************************************************
geobleu: 1.7796813903259925e-281
dtw: 6719.305203613998
*****************************************************************************************************************
2024-09-19 01:48:06,590 INFO User 19273 processed in 126.51s
2024-09-19 01:48:06,595 INFO Processing conversation 2272/2273
2024-09-19 01:48:06,610 INFO Input sequence length: torch.Size([1, 6909])
2024-09-19 01:51:37,365 INFO User 19270 processed in 210.77s
2024-09-19 01:51:37,372 INFO Processing conversation 2273/2273
2024-09-19 01:51:37,388 INFO Input sequence length: torch.Size([1, 6573])
**************************************************Result Report**************************************************
geobleu: 0.0
dtw: 10296.309259363008
*****************************************************************************************************************
2024-09-19 01:52:22,265 INFO User 19266 processed in 44.89s
2024-09-19 01:52:22,268 INFO Failed conversations: []
**************************************************Result Report**************************************************
geobleu: 2.5108894092974187e-278
dtw: 2279.867430587481
*****************************************************************************************************************
2024-09-19 01:52:22,815 INFO Saving results to generated_datasetC_test_17000-19999_range(2271, 2274).csv.gz
2024-09-19 01:52:22,817 INFO Results saved to generated_datasetC_test_17000-19999_range(2271, 2274).csv.gz