{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 625,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 2.616196632385254,
      "learning_rate": 4e-05,
      "loss": 2.6469,
      "step": 1
    },
    {
      "epoch": 0.0032,
      "grad_norm": 2.643979787826538,
      "learning_rate": 8e-05,
      "loss": 2.5748,
      "step": 2
    },
    {
      "epoch": 0.0048,
      "grad_norm": 2.483185291290283,
      "learning_rate": 0.00012,
      "loss": 2.5191,
      "step": 3
    },
    {
      "epoch": 0.0064,
      "grad_norm": 1.4394853115081787,
      "learning_rate": 0.00016,
      "loss": 2.5816,
      "step": 4
    },
    {
      "epoch": 0.008,
      "grad_norm": 3.9909725189208984,
      "learning_rate": 0.0002,
      "loss": 2.3335,
      "step": 5
    },
    {
      "epoch": 0.0096,
      "grad_norm": 1.62691330909729,
      "learning_rate": 0.00019967741935483872,
      "loss": 2.2398,
      "step": 6
    },
    {
      "epoch": 0.0112,
      "grad_norm": 1.6906344890594482,
      "learning_rate": 0.00019935483870967745,
      "loss": 2.2334,
      "step": 7
    },
    {
      "epoch": 0.0128,
      "grad_norm": 1.6319154500961304,
      "learning_rate": 0.00019903225806451613,
      "loss": 2.1845,
      "step": 8
    },
    {
      "epoch": 0.0144,
      "grad_norm": 1.0166704654693604,
      "learning_rate": 0.00019870967741935483,
      "loss": 1.9356,
      "step": 9
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.1774624586105347,
      "learning_rate": 0.00019838709677419357,
      "loss": 1.9067,
      "step": 10
    },
    {
      "epoch": 0.0176,
      "grad_norm": 1.5877622365951538,
      "learning_rate": 0.00019806451612903227,
      "loss": 1.7079,
      "step": 11
    },
    {
      "epoch": 0.0192,
      "grad_norm": 1.0137536525726318,
      "learning_rate": 0.00019774193548387098,
      "loss": 1.7357,
      "step": 12
    },
    {
      "epoch": 0.0208,
      "grad_norm": 1.416523814201355,
      "learning_rate": 0.00019741935483870969,
      "loss": 1.6807,
      "step": 13
    },
    {
      "epoch": 0.0224,
      "grad_norm": 1.347508192062378,
      "learning_rate": 0.0001970967741935484,
      "loss": 1.6495,
      "step": 14
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.8542117476463318,
      "learning_rate": 0.0001967741935483871,
      "loss": 1.5975,
      "step": 15
    },
    {
      "epoch": 0.0256,
      "grad_norm": 1.8865735530853271,
      "learning_rate": 0.00019645161290322583,
      "loss": 1.4956,
      "step": 16
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.9958257675170898,
      "learning_rate": 0.0001961290322580645,
      "loss": 1.4937,
      "step": 17
    },
    {
      "epoch": 0.0288,
      "grad_norm": 1.478940725326538,
      "learning_rate": 0.00019580645161290322,
      "loss": 1.4737,
      "step": 18
    },
    {
      "epoch": 0.0304,
      "grad_norm": 1.4631431102752686,
      "learning_rate": 0.00019548387096774195,
      "loss": 1.4103,
      "step": 19
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.9533590078353882,
      "learning_rate": 0.00019516129032258066,
      "loss": 1.3921,
      "step": 20
    },
    {
      "epoch": 0.0336,
      "grad_norm": 1.1684958934783936,
      "learning_rate": 0.00019483870967741936,
      "loss": 1.417,
      "step": 21
    },
    {
      "epoch": 0.0352,
      "grad_norm": 1.137438178062439,
      "learning_rate": 0.00019451612903225807,
      "loss": 1.3084,
      "step": 22
    },
    {
      "epoch": 0.0368,
      "grad_norm": 1.697924017906189,
      "learning_rate": 0.00019419354838709678,
      "loss": 1.1311,
      "step": 23
    },
    {
      "epoch": 0.0384,
      "grad_norm": 1.4460772275924683,
      "learning_rate": 0.00019387096774193548,
      "loss": 0.9327,
      "step": 24
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.099903106689453,
      "learning_rate": 0.00019354838709677422,
      "loss": 0.9918,
      "step": 25
    },
    {
      "epoch": 0.0416,
      "grad_norm": 1.7604769468307495,
      "learning_rate": 0.00019322580645161292,
      "loss": 0.8579,
      "step": 26
    },
    {
      "epoch": 0.0432,
      "grad_norm": 8.482519149780273,
      "learning_rate": 0.00019290322580645163,
      "loss": 1.0047,
      "step": 27
    },
    {
      "epoch": 0.0448,
      "grad_norm": 2.2215404510498047,
      "learning_rate": 0.00019258064516129033,
      "loss": 0.8382,
      "step": 28
    },
    {
      "epoch": 0.0464,
      "grad_norm": 2.233670949935913,
      "learning_rate": 0.00019225806451612904,
      "loss": 0.7717,
      "step": 29
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.3798346519470215,
      "learning_rate": 0.00019193548387096775,
      "loss": 0.7463,
      "step": 30
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.9335788488388062,
      "learning_rate": 0.00019161290322580645,
      "loss": 0.7663,
      "step": 31
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.7591703534126282,
      "learning_rate": 0.00019129032258064516,
      "loss": 0.758,
      "step": 32
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.6523720026016235,
      "learning_rate": 0.0001909677419354839,
      "loss": 0.6369,
      "step": 33
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.5352237224578857,
      "learning_rate": 0.0001906451612903226,
      "loss": 0.6803,
      "step": 34
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.4772432744503021,
      "learning_rate": 0.0001903225806451613,
      "loss": 0.6225,
      "step": 35
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.38717642426490784,
      "learning_rate": 0.00019,
      "loss": 0.6309,
      "step": 36
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.32022330164909363,
      "learning_rate": 0.00018967741935483872,
      "loss": 0.5357,
      "step": 37
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.5376318097114563,
      "learning_rate": 0.00018935483870967742,
      "loss": 0.6357,
      "step": 38
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.4457826316356659,
      "learning_rate": 0.00018903225806451616,
      "loss": 0.7231,
      "step": 39
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.33144673705101013,
      "learning_rate": 0.00018870967741935486,
      "loss": 0.668,
      "step": 40
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.39594921469688416,
      "learning_rate": 0.00018838709677419354,
      "loss": 0.6543,
      "step": 41
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.38881850242614746,
      "learning_rate": 0.00018806451612903227,
      "loss": 0.6045,
      "step": 42
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.5403571128845215,
      "learning_rate": 0.00018774193548387098,
      "loss": 0.5932,
      "step": 43
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.5587735772132874,
      "learning_rate": 0.0001874193548387097,
      "loss": 0.7142,
      "step": 44
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.37271788716316223,
      "learning_rate": 0.0001870967741935484,
      "loss": 0.5771,
      "step": 45
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.33117005228996277,
      "learning_rate": 0.0001867741935483871,
      "loss": 0.6044,
      "step": 46
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.3530963063240051,
      "learning_rate": 0.0001864516129032258,
      "loss": 0.591,
      "step": 47
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.34774208068847656,
      "learning_rate": 0.00018612903225806454,
      "loss": 0.5454,
      "step": 48
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.2819203734397888,
      "learning_rate": 0.00018580645161290325,
      "loss": 0.6164,
      "step": 49
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2853229343891144,
      "learning_rate": 0.00018548387096774192,
      "loss": 0.6447,
      "step": 50
    },
    {
      "epoch": 0.0816,
      "grad_norm": 0.27104777097702026,
      "learning_rate": 0.00018516129032258066,
      "loss": 0.5773,
      "step": 51
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.3678455054759979,
      "learning_rate": 0.00018483870967741936,
      "loss": 0.5844,
      "step": 52
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.1878814697265625,
      "learning_rate": 0.00018451612903225807,
      "loss": 0.5467,
      "step": 53
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.19288946688175201,
      "learning_rate": 0.0001841935483870968,
      "loss": 0.597,
      "step": 54
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.24192239344120026,
      "learning_rate": 0.00018387096774193548,
      "loss": 0.6421,
      "step": 55
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.16890938580036163,
      "learning_rate": 0.0001835483870967742,
      "loss": 0.6047,
      "step": 56
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.1373911052942276,
      "learning_rate": 0.00018322580645161292,
      "loss": 0.5853,
      "step": 57
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.1847759485244751,
      "learning_rate": 0.00018290322580645163,
      "loss": 0.6076,
      "step": 58
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.17729054391384125,
      "learning_rate": 0.00018258064516129033,
      "loss": 0.584,
      "step": 59
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.14845684170722961,
      "learning_rate": 0.00018225806451612904,
      "loss": 0.5842,
      "step": 60
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.21104726195335388,
      "learning_rate": 0.00018193548387096775,
      "loss": 0.5695,
      "step": 61
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.17625734210014343,
      "learning_rate": 0.00018161290322580645,
      "loss": 0.5179,
      "step": 62
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.21689021587371826,
      "learning_rate": 0.0001812903225806452,
      "loss": 0.6306,
      "step": 63
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.19933228194713593,
      "learning_rate": 0.00018096774193548387,
      "loss": 0.5781,
      "step": 64
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.28530794382095337,
      "learning_rate": 0.00018064516129032257,
      "loss": 0.5389,
      "step": 65
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.14917366206645966,
      "learning_rate": 0.0001803225806451613,
      "loss": 0.6257,
      "step": 66
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.23075802624225616,
      "learning_rate": 0.00018,
      "loss": 0.6168,
      "step": 67
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.18825402855873108,
      "learning_rate": 0.00017967741935483872,
      "loss": 0.5557,
      "step": 68
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.14582152664661407,
      "learning_rate": 0.00017935483870967742,
      "loss": 0.4648,
      "step": 69
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.20653527975082397,
      "learning_rate": 0.00017903225806451613,
      "loss": 0.5916,
      "step": 70
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.2815547287464142,
      "learning_rate": 0.00017870967741935484,
      "loss": 0.5272,
      "step": 71
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.1619197428226471,
      "learning_rate": 0.00017838709677419357,
      "loss": 0.5038,
      "step": 72
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.19685985147953033,
      "learning_rate": 0.00017806451612903228,
      "loss": 0.5509,
      "step": 73
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.2014797478914261,
      "learning_rate": 0.00017774193548387098,
      "loss": 0.5457,
      "step": 74
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.13525129854679108,
      "learning_rate": 0.0001774193548387097,
      "loss": 0.599,
      "step": 75
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.15792842209339142,
      "learning_rate": 0.0001770967741935484,
      "loss": 0.4729,
      "step": 76
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.16623426973819733,
      "learning_rate": 0.0001767741935483871,
      "loss": 0.5346,
      "step": 77
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.14811131358146667,
      "learning_rate": 0.0001764516129032258,
      "loss": 0.5205,
      "step": 78
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.20992255210876465,
      "learning_rate": 0.0001761290322580645,
      "loss": 0.58,
      "step": 79
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1618109494447708,
      "learning_rate": 0.00017580645161290325,
      "loss": 0.601,
      "step": 80
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.1492798924446106,
      "learning_rate": 0.00017548387096774195,
      "loss": 0.4976,
      "step": 81
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.20741593837738037,
      "learning_rate": 0.00017516129032258066,
      "loss": 0.5476,
      "step": 82
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.17395402491092682,
      "learning_rate": 0.00017483870967741936,
      "loss": 0.5102,
      "step": 83
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.24242299795150757,
      "learning_rate": 0.00017451612903225807,
      "loss": 0.5739,
      "step": 84
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.21150965988636017,
      "learning_rate": 0.00017419354838709678,
      "loss": 0.5224,
      "step": 85
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.1425972878932953,
      "learning_rate": 0.0001738709677419355,
      "loss": 0.4832,
      "step": 86
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.15660522878170013,
      "learning_rate": 0.00017354838709677422,
      "loss": 0.6227,
      "step": 87
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.1716149002313614,
      "learning_rate": 0.0001732258064516129,
      "loss": 0.498,
      "step": 88
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.18019424378871918,
      "learning_rate": 0.00017290322580645163,
      "loss": 0.5676,
      "step": 89
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.16720883548259735,
      "learning_rate": 0.00017258064516129034,
      "loss": 0.482,
      "step": 90
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.18075114488601685,
      "learning_rate": 0.00017225806451612904,
      "loss": 0.5615,
      "step": 91
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.22376377880573273,
      "learning_rate": 0.00017193548387096775,
      "loss": 0.5187,
      "step": 92
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.15681612491607666,
      "learning_rate": 0.00017161290322580645,
      "loss": 0.516,
      "step": 93
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.160774365067482,
      "learning_rate": 0.00017129032258064516,
      "loss": 0.5645,
      "step": 94
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.17915333807468414,
      "learning_rate": 0.0001709677419354839,
      "loss": 0.5838,
      "step": 95
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.2114766389131546,
      "learning_rate": 0.0001706451612903226,
      "loss": 0.5352,
      "step": 96
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.215794175863266,
      "learning_rate": 0.00017032258064516128,
      "loss": 0.5558,
      "step": 97
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.15280576050281525,
      "learning_rate": 0.00017,
      "loss": 0.5182,
      "step": 98
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.18414147198200226,
      "learning_rate": 0.00016967741935483872,
      "loss": 0.5804,
      "step": 99
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.23627683520317078,
      "learning_rate": 0.00016935483870967742,
      "loss": 0.5168,
      "step": 100
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.16767418384552002,
      "learning_rate": 0.00016903225806451616,
      "loss": 0.5485,
      "step": 101
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.2861715853214264,
      "learning_rate": 0.00016870967741935484,
      "loss": 0.5913,
      "step": 102
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.19229498505592346,
      "learning_rate": 0.00016838709677419354,
      "loss": 0.5502,
      "step": 103
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.24195992946624756,
      "learning_rate": 0.00016806451612903228,
      "loss": 0.544,
      "step": 104
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.2296346127986908,
      "learning_rate": 0.00016774193548387098,
      "loss": 0.5603,
      "step": 105
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.16268134117126465,
      "learning_rate": 0.00016741935483870966,
      "loss": 0.4546,
      "step": 106
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.16574108600616455,
      "learning_rate": 0.0001670967741935484,
      "loss": 0.5544,
      "step": 107
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.18854588270187378,
      "learning_rate": 0.0001667741935483871,
      "loss": 0.5213,
      "step": 108
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.1790463775396347,
      "learning_rate": 0.0001664516129032258,
      "loss": 0.5779,
      "step": 109
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.11948327720165253,
      "learning_rate": 0.00016612903225806454,
      "loss": 0.4768,
      "step": 110
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.14277701079845428,
      "learning_rate": 0.00016580645161290322,
      "loss": 0.514,
      "step": 111
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.16573388874530792,
      "learning_rate": 0.00016548387096774193,
      "loss": 0.4184,
      "step": 112
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.1554487943649292,
      "learning_rate": 0.00016516129032258066,
      "loss": 0.5042,
      "step": 113
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.17680864036083221,
      "learning_rate": 0.00016483870967741937,
      "loss": 0.4766,
      "step": 114
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.18221415579319,
      "learning_rate": 0.00016451612903225807,
      "loss": 0.5456,
      "step": 115
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.14337192475795746,
      "learning_rate": 0.00016419354838709678,
      "loss": 0.5222,
      "step": 116
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.17619454860687256,
      "learning_rate": 0.00016387096774193548,
      "loss": 0.5641,
      "step": 117
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.10750243812799454,
      "learning_rate": 0.0001635483870967742,
      "loss": 0.4905,
      "step": 118
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.18387152254581451,
      "learning_rate": 0.00016322580645161292,
      "loss": 0.5978,
      "step": 119
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.1504371613264084,
      "learning_rate": 0.00016290322580645163,
      "loss": 0.5648,
      "step": 120
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.1438421607017517,
      "learning_rate": 0.00016258064516129034,
      "loss": 0.4911,
      "step": 121
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.1803305745124817,
      "learning_rate": 0.00016225806451612904,
      "loss": 0.572,
      "step": 122
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.148213729262352,
      "learning_rate": 0.00016193548387096775,
      "loss": 0.5171,
      "step": 123
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.1518433392047882,
      "learning_rate": 0.00016161290322580645,
      "loss": 0.4886,
      "step": 124
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.17367883026599884,
      "learning_rate": 0.00016129032258064516,
      "loss": 0.4606,
      "step": 125
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.23785041272640228,
      "learning_rate": 0.00016096774193548387,
      "loss": 0.5734,
      "step": 126
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.24512410163879395,
      "learning_rate": 0.0001606451612903226,
      "loss": 0.5111,
      "step": 127
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.14737063646316528,
      "learning_rate": 0.0001603225806451613,
      "loss": 0.4908,
      "step": 128
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.19976355135440826,
      "learning_rate": 0.00016,
      "loss": 0.529,
      "step": 129
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.16273675858974457,
      "learning_rate": 0.00015967741935483872,
      "loss": 0.4277,
      "step": 130
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.16616898775100708,
      "learning_rate": 0.00015935483870967743,
      "loss": 0.5507,
      "step": 131
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.15309563279151917,
      "learning_rate": 0.00015903225806451613,
      "loss": 0.5419,
      "step": 132
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.1836058497428894,
      "learning_rate": 0.00015870967741935487,
      "loss": 0.5748,
      "step": 133
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.1922934502363205,
      "learning_rate": 0.00015838709677419357,
      "loss": 0.564,
      "step": 134
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.157857283949852,
      "learning_rate": 0.00015806451612903225,
      "loss": 0.5714,
      "step": 135
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.18139144778251648,
      "learning_rate": 0.00015774193548387098,
      "loss": 0.5764,
      "step": 136
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.1422162801027298,
      "learning_rate": 0.0001574193548387097,
      "loss": 0.5848,
      "step": 137
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.17493070662021637,
      "learning_rate": 0.0001570967741935484,
      "loss": 0.4746,
      "step": 138
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.14217311143875122,
      "learning_rate": 0.0001567741935483871,
      "loss": 0.5582,
      "step": 139
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.18344709277153015,
      "learning_rate": 0.0001564516129032258,
      "loss": 0.5342,
      "step": 140
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.19554004073143005,
      "learning_rate": 0.00015612903225806451,
      "loss": 0.5334,
      "step": 141
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.165365532040596,
      "learning_rate": 0.00015580645161290325,
      "loss": 0.4718,
      "step": 142
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.18556851148605347,
      "learning_rate": 0.00015548387096774195,
      "loss": 0.5337,
      "step": 143
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.15942391753196716,
      "learning_rate": 0.00015516129032258063,
      "loss": 0.5928,
      "step": 144
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.13840670883655548,
      "learning_rate": 0.00015483870967741937,
      "loss": 0.464,
      "step": 145
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.1372445821762085,
      "learning_rate": 0.00015451612903225807,
      "loss": 0.5461,
      "step": 146
    },
    {
      "epoch": 0.2352,
      "grad_norm": 0.16804781556129456,
      "learning_rate": 0.00015419354838709678,
      "loss": 0.4626,
      "step": 147
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.1742524355649948,
      "learning_rate": 0.0001538709677419355,
      "loss": 0.5386,
      "step": 148
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.15360943973064423,
      "learning_rate": 0.0001535483870967742,
      "loss": 0.5404,
      "step": 149
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.25241589546203613,
      "learning_rate": 0.0001532258064516129,
      "loss": 0.5561,
      "step": 150
    },
    {
      "epoch": 0.2416,
      "grad_norm": 0.1383262276649475,
      "learning_rate": 0.00015290322580645163,
      "loss": 0.5683,
      "step": 151
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.24484914541244507,
      "learning_rate": 0.00015258064516129034,
      "loss": 0.5479,
      "step": 152
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.13822227716445923,
      "learning_rate": 0.00015225806451612902,
      "loss": 0.4543,
      "step": 153
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.17341665923595428,
      "learning_rate": 0.00015193548387096775,
      "loss": 0.5544,
      "step": 154
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.24832943081855774,
      "learning_rate": 0.00015161290322580646,
      "loss": 0.5189,
      "step": 155
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.14903169870376587,
      "learning_rate": 0.00015129032258064516,
      "loss": 0.5159,
      "step": 156
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.22984497249126434,
      "learning_rate": 0.0001509677419354839,
      "loss": 0.5923,
      "step": 157
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.15873835980892181,
      "learning_rate": 0.00015064516129032257,
      "loss": 0.47,
      "step": 158
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.1733444780111313,
      "learning_rate": 0.00015032258064516128,
      "loss": 0.5089,
      "step": 159
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.14364932477474213,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.4978,
      "step": 160
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.16657495498657227,
      "learning_rate": 0.00014967741935483872,
      "loss": 0.5093,
      "step": 161
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.15221890807151794,
      "learning_rate": 0.00014935483870967743,
      "loss": 0.4963,
      "step": 162
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.1484401524066925,
      "learning_rate": 0.00014903225806451613,
      "loss": 0.5442,
      "step": 163
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.1576363742351532,
      "learning_rate": 0.00014870967741935484,
      "loss": 0.5161,
      "step": 164
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.13411583006381989,
      "learning_rate": 0.00014838709677419355,
      "loss": 0.5519,
      "step": 165
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.18380095064640045,
      "learning_rate": 0.00014806451612903228,
      "loss": 0.5335,
      "step": 166
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.14879219233989716,
      "learning_rate": 0.00014774193548387098,
      "loss": 0.5613,
      "step": 167
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.21698440611362457,
      "learning_rate": 0.0001474193548387097,
      "loss": 0.4645,
      "step": 168
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.14173097908496857,
      "learning_rate": 0.0001470967741935484,
      "loss": 0.6042,
      "step": 169
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.12478388100862503,
      "learning_rate": 0.0001467741935483871,
      "loss": 0.5738,
      "step": 170
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.150643453001976,
      "learning_rate": 0.0001464516129032258,
      "loss": 0.5388,
      "step": 171
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.14822064340114594,
      "learning_rate": 0.00014612903225806452,
      "loss": 0.5518,
      "step": 172
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.13478340208530426,
      "learning_rate": 0.00014580645161290322,
      "loss": 0.5229,
      "step": 173
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.19078855216503143,
      "learning_rate": 0.00014548387096774196,
      "loss": 0.5006,
      "step": 174
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16125154495239258,
      "learning_rate": 0.00014516129032258066,
      "loss": 0.5564,
      "step": 175
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.15212810039520264,
      "learning_rate": 0.00014483870967741937,
      "loss": 0.5161,
      "step": 176
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.1542932391166687,
      "learning_rate": 0.00014451612903225807,
      "loss": 0.5099,
      "step": 177
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.1573498696088791,
      "learning_rate": 0.00014419354838709678,
      "loss": 0.5292,
      "step": 178
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.1651434600353241,
      "learning_rate": 0.00014387096774193549,
      "loss": 0.4982,
      "step": 179
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.527588963508606,
      "learning_rate": 0.00014354838709677422,
      "loss": 0.5309,
      "step": 180
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.20825862884521484,
      "learning_rate": 0.00014322580645161293,
      "loss": 0.479,
      "step": 181
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.21218740940093994,
      "learning_rate": 0.0001429032258064516,
      "loss": 0.5547,
      "step": 182
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.22643132507801056,
      "learning_rate": 0.00014258064516129034,
      "loss": 0.4921,
      "step": 183
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.31380942463874817,
      "learning_rate": 0.00014225806451612904,
      "loss": 0.6318,
      "step": 184
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.1715070605278015,
      "learning_rate": 0.00014193548387096775,
      "loss": 0.562,
      "step": 185
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.23459064960479736,
      "learning_rate": 0.00014161290322580646,
      "loss": 0.5256,
      "step": 186
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.17199838161468506,
      "learning_rate": 0.00014129032258064516,
      "loss": 0.4622,
      "step": 187
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.1744316965341568,
      "learning_rate": 0.00014096774193548387,
      "loss": 0.5392,
      "step": 188
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.12548361718654633,
      "learning_rate": 0.0001406451612903226,
      "loss": 0.4925,
      "step": 189
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.17542396485805511,
      "learning_rate": 0.0001403225806451613,
      "loss": 0.5406,
      "step": 190
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.20041760802268982,
      "learning_rate": 0.00014,
      "loss": 0.5135,
      "step": 191
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.11009722948074341,
      "learning_rate": 0.00013967741935483872,
      "loss": 0.5091,
      "step": 192
    },
    {
      "epoch": 0.3088,
      "grad_norm": 0.19465188682079315,
      "learning_rate": 0.00013935483870967743,
      "loss": 0.5373,
      "step": 193
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.1847967505455017,
      "learning_rate": 0.00013903225806451613,
      "loss": 0.4839,
      "step": 194
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.14434602856636047,
      "learning_rate": 0.00013870967741935487,
      "loss": 0.4859,
      "step": 195
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.17612160742282867,
      "learning_rate": 0.00013838709677419355,
      "loss": 0.502,
      "step": 196
    },
    {
      "epoch": 0.3152,
      "grad_norm": 0.18987397849559784,
      "learning_rate": 0.00013806451612903225,
      "loss": 0.5371,
      "step": 197
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.1303003877401352,
      "learning_rate": 0.00013774193548387099,
      "loss": 0.4706,
      "step": 198
    },
    {
      "epoch": 0.3184,
      "grad_norm": 0.15636107325553894,
      "learning_rate": 0.0001374193548387097,
      "loss": 0.6161,
      "step": 199
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.11153388023376465,
      "learning_rate": 0.00013709677419354837,
      "loss": 0.5041,
      "step": 200
    },
    {
      "epoch": 0.3216,
      "grad_norm": 0.19253772497177124,
      "learning_rate": 0.0001367741935483871,
      "loss": 0.457,
      "step": 201
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.13231267035007477,
      "learning_rate": 0.0001364516129032258,
      "loss": 0.4936,
      "step": 202
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.11498859524726868,
      "learning_rate": 0.00013612903225806452,
      "loss": 0.5134,
      "step": 203
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.2531065046787262,
      "learning_rate": 0.00013580645161290325,
      "loss": 0.5684,
      "step": 204
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.1466679573059082,
      "learning_rate": 0.00013548387096774193,
      "loss": 0.4703,
      "step": 205
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.2010045200586319,
      "learning_rate": 0.00013516129032258064,
      "loss": 0.5294,
      "step": 206
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.12157200276851654,
      "learning_rate": 0.00013483870967741937,
      "loss": 0.5065,
      "step": 207
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.14472809433937073,
      "learning_rate": 0.00013451612903225807,
      "loss": 0.5094,
      "step": 208
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.15692256391048431,
      "learning_rate": 0.00013419354838709678,
      "loss": 0.4696,
      "step": 209
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.1609804779291153,
      "learning_rate": 0.0001338709677419355,
      "loss": 0.5704,
      "step": 210
    },
    {
      "epoch": 0.3376,
      "grad_norm": 0.10734965652227402,
      "learning_rate": 0.0001335483870967742,
      "loss": 0.5032,
      "step": 211
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.15811170637607574,
      "learning_rate": 0.0001332258064516129,
      "loss": 0.5356,
      "step": 212
    },
    {
      "epoch": 0.3408,
      "grad_norm": 0.15921898186206818,
      "learning_rate": 0.00013290322580645163,
      "loss": 0.6031,
      "step": 213
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.1410362273454666,
      "learning_rate": 0.00013258064516129034,
      "loss": 0.5631,
      "step": 214
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.1405416876077652,
      "learning_rate": 0.00013225806451612905,
      "loss": 0.5428,
      "step": 215
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.12273843586444855,
      "learning_rate": 0.00013193548387096775,
      "loss": 0.4514,
      "step": 216
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.16304141283035278,
      "learning_rate": 0.00013161290322580646,
      "loss": 0.5566,
      "step": 217
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.13519325852394104,
      "learning_rate": 0.00013129032258064516,
      "loss": 0.5545,
      "step": 218
    },
    {
      "epoch": 0.3504,
      "grad_norm": 0.12838585674762726,
      "learning_rate": 0.00013096774193548387,
      "loss": 0.5202,
      "step": 219
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.26963189244270325,
      "learning_rate": 0.00013064516129032258,
      "loss": 0.5152,
      "step": 220
    },
    {
      "epoch": 0.3536,
      "grad_norm": 0.13668707013130188,
      "learning_rate": 0.0001303225806451613,
      "loss": 0.4972,
      "step": 221
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.18767444789409637,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.5614,
      "step": 222
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.1955798864364624,
      "learning_rate": 0.00012967741935483872,
      "loss": 0.5673,
      "step": 223
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.15091735124588013,
      "learning_rate": 0.00012935483870967743,
      "loss": 0.4377,
      "step": 224
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.20578190684318542,
      "learning_rate": 0.00012903225806451613,
      "loss": 0.5274,
      "step": 225
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.22003914415836334,
      "learning_rate": 0.00012870967741935484,
      "loss": 0.5401,
      "step": 226
    },
    {
      "epoch": 0.3632,
      "grad_norm": 0.16983671486377716,
      "learning_rate": 0.00012838709677419357,
      "loss": 0.5489,
      "step": 227
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.18932950496673584,
      "learning_rate": 0.00012806451612903228,
      "loss": 0.486,
      "step": 228
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.19429107010364532,
      "learning_rate": 0.00012774193548387096,
      "loss": 0.4481,
      "step": 229
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.14546318352222443,
      "learning_rate": 0.0001274193548387097,
      "loss": 0.5284,
      "step": 230
    },
    {
      "epoch": 0.3696,
      "grad_norm": 0.14719180762767792,
      "learning_rate": 0.0001270967741935484,
      "loss": 0.4661,
      "step": 231
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.158120796084404,
      "learning_rate": 0.0001267741935483871,
      "loss": 0.5405,
      "step": 232
    },
    {
      "epoch": 0.3728,
      "grad_norm": 0.12977851927280426,
      "learning_rate": 0.0001264516129032258,
      "loss": 0.4568,
      "step": 233
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.14880327880382538,
      "learning_rate": 0.00012612903225806452,
      "loss": 0.4922,
      "step": 234
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.15622787177562714,
      "learning_rate": 0.00012580645161290322,
      "loss": 0.5482,
      "step": 235
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.14141933619976044,
      "learning_rate": 0.00012548387096774196,
      "loss": 0.5154,
      "step": 236
    },
    {
      "epoch": 0.3792,
      "grad_norm": 0.1551292985677719,
      "learning_rate": 0.00012516129032258066,
      "loss": 0.5588,
      "step": 237
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.13905231654644012,
      "learning_rate": 0.00012483870967741934,
      "loss": 0.506,
      "step": 238
    },
    {
      "epoch": 0.3824,
      "grad_norm": 0.12110227346420288,
      "learning_rate": 0.00012451612903225808,
      "loss": 0.4876,
      "step": 239
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.1331094652414322,
      "learning_rate": 0.00012419354838709678,
      "loss": 0.5123,
      "step": 240
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.14777371287345886,
      "learning_rate": 0.0001238709677419355,
      "loss": 0.5308,
      "step": 241
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.1233958825469017,
      "learning_rate": 0.00012354838709677422,
      "loss": 0.5617,
      "step": 242
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.12221821397542953,
      "learning_rate": 0.0001232258064516129,
      "loss": 0.5194,
      "step": 243
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.13665257394313812,
      "learning_rate": 0.0001229032258064516,
      "loss": 0.5617,
      "step": 244
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.0916622206568718,
      "learning_rate": 0.00012258064516129034,
      "loss": 0.4264,
      "step": 245
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.11954159289598465,
      "learning_rate": 0.00012225806451612905,
      "loss": 0.5548,
      "step": 246
    },
    {
      "epoch": 0.3952,
      "grad_norm": 0.12496061623096466,
      "learning_rate": 0.00012193548387096774,
      "loss": 0.4507,
      "step": 247
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.10434919595718384,
      "learning_rate": 0.00012161290322580644,
      "loss": 0.5215,
      "step": 248
    },
    {
      "epoch": 0.3984,
      "grad_norm": 0.12496913969516754,
      "learning_rate": 0.00012129032258064516,
      "loss": 0.5325,
      "step": 249
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.10898428410291672,
      "learning_rate": 0.00012096774193548388,
      "loss": 0.5521,
      "step": 250
    },
    {
      "epoch": 0.4016,
      "grad_norm": 0.11292990297079086,
      "learning_rate": 0.00012064516129032259,
      "loss": 0.4516,
      "step": 251
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.10677102208137512,
      "learning_rate": 0.00012032258064516128,
      "loss": 0.4359,
      "step": 252
    },
    {
      "epoch": 0.4048,
      "grad_norm": 0.1265905499458313,
      "learning_rate": 0.00012,
      "loss": 0.5192,
      "step": 253
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.12361595779657364,
      "learning_rate": 0.00011967741935483871,
      "loss": 0.4823,
      "step": 254
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.0953320860862732,
      "learning_rate": 0.00011935483870967743,
      "loss": 0.4697,
      "step": 255
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.127138152718544,
      "learning_rate": 0.00011903225806451615,
      "loss": 0.5791,
      "step": 256
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.17464688420295715,
      "learning_rate": 0.00011870967741935484,
      "loss": 0.5908,
      "step": 257
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.1272588074207306,
      "learning_rate": 0.00011838709677419355,
      "loss": 0.5493,
      "step": 258
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.10770399868488312,
      "learning_rate": 0.00011806451612903227,
      "loss": 0.4536,
      "step": 259
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.1316964477300644,
      "learning_rate": 0.00011774193548387097,
      "loss": 0.5557,
      "step": 260
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.13736392557621002,
      "learning_rate": 0.00011741935483870967,
      "loss": 0.5297,
      "step": 261
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.18477469682693481,
      "learning_rate": 0.00011709677419354839,
      "loss": 0.5382,
      "step": 262
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.11298839747905731,
      "learning_rate": 0.0001167741935483871,
      "loss": 0.4387,
      "step": 263
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.19949324429035187,
      "learning_rate": 0.00011645161290322581,
      "loss": 0.5321,
      "step": 264
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.1252422034740448,
      "learning_rate": 0.00011612903225806453,
      "loss": 0.547,
      "step": 265
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.2399924248456955,
      "learning_rate": 0.00011580645161290322,
      "loss": 0.5381,
      "step": 266
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.14132000505924225,
      "learning_rate": 0.00011548387096774193,
      "loss": 0.5784,
      "step": 267
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.1302478015422821,
      "learning_rate": 0.00011516129032258065,
      "loss": 0.5066,
      "step": 268
    },
    {
      "epoch": 0.4304,
      "grad_norm": 0.2048477977514267,
      "learning_rate": 0.00011483870967741937,
      "loss": 0.5402,
      "step": 269
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.1092580258846283,
      "learning_rate": 0.00011451612903225808,
      "loss": 0.4819,
      "step": 270
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.1705201417207718,
      "learning_rate": 0.00011419354838709677,
      "loss": 0.4656,
      "step": 271
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.1456979364156723,
      "learning_rate": 0.00011387096774193549,
      "loss": 0.4922,
      "step": 272
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.09874267131090164,
      "learning_rate": 0.0001135483870967742,
      "loss": 0.4557,
      "step": 273
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.11011428385972977,
      "learning_rate": 0.00011322580645161291,
      "loss": 0.4768,
      "step": 274
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.13698770105838776,
      "learning_rate": 0.00011290322580645163,
      "loss": 0.5134,
      "step": 275
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.11008768528699875,
      "learning_rate": 0.00011258064516129033,
      "loss": 0.5284,
      "step": 276
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.1358780562877655,
      "learning_rate": 0.00011225806451612903,
      "loss": 0.4998,
      "step": 277
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.15160834789276123,
      "learning_rate": 0.00011193548387096775,
      "loss": 0.5699,
      "step": 278
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.1261625438928604,
      "learning_rate": 0.00011161290322580646,
      "loss": 0.5106,
      "step": 279
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.12638907134532928,
      "learning_rate": 0.00011129032258064515,
      "loss": 0.5111,
      "step": 280
    },
    {
      "epoch": 0.4496,
      "grad_norm": 0.17487944662570953,
      "learning_rate": 0.00011096774193548387,
      "loss": 0.4994,
      "step": 281
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.1302817463874817,
      "learning_rate": 0.00011064516129032259,
      "loss": 0.556,
      "step": 282
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.1317821443080902,
      "learning_rate": 0.0001103225806451613,
      "loss": 0.4795,
      "step": 283
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.16223900020122528,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.5101,
      "step": 284
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.1430860310792923,
      "learning_rate": 0.00010967741935483871,
      "loss": 0.5099,
      "step": 285
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.12634940445423126,
      "learning_rate": 0.00010935483870967742,
      "loss": 0.571,
      "step": 286
    },
    {
      "epoch": 0.4592,
      "grad_norm": 0.10688186436891556,
      "learning_rate": 0.00010903225806451614,
      "loss": 0.5448,
      "step": 287
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.11438576877117157,
      "learning_rate": 0.00010870967741935486,
      "loss": 0.5141,
      "step": 288
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.12778228521347046,
      "learning_rate": 0.00010838709677419356,
      "loss": 0.5392,
      "step": 289
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.1391276866197586,
      "learning_rate": 0.00010806451612903225,
      "loss": 0.5079,
      "step": 290
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.1320669800043106,
      "learning_rate": 0.00010774193548387097,
      "loss": 0.5337,
      "step": 291
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.11457010358572006,
      "learning_rate": 0.00010741935483870968,
      "loss": 0.5134,
      "step": 292
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.19511409103870392,
      "learning_rate": 0.0001070967741935484,
      "loss": 0.5611,
      "step": 293
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.1542099416255951,
      "learning_rate": 0.00010677419354838709,
      "loss": 0.5384,
      "step": 294
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.11110133677721024,
      "learning_rate": 0.0001064516129032258,
      "loss": 0.5505,
      "step": 295
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.1565214991569519,
      "learning_rate": 0.00010612903225806452,
      "loss": 0.5043,
      "step": 296
    },
    {
      "epoch": 0.4752,
      "grad_norm": 0.15034814178943634,
      "learning_rate": 0.00010580645161290324,
      "loss": 0.5377,
      "step": 297
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.14072442054748535,
      "learning_rate": 0.00010548387096774195,
      "loss": 0.5596,
      "step": 298
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.1635579615831375,
      "learning_rate": 0.00010516129032258064,
      "loss": 0.4604,
      "step": 299
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.11710410565137863,
      "learning_rate": 0.00010483870967741936,
      "loss": 0.5401,
      "step": 300
    },
    {
      "epoch": 0.4816,
      "grad_norm": 0.1859472543001175,
      "learning_rate": 0.00010451612903225806,
      "loss": 0.5358,
      "step": 301
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.1595281958580017,
      "learning_rate": 0.00010419354838709678,
      "loss": 0.4502,
      "step": 302
    },
    {
      "epoch": 0.4848,
      "grad_norm": 0.1513810157775879,
      "learning_rate": 0.0001038709677419355,
      "loss": 0.4991,
      "step": 303
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.14707008004188538,
      "learning_rate": 0.0001035483870967742,
      "loss": 0.5264,
      "step": 304
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.135506272315979,
      "learning_rate": 0.0001032258064516129,
      "loss": 0.4938,
      "step": 305
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.13001322746276855,
      "learning_rate": 0.00010290322580645162,
      "loss": 0.4507,
      "step": 306
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.11567723751068115,
      "learning_rate": 0.00010258064516129033,
      "loss": 0.5,
      "step": 307
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.1662069708108902,
      "learning_rate": 0.00010225806451612902,
      "loss": 0.5007,
      "step": 308
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.1700979471206665,
      "learning_rate": 0.00010193548387096774,
      "loss": 0.5338,
      "step": 309
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.11213324964046478,
      "learning_rate": 0.00010161290322580646,
      "loss": 0.5107,
      "step": 310
    },
    {
      "epoch": 0.4976,
      "grad_norm": 0.11964552104473114,
      "learning_rate": 0.00010129032258064517,
      "loss": 0.4862,
      "step": 311
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.14524421095848083,
      "learning_rate": 0.00010096774193548389,
      "loss": 0.4724,
      "step": 312
    },
    {
      "epoch": 0.5008,
      "grad_norm": 0.15129810571670532,
      "learning_rate": 0.00010064516129032258,
      "loss": 0.5147,
      "step": 313
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.12961702048778534,
      "learning_rate": 0.00010032258064516129,
      "loss": 0.4873,
      "step": 314
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.12583334743976593,
      "learning_rate": 0.0001,
      "loss": 0.5046,
      "step": 315
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.17683498561382294,
      "learning_rate": 9.967741935483872e-05,
      "loss": 0.5582,
      "step": 316
    },
    {
      "epoch": 0.5072,
      "grad_norm": 0.12427359074354172,
      "learning_rate": 9.935483870967742e-05,
      "loss": 0.5305,
      "step": 317
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.15445293486118317,
      "learning_rate": 9.903225806451614e-05,
      "loss": 0.4924,
      "step": 318
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.11405935883522034,
      "learning_rate": 9.870967741935484e-05,
      "loss": 0.5091,
      "step": 319
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.15397576987743378,
      "learning_rate": 9.838709677419355e-05,
      "loss": 0.5186,
      "step": 320
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.13119035959243774,
      "learning_rate": 9.806451612903226e-05,
      "loss": 0.5004,
      "step": 321
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.11579037457704544,
      "learning_rate": 9.774193548387098e-05,
      "loss": 0.4491,
      "step": 322
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.20189273357391357,
      "learning_rate": 9.741935483870968e-05,
      "loss": 0.4986,
      "step": 323
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.10102647542953491,
      "learning_rate": 9.709677419354839e-05,
      "loss": 0.448,
      "step": 324
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1293172389268875,
      "learning_rate": 9.677419354838711e-05,
      "loss": 0.4486,
      "step": 325
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.16146263480186462,
      "learning_rate": 9.645161290322581e-05,
      "loss": 0.4619,
      "step": 326
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.14499424397945404,
      "learning_rate": 9.612903225806452e-05,
      "loss": 0.4874,
      "step": 327
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.14938177168369293,
      "learning_rate": 9.580645161290323e-05,
      "loss": 0.4785,
      "step": 328
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.13949239253997803,
      "learning_rate": 9.548387096774195e-05,
      "loss": 0.447,
      "step": 329
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.13493935763835907,
      "learning_rate": 9.516129032258065e-05,
      "loss": 0.483,
      "step": 330
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.12645159661769867,
      "learning_rate": 9.483870967741936e-05,
      "loss": 0.5128,
      "step": 331
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.1343155950307846,
      "learning_rate": 9.451612903225808e-05,
      "loss": 0.4566,
      "step": 332
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.13048920035362244,
      "learning_rate": 9.419354838709677e-05,
      "loss": 0.5936,
      "step": 333
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.16979026794433594,
      "learning_rate": 9.387096774193549e-05,
      "loss": 0.5045,
      "step": 334
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.11575527489185333,
      "learning_rate": 9.35483870967742e-05,
      "loss": 0.5238,
      "step": 335
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.1636132001876831,
      "learning_rate": 9.32258064516129e-05,
      "loss": 0.549,
      "step": 336
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.09463471174240112,
      "learning_rate": 9.290322580645162e-05,
      "loss": 0.4564,
      "step": 337
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.14128853380680084,
      "learning_rate": 9.258064516129033e-05,
      "loss": 0.5265,
      "step": 338
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.13930568099021912,
      "learning_rate": 9.225806451612904e-05,
      "loss": 0.5307,
      "step": 339
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.1343477964401245,
      "learning_rate": 9.193548387096774e-05,
      "loss": 0.5766,
      "step": 340
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.09423892199993134,
      "learning_rate": 9.161290322580646e-05,
      "loss": 0.5872,
      "step": 341
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.14801204204559326,
      "learning_rate": 9.129032258064517e-05,
      "loss": 0.5018,
      "step": 342
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.15226587653160095,
      "learning_rate": 9.096774193548387e-05,
      "loss": 0.5373,
      "step": 343
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.11677032709121704,
      "learning_rate": 9.06451612903226e-05,
      "loss": 0.5212,
      "step": 344
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.13288697600364685,
      "learning_rate": 9.032258064516129e-05,
      "loss": 0.4753,
      "step": 345
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.1502215415239334,
      "learning_rate": 9e-05,
      "loss": 0.5645,
      "step": 346
    },
    {
      "epoch": 0.5552,
      "grad_norm": 0.10844293236732483,
      "learning_rate": 8.967741935483871e-05,
      "loss": 0.4611,
      "step": 347
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.12488885968923569,
      "learning_rate": 8.935483870967742e-05,
      "loss": 0.4806,
      "step": 348
    },
    {
      "epoch": 0.5584,
      "grad_norm": 0.12897737324237823,
      "learning_rate": 8.903225806451614e-05,
      "loss": 0.4447,
      "step": 349
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.14331652224063873,
      "learning_rate": 8.870967741935484e-05,
      "loss": 0.5699,
      "step": 350
    },
    {
      "epoch": 0.5616,
      "grad_norm": 0.142014741897583,
      "learning_rate": 8.838709677419355e-05,
      "loss": 0.5074,
      "step": 351
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.12968413531780243,
      "learning_rate": 8.806451612903226e-05,
      "loss": 0.5499,
      "step": 352
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.11368823796510696,
      "learning_rate": 8.774193548387098e-05,
      "loss": 0.4868,
      "step": 353
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.18259893357753754,
      "learning_rate": 8.741935483870968e-05,
      "loss": 0.5661,
      "step": 354
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.18164236843585968,
      "learning_rate": 8.709677419354839e-05,
      "loss": 0.4889,
      "step": 355
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.12289272248744965,
      "learning_rate": 8.677419354838711e-05,
      "loss": 0.4602,
      "step": 356
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.18023884296417236,
      "learning_rate": 8.645161290322581e-05,
      "loss": 0.558,
      "step": 357
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.13086144626140594,
      "learning_rate": 8.612903225806452e-05,
      "loss": 0.5162,
      "step": 358
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.12902718782424927,
      "learning_rate": 8.580645161290323e-05,
      "loss": 0.541,
      "step": 359
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.12609730660915375,
      "learning_rate": 8.548387096774195e-05,
      "loss": 0.5499,
      "step": 360
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.17694197595119476,
      "learning_rate": 8.516129032258064e-05,
      "loss": 0.534,
      "step": 361
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.15811966359615326,
      "learning_rate": 8.483870967741936e-05,
      "loss": 0.4701,
      "step": 362
    },
    {
      "epoch": 0.5808,
      "grad_norm": 0.1249733418226242,
      "learning_rate": 8.451612903225808e-05,
      "loss": 0.49,
      "step": 363
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.14867736399173737,
      "learning_rate": 8.419354838709677e-05,
      "loss": 0.4743,
      "step": 364
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.10646334290504456,
      "learning_rate": 8.387096774193549e-05,
      "loss": 0.4952,
      "step": 365
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.1495543122291565,
      "learning_rate": 8.35483870967742e-05,
      "loss": 0.4605,
      "step": 366
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.14560547471046448,
      "learning_rate": 8.32258064516129e-05,
      "loss": 0.4803,
      "step": 367
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.1499129831790924,
      "learning_rate": 8.290322580645161e-05,
      "loss": 0.5578,
      "step": 368
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.1491595059633255,
      "learning_rate": 8.258064516129033e-05,
      "loss": 0.5708,
      "step": 369
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.1267063170671463,
      "learning_rate": 8.225806451612904e-05,
      "loss": 0.5224,
      "step": 370
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.1598949134349823,
      "learning_rate": 8.193548387096774e-05,
      "loss": 0.5315,
      "step": 371
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.15245869755744934,
      "learning_rate": 8.161290322580646e-05,
      "loss": 0.5459,
      "step": 372
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.12158334255218506,
      "learning_rate": 8.129032258064517e-05,
      "loss": 0.5076,
      "step": 373
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.10894765704870224,
      "learning_rate": 8.096774193548387e-05,
      "loss": 0.5208,
      "step": 374
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1283508688211441,
      "learning_rate": 8.064516129032258e-05,
      "loss": 0.5118,
      "step": 375
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.16331228613853455,
      "learning_rate": 8.03225806451613e-05,
      "loss": 0.5478,
      "step": 376
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.12740640342235565,
      "learning_rate": 8e-05,
      "loss": 0.5764,
      "step": 377
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.09693451970815659,
      "learning_rate": 7.967741935483871e-05,
      "loss": 0.5058,
      "step": 378
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.12552127242088318,
      "learning_rate": 7.935483870967743e-05,
      "loss": 0.5039,
      "step": 379
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.1590624302625656,
      "learning_rate": 7.903225806451613e-05,
      "loss": 0.4324,
      "step": 380
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.08635002374649048,
      "learning_rate": 7.870967741935484e-05,
      "loss": 0.4927,
      "step": 381
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.10991907864809036,
      "learning_rate": 7.838709677419355e-05,
      "loss": 0.4652,
      "step": 382
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.14921024441719055,
      "learning_rate": 7.806451612903226e-05,
      "loss": 0.5538,
      "step": 383
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.12055832892656326,
      "learning_rate": 7.774193548387098e-05,
      "loss": 0.48,
      "step": 384
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.13070924580097198,
      "learning_rate": 7.741935483870968e-05,
      "loss": 0.5993,
      "step": 385
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.15794651210308075,
      "learning_rate": 7.709677419354839e-05,
      "loss": 0.5379,
      "step": 386
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.12713541090488434,
      "learning_rate": 7.67741935483871e-05,
      "loss": 0.5042,
      "step": 387
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.13023078441619873,
      "learning_rate": 7.645161290322582e-05,
      "loss": 0.497,
      "step": 388
    },
    {
      "epoch": 0.6224,
      "grad_norm": 0.1554642915725708,
      "learning_rate": 7.612903225806451e-05,
      "loss": 0.4526,
      "step": 389
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.1770000010728836,
      "learning_rate": 7.580645161290323e-05,
      "loss": 0.5389,
      "step": 390
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.13950730860233307,
      "learning_rate": 7.548387096774195e-05,
      "loss": 0.4622,
      "step": 391
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.12858612835407257,
      "learning_rate": 7.516129032258064e-05,
      "loss": 0.5996,
      "step": 392
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.135414257645607,
      "learning_rate": 7.483870967741936e-05,
      "loss": 0.5292,
      "step": 393
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.1768391728401184,
      "learning_rate": 7.451612903225807e-05,
      "loss": 0.5253,
      "step": 394
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.13922154903411865,
      "learning_rate": 7.419354838709677e-05,
      "loss": 0.6018,
      "step": 395
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.11736465245485306,
      "learning_rate": 7.387096774193549e-05,
      "loss": 0.4846,
      "step": 396
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.18134942650794983,
      "learning_rate": 7.35483870967742e-05,
      "loss": 0.498,
      "step": 397
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.16679443418979645,
      "learning_rate": 7.32258064516129e-05,
      "loss": 0.5377,
      "step": 398
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.1097637340426445,
      "learning_rate": 7.290322580645161e-05,
      "loss": 0.4428,
      "step": 399
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1929209679365158,
      "learning_rate": 7.258064516129033e-05,
      "loss": 0.4861,
      "step": 400
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.15041351318359375,
      "learning_rate": 7.225806451612904e-05,
      "loss": 0.5154,
      "step": 401
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.1471099704504013,
      "learning_rate": 7.193548387096774e-05,
      "loss": 0.5507,
      "step": 402
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.12420276552438736,
      "learning_rate": 7.161290322580646e-05,
      "loss": 0.467,
      "step": 403
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.1656889170408249,
      "learning_rate": 7.129032258064517e-05,
      "loss": 0.4847,
      "step": 404
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.1861678659915924,
      "learning_rate": 7.096774193548388e-05,
      "loss": 0.5539,
      "step": 405
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.14331945776939392,
      "learning_rate": 7.064516129032258e-05,
      "loss": 0.5238,
      "step": 406
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.1657908856868744,
      "learning_rate": 7.03225806451613e-05,
      "loss": 0.4975,
      "step": 407
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.1880418062210083,
      "learning_rate": 7e-05,
      "loss": 0.5255,
      "step": 408
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.21098510921001434,
      "learning_rate": 6.967741935483871e-05,
      "loss": 0.4979,
      "step": 409
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.10780645906925201,
      "learning_rate": 6.935483870967743e-05,
      "loss": 0.5412,
      "step": 410
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.13763727247714996,
      "learning_rate": 6.903225806451613e-05,
      "loss": 0.4014,
      "step": 411
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.1673937439918518,
      "learning_rate": 6.870967741935485e-05,
      "loss": 0.4684,
      "step": 412
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.15749049186706543,
      "learning_rate": 6.838709677419355e-05,
      "loss": 0.4697,
      "step": 413
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.16492998600006104,
      "learning_rate": 6.806451612903226e-05,
      "loss": 0.4445,
      "step": 414
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.1125369742512703,
      "learning_rate": 6.774193548387096e-05,
      "loss": 0.4682,
      "step": 415
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.15111762285232544,
      "learning_rate": 6.741935483870968e-05,
      "loss": 0.5138,
      "step": 416
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.1764736771583557,
      "learning_rate": 6.709677419354839e-05,
      "loss": 0.5064,
      "step": 417
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.11381307244300842,
      "learning_rate": 6.67741935483871e-05,
      "loss": 0.4673,
      "step": 418
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.10794217884540558,
      "learning_rate": 6.645161290322582e-05,
      "loss": 0.4806,
      "step": 419
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.11566586047410965,
      "learning_rate": 6.612903225806452e-05,
      "loss": 0.4948,
      "step": 420
    },
    {
      "epoch": 0.6736,
      "grad_norm": 0.15245601534843445,
      "learning_rate": 6.580645161290323e-05,
      "loss": 0.5071,
      "step": 421
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.11759835481643677,
      "learning_rate": 6.548387096774193e-05,
      "loss": 0.5007,
      "step": 422
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.12281366437673569,
      "learning_rate": 6.516129032258065e-05,
      "loss": 0.4684,
      "step": 423
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.14423918724060059,
      "learning_rate": 6.483870967741936e-05,
      "loss": 0.3819,
      "step": 424
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16215555369853973,
      "learning_rate": 6.451612903225807e-05,
      "loss": 0.5025,
      "step": 425
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.13440480828285217,
      "learning_rate": 6.419354838709679e-05,
      "loss": 0.5744,
      "step": 426
    },
    {
      "epoch": 0.6832,
      "grad_norm": 0.13854162395000458,
      "learning_rate": 6.387096774193548e-05,
      "loss": 0.5448,
      "step": 427
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.11486022174358368,
      "learning_rate": 6.35483870967742e-05,
      "loss": 0.4712,
      "step": 428
    },
    {
      "epoch": 0.6864,
      "grad_norm": 0.13865789771080017,
      "learning_rate": 6.32258064516129e-05,
      "loss": 0.5639,
      "step": 429
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.12989352643489838,
      "learning_rate": 6.290322580645161e-05,
      "loss": 0.5126,
      "step": 430
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.12721925973892212,
      "learning_rate": 6.258064516129033e-05,
      "loss": 0.5225,
      "step": 431
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.12494450807571411,
      "learning_rate": 6.225806451612904e-05,
      "loss": 0.4818,
      "step": 432
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.16719557344913483,
      "learning_rate": 6.193548387096774e-05,
      "loss": 0.5127,
      "step": 433
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.1206936240196228,
      "learning_rate": 6.161290322580645e-05,
      "loss": 0.5609,
      "step": 434
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.12526394426822662,
      "learning_rate": 6.129032258064517e-05,
      "loss": 0.5707,
      "step": 435
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.14468830823898315,
      "learning_rate": 6.096774193548387e-05,
      "loss": 0.5655,
      "step": 436
    },
    {
      "epoch": 0.6992,
      "grad_norm": 0.0961952656507492,
      "learning_rate": 6.064516129032258e-05,
      "loss": 0.4218,
      "step": 437
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.13118121027946472,
      "learning_rate": 6.0322580645161295e-05,
      "loss": 0.5568,
      "step": 438
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.11370903998613358,
      "learning_rate": 6e-05,
      "loss": 0.4861,
      "step": 439
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.11998188495635986,
      "learning_rate": 5.9677419354838715e-05,
      "loss": 0.5029,
      "step": 440
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.1672111600637436,
      "learning_rate": 5.935483870967742e-05,
      "loss": 0.5614,
      "step": 441
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.13851794600486755,
      "learning_rate": 5.9032258064516134e-05,
      "loss": 0.5896,
      "step": 442
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.12573407590389252,
      "learning_rate": 5.870967741935483e-05,
      "loss": 0.4949,
      "step": 443
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.13620634377002716,
      "learning_rate": 5.838709677419355e-05,
      "loss": 0.464,
      "step": 444
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.135532945394516,
      "learning_rate": 5.8064516129032266e-05,
      "loss": 0.4636,
      "step": 445
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.12588205933570862,
      "learning_rate": 5.7741935483870965e-05,
      "loss": 0.4749,
      "step": 446
    },
    {
      "epoch": 0.7152,
      "grad_norm": 0.11853652447462082,
      "learning_rate": 5.7419354838709685e-05,
      "loss": 0.4275,
      "step": 447
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.1209612786769867,
      "learning_rate": 5.7096774193548384e-05,
      "loss": 0.4622,
      "step": 448
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.1338224858045578,
      "learning_rate": 5.67741935483871e-05,
      "loss": 0.547,
      "step": 449
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.11625230312347412,
      "learning_rate": 5.645161290322582e-05,
      "loss": 0.4442,
      "step": 450
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.15246425569057465,
      "learning_rate": 5.612903225806452e-05,
      "loss": 0.5114,
      "step": 451
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.1020914614200592,
      "learning_rate": 5.580645161290323e-05,
      "loss": 0.4115,
      "step": 452
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.11810511350631714,
      "learning_rate": 5.5483870967741936e-05,
      "loss": 0.4771,
      "step": 453
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.12350338697433472,
      "learning_rate": 5.516129032258065e-05,
      "loss": 0.488,
      "step": 454
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.11868803948163986,
      "learning_rate": 5.4838709677419355e-05,
      "loss": 0.4867,
      "step": 455
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.11703111231327057,
      "learning_rate": 5.451612903225807e-05,
      "loss": 0.4937,
      "step": 456
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.1078174039721489,
      "learning_rate": 5.419354838709678e-05,
      "loss": 0.5253,
      "step": 457
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.10003415495157242,
      "learning_rate": 5.387096774193549e-05,
      "loss": 0.4795,
      "step": 458
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.15059791505336761,
      "learning_rate": 5.35483870967742e-05,
      "loss": 0.4747,
      "step": 459
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.15036706626415253,
      "learning_rate": 5.32258064516129e-05,
      "loss": 0.4661,
      "step": 460
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.11819734424352646,
      "learning_rate": 5.290322580645162e-05,
      "loss": 0.509,
      "step": 461
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.12909682095050812,
      "learning_rate": 5.258064516129032e-05,
      "loss": 0.4844,
      "step": 462
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.1184709221124649,
      "learning_rate": 5.225806451612903e-05,
      "loss": 0.4914,
      "step": 463
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.11601440608501434,
      "learning_rate": 5.193548387096775e-05,
      "loss": 0.5456,
      "step": 464
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.1501566618680954,
      "learning_rate": 5.161290322580645e-05,
      "loss": 0.4868,
      "step": 465
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.16121886670589447,
      "learning_rate": 5.1290322580645164e-05,
      "loss": 0.5363,
      "step": 466
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.12940843403339386,
      "learning_rate": 5.096774193548387e-05,
      "loss": 0.5032,
      "step": 467
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.1162746474146843,
      "learning_rate": 5.064516129032258e-05,
      "loss": 0.5521,
      "step": 468
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.14665019512176514,
      "learning_rate": 5.032258064516129e-05,
      "loss": 0.4742,
      "step": 469
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.14089007675647736,
      "learning_rate": 5e-05,
      "loss": 0.4661,
      "step": 470
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.13445736467838287,
      "learning_rate": 4.967741935483871e-05,
      "loss": 0.5187,
      "step": 471
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.08837293833494186,
      "learning_rate": 4.935483870967742e-05,
      "loss": 0.4711,
      "step": 472
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.13194797933101654,
      "learning_rate": 4.903225806451613e-05,
      "loss": 0.5326,
      "step": 473
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.11352519690990448,
      "learning_rate": 4.870967741935484e-05,
      "loss": 0.4695,
      "step": 474
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.14293378591537476,
      "learning_rate": 4.8387096774193554e-05,
      "loss": 0.504,
      "step": 475
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.10934018343687057,
      "learning_rate": 4.806451612903226e-05,
      "loss": 0.5328,
      "step": 476
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.0909418985247612,
      "learning_rate": 4.774193548387097e-05,
      "loss": 0.4049,
      "step": 477
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.11814633011817932,
      "learning_rate": 4.741935483870968e-05,
      "loss": 0.5303,
      "step": 478
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.14075814187526703,
      "learning_rate": 4.7096774193548385e-05,
      "loss": 0.4636,
      "step": 479
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.1095709279179573,
      "learning_rate": 4.67741935483871e-05,
      "loss": 0.491,
      "step": 480
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.12298545986413956,
      "learning_rate": 4.645161290322581e-05,
      "loss": 0.5075,
      "step": 481
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.1020185723900795,
      "learning_rate": 4.612903225806452e-05,
      "loss": 0.4753,
      "step": 482
    },
    {
      "epoch": 0.7728,
      "grad_norm": 0.12058515846729279,
      "learning_rate": 4.580645161290323e-05,
      "loss": 0.4528,
      "step": 483
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.12864641845226288,
      "learning_rate": 4.548387096774194e-05,
      "loss": 0.6192,
      "step": 484
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.13162243366241455,
      "learning_rate": 4.516129032258064e-05,
      "loss": 0.5332,
      "step": 485
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.11599523574113846,
      "learning_rate": 4.4838709677419356e-05,
      "loss": 0.5454,
      "step": 486
    },
    {
      "epoch": 0.7792,
      "grad_norm": 0.1346886307001114,
      "learning_rate": 4.451612903225807e-05,
      "loss": 0.466,
      "step": 487
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.11646979302167892,
      "learning_rate": 4.4193548387096775e-05,
      "loss": 0.4702,
      "step": 488
    },
    {
      "epoch": 0.7824,
      "grad_norm": 0.1401304453611374,
      "learning_rate": 4.387096774193549e-05,
      "loss": 0.4449,
      "step": 489
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.1331409513950348,
      "learning_rate": 4.3548387096774194e-05,
      "loss": 0.5404,
      "step": 490
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.10433800518512726,
      "learning_rate": 4.322580645161291e-05,
      "loss": 0.5,
      "step": 491
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.10411138087511063,
      "learning_rate": 4.2903225806451614e-05,
      "loss": 0.447,
      "step": 492
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.10238772630691528,
      "learning_rate": 4.258064516129032e-05,
      "loss": 0.4773,
      "step": 493
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.12057149410247803,
      "learning_rate": 4.225806451612904e-05,
      "loss": 0.5466,
      "step": 494
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.13875815272331238,
      "learning_rate": 4.1935483870967746e-05,
      "loss": 0.4489,
      "step": 495
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.10119827836751938,
      "learning_rate": 4.161290322580645e-05,
      "loss": 0.4783,
      "step": 496
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.11328665912151337,
      "learning_rate": 4.1290322580645165e-05,
      "loss": 0.4931,
      "step": 497
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.12406649440526962,
      "learning_rate": 4.096774193548387e-05,
      "loss": 0.5566,
      "step": 498
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.1658165007829666,
      "learning_rate": 4.0645161290322584e-05,
      "loss": 0.5766,
      "step": 499
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1180209144949913,
      "learning_rate": 4.032258064516129e-05,
      "loss": 0.5202,
      "step": 500
    },
    {
      "epoch": 0.8016,
      "grad_norm": 0.11168360710144043,
      "learning_rate": 4e-05,
      "loss": 0.5364,
      "step": 501
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.14995042979717255,
      "learning_rate": 3.9677419354838716e-05,
      "loss": 0.5086,
      "step": 502
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.1433500498533249,
      "learning_rate": 3.935483870967742e-05,
      "loss": 0.5541,
      "step": 503
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.10742013901472092,
      "learning_rate": 3.903225806451613e-05,
      "loss": 0.432,
      "step": 504
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.11874411255121231,
      "learning_rate": 3.870967741935484e-05,
      "loss": 0.4378,
      "step": 505
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.12931805849075317,
      "learning_rate": 3.838709677419355e-05,
      "loss": 0.5514,
      "step": 506
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.12473943084478378,
      "learning_rate": 3.8064516129032254e-05,
      "loss": 0.4842,
      "step": 507
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.10672459751367569,
      "learning_rate": 3.7741935483870974e-05,
      "loss": 0.5291,
      "step": 508
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.12148831784725189,
      "learning_rate": 3.741935483870968e-05,
      "loss": 0.5009,
      "step": 509
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.11591164767742157,
      "learning_rate": 3.7096774193548386e-05,
      "loss": 0.503,
      "step": 510
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.11390406638383865,
      "learning_rate": 3.67741935483871e-05,
      "loss": 0.5329,
      "step": 511
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.15573212504386902,
      "learning_rate": 3.6451612903225805e-05,
      "loss": 0.5431,
      "step": 512
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.09192755818367004,
      "learning_rate": 3.612903225806452e-05,
      "loss": 0.5032,
      "step": 513
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.12478247284889221,
      "learning_rate": 3.580645161290323e-05,
      "loss": 0.5668,
      "step": 514
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.12618955969810486,
      "learning_rate": 3.548387096774194e-05,
      "loss": 0.4652,
      "step": 515
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.12160178273916245,
      "learning_rate": 3.516129032258065e-05,
      "loss": 0.4959,
      "step": 516
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.11388536542654037,
      "learning_rate": 3.483870967741936e-05,
      "loss": 0.52,
      "step": 517
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.14963585138320923,
      "learning_rate": 3.451612903225806e-05,
      "loss": 0.5488,
      "step": 518
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.1379740983247757,
      "learning_rate": 3.4193548387096776e-05,
      "loss": 0.5091,
      "step": 519
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.10447047650814056,
      "learning_rate": 3.387096774193548e-05,
      "loss": 0.4456,
      "step": 520
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.16247032582759857,
      "learning_rate": 3.3548387096774195e-05,
      "loss": 0.4701,
      "step": 521
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.13843098282814026,
      "learning_rate": 3.322580645161291e-05,
      "loss": 0.5226,
      "step": 522
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.11905230581760406,
      "learning_rate": 3.2903225806451614e-05,
      "loss": 0.5064,
      "step": 523
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.12341505289077759,
      "learning_rate": 3.258064516129033e-05,
      "loss": 0.5556,
      "step": 524
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.11746707558631897,
      "learning_rate": 3.2258064516129034e-05,
      "loss": 0.5084,
      "step": 525
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.16541625559329987,
      "learning_rate": 3.193548387096774e-05,
      "loss": 0.4515,
      "step": 526
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.11268448829650879,
      "learning_rate": 3.161290322580645e-05,
      "loss": 0.4783,
      "step": 527
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.10688760131597519,
      "learning_rate": 3.1290322580645166e-05,
      "loss": 0.5225,
      "step": 528
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.12713971734046936,
      "learning_rate": 3.096774193548387e-05,
      "loss": 0.5286,
      "step": 529
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.09042996913194656,
      "learning_rate": 3.0645161290322585e-05,
      "loss": 0.4469,
      "step": 530
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.163661926984787,
      "learning_rate": 3.032258064516129e-05,
      "loss": 0.4952,
      "step": 531
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.1254921853542328,
      "learning_rate": 3e-05,
      "loss": 0.4607,
      "step": 532
    },
    {
      "epoch": 0.8528,
      "grad_norm": 0.10536745935678482,
      "learning_rate": 2.967741935483871e-05,
      "loss": 0.558,
      "step": 533
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.12266209721565247,
      "learning_rate": 2.9354838709677417e-05,
      "loss": 0.5627,
      "step": 534
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.10951351374387741,
      "learning_rate": 2.9032258064516133e-05,
      "loss": 0.5167,
      "step": 535
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.11019006371498108,
      "learning_rate": 2.8709677419354843e-05,
      "loss": 0.4969,
      "step": 536
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.11857645213603973,
      "learning_rate": 2.838709677419355e-05,
      "loss": 0.5884,
      "step": 537
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.12696652114391327,
      "learning_rate": 2.806451612903226e-05,
      "loss": 0.53,
      "step": 538
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.12618499994277954,
      "learning_rate": 2.7741935483870968e-05,
      "loss": 0.5009,
      "step": 539
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.13252879679203033,
      "learning_rate": 2.7419354838709678e-05,
      "loss": 0.4357,
      "step": 540
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.1287432461977005,
      "learning_rate": 2.709677419354839e-05,
      "loss": 0.4681,
      "step": 541
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.13530637323856354,
      "learning_rate": 2.67741935483871e-05,
      "loss": 0.4875,
      "step": 542
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.1183914989233017,
      "learning_rate": 2.645161290322581e-05,
      "loss": 0.4043,
      "step": 543
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.13888317346572876,
      "learning_rate": 2.6129032258064516e-05,
      "loss": 0.5439,
      "step": 544
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.11204303801059723,
      "learning_rate": 2.5806451612903226e-05,
      "loss": 0.4887,
      "step": 545
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.10420187562704086,
      "learning_rate": 2.5483870967741935e-05,
      "loss": 0.4463,
      "step": 546
    },
    {
      "epoch": 0.8752,
      "grad_norm": 0.10547197610139847,
      "learning_rate": 2.5161290322580645e-05,
      "loss": 0.492,
      "step": 547
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.10044481605291367,
      "learning_rate": 2.4838709677419354e-05,
      "loss": 0.5369,
      "step": 548
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.14709840714931488,
      "learning_rate": 2.4516129032258064e-05,
      "loss": 0.4854,
      "step": 549
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.11122401803731918,
      "learning_rate": 2.4193548387096777e-05,
      "loss": 0.519,
      "step": 550
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.15423861145973206,
      "learning_rate": 2.3870967741935486e-05,
      "loss": 0.5212,
      "step": 551
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.14135479927062988,
      "learning_rate": 2.3548387096774193e-05,
      "loss": 0.5602,
      "step": 552
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.11849634349346161,
      "learning_rate": 2.3225806451612906e-05,
      "loss": 0.4695,
      "step": 553
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.12038415670394897,
      "learning_rate": 2.2903225806451615e-05,
      "loss": 0.4601,
      "step": 554
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.13231056928634644,
      "learning_rate": 2.258064516129032e-05,
      "loss": 0.5427,
      "step": 555
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.16081742942333221,
      "learning_rate": 2.2258064516129034e-05,
      "loss": 0.5209,
      "step": 556
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.12370502203702927,
      "learning_rate": 2.1935483870967744e-05,
      "loss": 0.454,
      "step": 557
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.1426519751548767,
      "learning_rate": 2.1612903225806454e-05,
      "loss": 0.5299,
      "step": 558
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.12006449699401855,
      "learning_rate": 2.129032258064516e-05,
      "loss": 0.5389,
      "step": 559
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.11027411371469498,
      "learning_rate": 2.0967741935483873e-05,
      "loss": 0.5244,
      "step": 560
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.14103884994983673,
      "learning_rate": 2.0645161290322582e-05,
      "loss": 0.5282,
      "step": 561
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.10163993388414383,
      "learning_rate": 2.0322580645161292e-05,
      "loss": 0.4786,
      "step": 562
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.14876233041286469,
      "learning_rate": 2e-05,
      "loss": 0.6133,
      "step": 563
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.11107626557350159,
      "learning_rate": 1.967741935483871e-05,
      "loss": 0.5379,
      "step": 564
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.10548064112663269,
      "learning_rate": 1.935483870967742e-05,
      "loss": 0.537,
      "step": 565
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.146066814661026,
      "learning_rate": 1.9032258064516127e-05,
      "loss": 0.5612,
      "step": 566
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.12325894832611084,
      "learning_rate": 1.870967741935484e-05,
      "loss": 0.4836,
      "step": 567
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.11255428940057755,
      "learning_rate": 1.838709677419355e-05,
      "loss": 0.5109,
      "step": 568
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.11378731578588486,
      "learning_rate": 1.806451612903226e-05,
      "loss": 0.5417,
      "step": 569
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.12938524782657623,
      "learning_rate": 1.774193548387097e-05,
      "loss": 0.4697,
      "step": 570
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.10084366053342819,
      "learning_rate": 1.741935483870968e-05,
      "loss": 0.4505,
      "step": 571
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.1203698143362999,
      "learning_rate": 1.7096774193548388e-05,
      "loss": 0.4974,
      "step": 572
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.09783194959163666,
      "learning_rate": 1.6774193548387098e-05,
      "loss": 0.4928,
      "step": 573
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.10529863834381104,
      "learning_rate": 1.6451612903225807e-05,
      "loss": 0.4412,
      "step": 574
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.10229147970676422,
      "learning_rate": 1.6129032258064517e-05,
      "loss": 0.4891,
      "step": 575
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.15403689444065094,
      "learning_rate": 1.5806451612903226e-05,
      "loss": 0.4745,
      "step": 576
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.1075698584318161,
      "learning_rate": 1.5483870967741936e-05,
      "loss": 0.4136,
      "step": 577
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.11291953176259995,
      "learning_rate": 1.5161290322580646e-05,
      "loss": 0.49,
      "step": 578
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.10634955018758774,
      "learning_rate": 1.4838709677419355e-05,
      "loss": 0.4796,
      "step": 579
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.15875357389450073,
      "learning_rate": 1.4516129032258066e-05,
      "loss": 0.5657,
      "step": 580
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.11874790489673615,
      "learning_rate": 1.4193548387096774e-05,
      "loss": 0.4918,
      "step": 581
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.12360362708568573,
      "learning_rate": 1.3870967741935484e-05,
      "loss": 0.4227,
      "step": 582
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.11116944253444672,
      "learning_rate": 1.3548387096774195e-05,
      "loss": 0.4549,
      "step": 583
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.10907237976789474,
      "learning_rate": 1.3225806451612905e-05,
      "loss": 0.5026,
      "step": 584
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.09876689314842224,
      "learning_rate": 1.2903225806451613e-05,
      "loss": 0.4355,
      "step": 585
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.11230368912220001,
      "learning_rate": 1.2580645161290322e-05,
      "loss": 0.5137,
      "step": 586
    },
    {
      "epoch": 0.9392,
      "grad_norm": 0.10124143213033676,
      "learning_rate": 1.2258064516129032e-05,
      "loss": 0.5016,
      "step": 587
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.11038053780794144,
      "learning_rate": 1.1935483870967743e-05,
      "loss": 0.5035,
      "step": 588
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.09446398913860321,
      "learning_rate": 1.1612903225806453e-05,
      "loss": 0.4997,
      "step": 589
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.12367942184209824,
      "learning_rate": 1.129032258064516e-05,
      "loss": 0.4288,
      "step": 590
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.11383063346147537,
      "learning_rate": 1.0967741935483872e-05,
      "loss": 0.5884,
      "step": 591
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.10542073845863342,
      "learning_rate": 1.064516129032258e-05,
      "loss": 0.5356,
      "step": 592
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.1164909154176712,
      "learning_rate": 1.0322580645161291e-05,
      "loss": 0.5468,
      "step": 593
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.12321844696998596,
      "learning_rate": 1e-05,
      "loss": 0.4887,
      "step": 594
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.13073323667049408,
      "learning_rate": 9.67741935483871e-06,
      "loss": 0.5491,
      "step": 595
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.11380518972873688,
      "learning_rate": 9.35483870967742e-06,
      "loss": 0.4966,
      "step": 596
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.11925575882196426,
      "learning_rate": 9.03225806451613e-06,
      "loss": 0.5169,
      "step": 597
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.1206803247332573,
      "learning_rate": 8.70967741935484e-06,
      "loss": 0.5707,
      "step": 598
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.11509264260530472,
      "learning_rate": 8.387096774193549e-06,
      "loss": 0.4009,
      "step": 599
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1066136285662651,
      "learning_rate": 8.064516129032258e-06,
      "loss": 0.4962,
      "step": 600
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.12976092100143433,
      "learning_rate": 7.741935483870968e-06,
      "loss": 0.5419,
      "step": 601
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.09988882392644882,
      "learning_rate": 7.419354838709678e-06,
      "loss": 0.4734,
      "step": 602
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.12926629185676575,
      "learning_rate": 7.096774193548387e-06,
      "loss": 0.5254,
      "step": 603
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.15131981670856476,
      "learning_rate": 6.774193548387098e-06,
      "loss": 0.5585,
      "step": 604
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.10251925140619278,
      "learning_rate": 6.451612903225806e-06,
      "loss": 0.503,
      "step": 605
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.11789629608392715,
      "learning_rate": 6.129032258064516e-06,
      "loss": 0.5428,
      "step": 606
    },
    {
      "epoch": 0.9712,
      "grad_norm": 0.09990023821592331,
      "learning_rate": 5.806451612903226e-06,
      "loss": 0.5272,
      "step": 607
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.11015291512012482,
      "learning_rate": 5.483870967741936e-06,
      "loss": 0.4305,
      "step": 608
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.09321267157793045,
      "learning_rate": 5.161290322580646e-06,
      "loss": 0.4959,
      "step": 609
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.08933094143867493,
      "learning_rate": 4.838709677419355e-06,
      "loss": 0.495,
      "step": 610
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.11869105696678162,
      "learning_rate": 4.516129032258065e-06,
      "loss": 0.5096,
      "step": 611
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.18349042534828186,
      "learning_rate": 4.193548387096774e-06,
      "loss": 0.5208,
      "step": 612
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.12059921026229858,
      "learning_rate": 3.870967741935484e-06,
      "loss": 0.4949,
      "step": 613
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.10860711336135864,
      "learning_rate": 3.5483870967741936e-06,
      "loss": 0.5026,
      "step": 614
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.10410104691982269,
      "learning_rate": 3.225806451612903e-06,
      "loss": 0.488,
      "step": 615
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.11877468228340149,
      "learning_rate": 2.903225806451613e-06,
      "loss": 0.487,
      "step": 616
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.09924232214689255,
      "learning_rate": 2.580645161290323e-06,
      "loss": 0.4504,
      "step": 617
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.1179489716887474,
      "learning_rate": 2.2580645161290324e-06,
      "loss": 0.5684,
      "step": 618
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.1073368713259697,
      "learning_rate": 1.935483870967742e-06,
      "loss": 0.5712,
      "step": 619
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.11468098312616348,
      "learning_rate": 1.6129032258064516e-06,
      "loss": 0.5245,
      "step": 620
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.09223446249961853,
      "learning_rate": 1.2903225806451614e-06,
      "loss": 0.4796,
      "step": 621
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.1089564710855484,
      "learning_rate": 9.67741935483871e-07,
      "loss": 0.4616,
      "step": 622
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.11383774131536484,
      "learning_rate": 6.451612903225807e-07,
      "loss": 0.5467,
      "step": 623
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.09984805434942245,
      "learning_rate": 3.2258064516129035e-07,
      "loss": 0.5451,
      "step": 624
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09531625360250473,
      "learning_rate": 0.0,
      "loss": 0.4948,
      "step": 625
    }
  ],
  "logging_steps": 1,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.131065426032984e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
