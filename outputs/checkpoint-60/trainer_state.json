{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0531326101394731,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008855435023245517,
      "grad_norm": 0.7509117126464844,
      "learning_rate": 4e-05,
      "loss": 2.3254,
      "step": 1
    },
    {
      "epoch": 0.0017710870046491033,
      "grad_norm": 0.5306025147438049,
      "learning_rate": 8e-05,
      "loss": 1.4306,
      "step": 2
    },
    {
      "epoch": 0.002656630506973655,
      "grad_norm": 0.5943707823753357,
      "learning_rate": 0.00012,
      "loss": 1.6796,
      "step": 3
    },
    {
      "epoch": 0.0035421740092982067,
      "grad_norm": 0.8043237924575806,
      "learning_rate": 0.00016,
      "loss": 1.8539,
      "step": 4
    },
    {
      "epoch": 0.004427717511622758,
      "grad_norm": 0.822300910949707,
      "learning_rate": 0.0002,
      "loss": 1.7575,
      "step": 5
    },
    {
      "epoch": 0.00531326101394731,
      "grad_norm": 0.5646992921829224,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.4691,
      "step": 6
    },
    {
      "epoch": 0.006198804516271862,
      "grad_norm": 0.7016412019729614,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.1469,
      "step": 7
    },
    {
      "epoch": 0.007084348018596413,
      "grad_norm": 0.6996845602989197,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.6726,
      "step": 8
    },
    {
      "epoch": 0.007969891520920966,
      "grad_norm": 0.6906856298446655,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.7181,
      "step": 9
    },
    {
      "epoch": 0.008855435023245517,
      "grad_norm": 0.687568187713623,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.3788,
      "step": 10
    },
    {
      "epoch": 0.00974097852557007,
      "grad_norm": 0.6599600911140442,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.5102,
      "step": 11
    },
    {
      "epoch": 0.01062652202789462,
      "grad_norm": 0.6023598313331604,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.3707,
      "step": 12
    },
    {
      "epoch": 0.011512065530219173,
      "grad_norm": 0.5438995361328125,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.7434,
      "step": 13
    },
    {
      "epoch": 0.012397609032543723,
      "grad_norm": 0.5091120004653931,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.6533,
      "step": 14
    },
    {
      "epoch": 0.013283152534868276,
      "grad_norm": 0.3594362437725067,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.279,
      "step": 15
    },
    {
      "epoch": 0.014168696037192827,
      "grad_norm": 0.24928198754787445,
      "learning_rate": 0.00016,
      "loss": 1.1839,
      "step": 16
    },
    {
      "epoch": 0.01505423953951738,
      "grad_norm": 0.36622899770736694,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.0428,
      "step": 17
    },
    {
      "epoch": 0.01593978304184193,
      "grad_norm": 0.3478200435638428,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.0753,
      "step": 18
    },
    {
      "epoch": 0.01682532654416648,
      "grad_norm": 0.5941367149353027,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.2947,
      "step": 19
    },
    {
      "epoch": 0.017710870046491033,
      "grad_norm": 0.45233452320098877,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.5783,
      "step": 20
    },
    {
      "epoch": 0.018596413548815586,
      "grad_norm": 0.48396825790405273,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.3342,
      "step": 21
    },
    {
      "epoch": 0.01948195705114014,
      "grad_norm": 0.4410005807876587,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.2264,
      "step": 22
    },
    {
      "epoch": 0.020367500553464687,
      "grad_norm": 0.5144936442375183,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.4644,
      "step": 23
    },
    {
      "epoch": 0.02125304405578924,
      "grad_norm": 0.31184321641921997,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.9931,
      "step": 24
    },
    {
      "epoch": 0.022138587558113793,
      "grad_norm": 0.4835028648376465,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.2797,
      "step": 25
    },
    {
      "epoch": 0.023024131060438345,
      "grad_norm": 0.36348670721054077,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.3721,
      "step": 26
    },
    {
      "epoch": 0.023909674562762894,
      "grad_norm": 0.30299729108810425,
      "learning_rate": 0.00012,
      "loss": 1.2467,
      "step": 27
    },
    {
      "epoch": 0.024795218065087447,
      "grad_norm": 0.36764803528785706,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.3017,
      "step": 28
    },
    {
      "epoch": 0.025680761567412,
      "grad_norm": 0.3464679718017578,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.3417,
      "step": 29
    },
    {
      "epoch": 0.02656630506973655,
      "grad_norm": 0.41516879200935364,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.3176,
      "step": 30
    },
    {
      "epoch": 0.0274518485720611,
      "grad_norm": 0.37646543979644775,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.4835,
      "step": 31
    },
    {
      "epoch": 0.028337392074385653,
      "grad_norm": 0.4694315493106842,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.4224,
      "step": 32
    },
    {
      "epoch": 0.029222935576710206,
      "grad_norm": 0.32980525493621826,
      "learning_rate": 9.818181818181818e-05,
      "loss": 1.1497,
      "step": 33
    },
    {
      "epoch": 0.03010847907903476,
      "grad_norm": 0.4402368366718292,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.5921,
      "step": 34
    },
    {
      "epoch": 0.03099402258135931,
      "grad_norm": 0.29644834995269775,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.4951,
      "step": 35
    },
    {
      "epoch": 0.03187956608368386,
      "grad_norm": 0.33046385645866394,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.3356,
      "step": 36
    },
    {
      "epoch": 0.032765109586008416,
      "grad_norm": 0.388113409280777,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.1197,
      "step": 37
    },
    {
      "epoch": 0.03365065308833296,
      "grad_norm": 0.2524200677871704,
      "learning_rate": 8e-05,
      "loss": 1.3032,
      "step": 38
    },
    {
      "epoch": 0.034536196590657514,
      "grad_norm": 0.41555485129356384,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.4991,
      "step": 39
    },
    {
      "epoch": 0.03542174009298207,
      "grad_norm": 0.25714170932769775,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.4002,
      "step": 40
    },
    {
      "epoch": 0.03630728359530662,
      "grad_norm": 0.3498622179031372,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.2637,
      "step": 41
    },
    {
      "epoch": 0.03719282709763117,
      "grad_norm": 0.3357851803302765,
      "learning_rate": 6.545454545454546e-05,
      "loss": 1.2804,
      "step": 42
    },
    {
      "epoch": 0.038078370599955724,
      "grad_norm": 0.40339982509613037,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.5684,
      "step": 43
    },
    {
      "epoch": 0.03896391410228028,
      "grad_norm": 0.34290841221809387,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.4125,
      "step": 44
    },
    {
      "epoch": 0.03984945760460483,
      "grad_norm": 0.4271998107433319,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.4176,
      "step": 45
    },
    {
      "epoch": 0.040735001106929375,
      "grad_norm": 0.28239768743515015,
      "learning_rate": 5.090909090909091e-05,
      "loss": 1.4215,
      "step": 46
    },
    {
      "epoch": 0.04162054460925393,
      "grad_norm": 0.4169674813747406,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.4537,
      "step": 47
    },
    {
      "epoch": 0.04250608811157848,
      "grad_norm": 0.31932732462882996,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.4217,
      "step": 48
    },
    {
      "epoch": 0.04339163161390303,
      "grad_norm": 1.291681170463562,
      "learning_rate": 4e-05,
      "loss": 1.8322,
      "step": 49
    },
    {
      "epoch": 0.044277175116227585,
      "grad_norm": 0.35362446308135986,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.5158,
      "step": 50
    },
    {
      "epoch": 0.04516271861855214,
      "grad_norm": 0.4582468569278717,
      "learning_rate": 3.272727272727273e-05,
      "loss": 1.623,
      "step": 51
    },
    {
      "epoch": 0.04604826212087669,
      "grad_norm": 0.26392659544944763,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.3761,
      "step": 52
    },
    {
      "epoch": 0.04693380562320124,
      "grad_norm": 0.3544425666332245,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.2225,
      "step": 53
    },
    {
      "epoch": 0.04781934912552579,
      "grad_norm": 0.5326765775680542,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.5122,
      "step": 54
    },
    {
      "epoch": 0.04870489262785034,
      "grad_norm": 0.3649826645851135,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.084,
      "step": 55
    },
    {
      "epoch": 0.04959043613017489,
      "grad_norm": 0.3071243166923523,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.5742,
      "step": 56
    },
    {
      "epoch": 0.050475979632499446,
      "grad_norm": 0.30486786365509033,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.3567,
      "step": 57
    },
    {
      "epoch": 0.051361523134824,
      "grad_norm": 0.39517080783843994,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.5923,
      "step": 58
    },
    {
      "epoch": 0.05224706663714855,
      "grad_norm": 0.39812371134757996,
      "learning_rate": 3.636363636363636e-06,
      "loss": 1.2717,
      "step": 59
    },
    {
      "epoch": 0.0531326101394731,
      "grad_norm": 0.3511030375957489,
      "learning_rate": 0.0,
      "loss": 1.1829,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1405973610266624e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
