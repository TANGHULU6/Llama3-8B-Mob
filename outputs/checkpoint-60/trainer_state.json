{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0531326101394731,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008855435023245517,
      "grad_norm": 0.7508887648582458,
      "learning_rate": 4e-05,
      "loss": 2.3254,
      "step": 1
    },
    {
      "epoch": 0.0017710870046491033,
      "grad_norm": 0.5305446982383728,
      "learning_rate": 8e-05,
      "loss": 1.4306,
      "step": 2
    },
    {
      "epoch": 0.002656630506973655,
      "grad_norm": 0.5941690802574158,
      "learning_rate": 0.00012,
      "loss": 1.6795,
      "step": 3
    },
    {
      "epoch": 0.0035421740092982067,
      "grad_norm": 0.7814445495605469,
      "learning_rate": 0.00016,
      "loss": 1.8567,
      "step": 4
    },
    {
      "epoch": 0.004427717511622758,
      "grad_norm": 0.8204377889633179,
      "learning_rate": 0.0002,
      "loss": 1.7577,
      "step": 5
    },
    {
      "epoch": 0.00531326101394731,
      "grad_norm": 0.5642648935317993,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.4684,
      "step": 6
    },
    {
      "epoch": 0.006198804516271862,
      "grad_norm": 0.6997227668762207,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.1466,
      "step": 7
    },
    {
      "epoch": 0.007084348018596413,
      "grad_norm": 0.6998892426490784,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.6724,
      "step": 8
    },
    {
      "epoch": 0.007969891520920966,
      "grad_norm": 0.6872819066047668,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.719,
      "step": 9
    },
    {
      "epoch": 0.008855435023245517,
      "grad_norm": 0.6895749568939209,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.3795,
      "step": 10
    },
    {
      "epoch": 0.00974097852557007,
      "grad_norm": 0.6569601893424988,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.5102,
      "step": 11
    },
    {
      "epoch": 0.01062652202789462,
      "grad_norm": 0.601222574710846,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.3709,
      "step": 12
    },
    {
      "epoch": 0.011512065530219173,
      "grad_norm": 0.5431746244430542,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.7428,
      "step": 13
    },
    {
      "epoch": 0.012397609032543723,
      "grad_norm": 0.5098942518234253,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.6534,
      "step": 14
    },
    {
      "epoch": 0.013283152534868276,
      "grad_norm": 0.3581394851207733,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.2795,
      "step": 15
    },
    {
      "epoch": 0.014168696037192827,
      "grad_norm": 0.2492896020412445,
      "learning_rate": 0.00016,
      "loss": 1.1839,
      "step": 16
    },
    {
      "epoch": 0.01505423953951738,
      "grad_norm": 0.3661647140979767,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.0427,
      "step": 17
    },
    {
      "epoch": 0.01593978304184193,
      "grad_norm": 0.3479061722755432,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.0757,
      "step": 18
    },
    {
      "epoch": 0.01682532654416648,
      "grad_norm": 0.5674017071723938,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.2944,
      "step": 19
    },
    {
      "epoch": 0.017710870046491033,
      "grad_norm": 0.45227617025375366,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.5772,
      "step": 20
    },
    {
      "epoch": 0.018596413548815586,
      "grad_norm": 0.4850015640258789,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.3351,
      "step": 21
    },
    {
      "epoch": 0.01948195705114014,
      "grad_norm": 0.4396405518054962,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.2248,
      "step": 22
    },
    {
      "epoch": 0.020367500553464687,
      "grad_norm": 0.5142112970352173,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.4628,
      "step": 23
    },
    {
      "epoch": 0.02125304405578924,
      "grad_norm": 0.3131125271320343,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.9936,
      "step": 24
    },
    {
      "epoch": 0.022138587558113793,
      "grad_norm": 0.48141205310821533,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.2805,
      "step": 25
    },
    {
      "epoch": 0.023024131060438345,
      "grad_norm": 0.3637988865375519,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.3712,
      "step": 26
    },
    {
      "epoch": 0.023909674562762894,
      "grad_norm": 0.3040979206562042,
      "learning_rate": 0.00012,
      "loss": 1.2466,
      "step": 27
    },
    {
      "epoch": 0.024795218065087447,
      "grad_norm": 0.3686829209327698,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.3017,
      "step": 28
    },
    {
      "epoch": 0.025680761567412,
      "grad_norm": 0.30889415740966797,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.3413,
      "step": 29
    },
    {
      "epoch": 0.02656630506973655,
      "grad_norm": 0.41525015234947205,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.3182,
      "step": 30
    },
    {
      "epoch": 0.0274518485720611,
      "grad_norm": 0.376594603061676,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.483,
      "step": 31
    },
    {
      "epoch": 0.028337392074385653,
      "grad_norm": 0.4687453508377075,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.4207,
      "step": 32
    },
    {
      "epoch": 0.029222935576710206,
      "grad_norm": 0.33051204681396484,
      "learning_rate": 9.818181818181818e-05,
      "loss": 1.1501,
      "step": 33
    },
    {
      "epoch": 0.03010847907903476,
      "grad_norm": 0.442424476146698,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.593,
      "step": 34
    },
    {
      "epoch": 0.03099402258135931,
      "grad_norm": 0.29391154646873474,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.4941,
      "step": 35
    },
    {
      "epoch": 0.03187956608368386,
      "grad_norm": 0.32881370186805725,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.3347,
      "step": 36
    },
    {
      "epoch": 0.032765109586008416,
      "grad_norm": 0.38920602202415466,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.1198,
      "step": 37
    },
    {
      "epoch": 0.03365065308833296,
      "grad_norm": 0.2524585425853729,
      "learning_rate": 8e-05,
      "loss": 1.303,
      "step": 38
    },
    {
      "epoch": 0.034536196590657514,
      "grad_norm": 0.4151575565338135,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.4982,
      "step": 39
    },
    {
      "epoch": 0.03542174009298207,
      "grad_norm": 0.25756821036338806,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.4008,
      "step": 40
    },
    {
      "epoch": 0.03630728359530662,
      "grad_norm": 0.3522781431674957,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.2643,
      "step": 41
    },
    {
      "epoch": 0.03719282709763117,
      "grad_norm": 0.33587247133255005,
      "learning_rate": 6.545454545454546e-05,
      "loss": 1.28,
      "step": 42
    },
    {
      "epoch": 0.038078370599955724,
      "grad_norm": 0.3996308445930481,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.5688,
      "step": 43
    },
    {
      "epoch": 0.03896391410228028,
      "grad_norm": 0.34269949793815613,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.4122,
      "step": 44
    },
    {
      "epoch": 0.03984945760460483,
      "grad_norm": 0.42890340089797974,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.4172,
      "step": 45
    },
    {
      "epoch": 0.040735001106929375,
      "grad_norm": 0.28263816237449646,
      "learning_rate": 5.090909090909091e-05,
      "loss": 1.4224,
      "step": 46
    },
    {
      "epoch": 0.04162054460925393,
      "grad_norm": 0.41740682721138,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.4545,
      "step": 47
    },
    {
      "epoch": 0.04250608811157848,
      "grad_norm": 0.3025653660297394,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.4209,
      "step": 48
    },
    {
      "epoch": 0.04339163161390303,
      "grad_norm": 1.2997461557388306,
      "learning_rate": 4e-05,
      "loss": 1.8326,
      "step": 49
    },
    {
      "epoch": 0.044277175116227585,
      "grad_norm": 0.3535081446170807,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.5165,
      "step": 50
    },
    {
      "epoch": 0.04516271861855214,
      "grad_norm": 0.4678780138492584,
      "learning_rate": 3.272727272727273e-05,
      "loss": 1.6229,
      "step": 51
    },
    {
      "epoch": 0.04604826212087669,
      "grad_norm": 0.26309797167778015,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.3762,
      "step": 52
    },
    {
      "epoch": 0.04693380562320124,
      "grad_norm": 0.3562150001525879,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.2231,
      "step": 53
    },
    {
      "epoch": 0.04781934912552579,
      "grad_norm": 0.5312833786010742,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.5111,
      "step": 54
    },
    {
      "epoch": 0.04870489262785034,
      "grad_norm": 0.3650701642036438,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.0829,
      "step": 55
    },
    {
      "epoch": 0.04959043613017489,
      "grad_norm": 0.3076566159725189,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.5737,
      "step": 56
    },
    {
      "epoch": 0.050475979632499446,
      "grad_norm": 0.3053981363773346,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.3568,
      "step": 57
    },
    {
      "epoch": 0.051361523134824,
      "grad_norm": 0.39818787574768066,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.5934,
      "step": 58
    },
    {
      "epoch": 0.05224706663714855,
      "grad_norm": 0.3971233069896698,
      "learning_rate": 3.636363636363636e-06,
      "loss": 1.2702,
      "step": 59
    },
    {
      "epoch": 0.0531326101394731,
      "grad_norm": 0.3576112985610962,
      "learning_rate": 0.0,
      "loss": 1.1829,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1405973610266624e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
