{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 2.9621710777282715,
      "learning_rate": 4e-05,
      "loss": 2.6207,
      "step": 1
    },
    {
      "epoch": 0.008,
      "grad_norm": 2.784510374069214,
      "learning_rate": 8e-05,
      "loss": 2.7078,
      "step": 2
    },
    {
      "epoch": 0.012,
      "grad_norm": 2.3291518688201904,
      "learning_rate": 0.00012,
      "loss": 2.6704,
      "step": 3
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.4346833229064941,
      "learning_rate": 0.00016,
      "loss": 2.5532,
      "step": 4
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.7566723823547363,
      "learning_rate": 0.0002,
      "loss": 2.4075,
      "step": 5
    },
    {
      "epoch": 0.024,
      "grad_norm": 1.7133734226226807,
      "learning_rate": 0.00019918367346938775,
      "loss": 2.4614,
      "step": 6
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.7718696594238281,
      "learning_rate": 0.00019836734693877553,
      "loss": 2.2039,
      "step": 7
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.5088943243026733,
      "learning_rate": 0.00019755102040816327,
      "loss": 2.0966,
      "step": 8
    },
    {
      "epoch": 0.036,
      "grad_norm": 1.1518433094024658,
      "learning_rate": 0.00019673469387755104,
      "loss": 1.8115,
      "step": 9
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4429471492767334,
      "learning_rate": 0.0001959183673469388,
      "loss": 1.9797,
      "step": 10
    },
    {
      "epoch": 0.044,
      "grad_norm": 1.7510969638824463,
      "learning_rate": 0.00019510204081632656,
      "loss": 1.8092,
      "step": 11
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.0219520330429077,
      "learning_rate": 0.0001942857142857143,
      "loss": 1.8609,
      "step": 12
    },
    {
      "epoch": 0.052,
      "grad_norm": 1.2776376008987427,
      "learning_rate": 0.00019346938775510205,
      "loss": 1.6841,
      "step": 13
    },
    {
      "epoch": 0.056,
      "grad_norm": 1.1247386932373047,
      "learning_rate": 0.0001926530612244898,
      "loss": 1.6921,
      "step": 14
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9311235547065735,
      "learning_rate": 0.00019183673469387756,
      "loss": 1.6725,
      "step": 15
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.063733458518982,
      "learning_rate": 0.0001910204081632653,
      "loss": 1.3648,
      "step": 16
    },
    {
      "epoch": 0.068,
      "grad_norm": 1.5641720294952393,
      "learning_rate": 0.00019020408163265305,
      "loss": 1.5323,
      "step": 17
    },
    {
      "epoch": 0.072,
      "grad_norm": 2.304107904434204,
      "learning_rate": 0.00018938775510204083,
      "loss": 1.7106,
      "step": 18
    },
    {
      "epoch": 0.076,
      "grad_norm": 1.384399175643921,
      "learning_rate": 0.00018857142857142857,
      "loss": 1.5229,
      "step": 19
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8804804682731628,
      "learning_rate": 0.00018775510204081634,
      "loss": 1.3833,
      "step": 20
    },
    {
      "epoch": 0.084,
      "grad_norm": 1.0198079347610474,
      "learning_rate": 0.0001869387755102041,
      "loss": 1.2651,
      "step": 21
    },
    {
      "epoch": 0.088,
      "grad_norm": 1.1569938659667969,
      "learning_rate": 0.00018612244897959183,
      "loss": 1.2895,
      "step": 22
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.9339337348937988,
      "learning_rate": 0.0001853061224489796,
      "loss": 1.0782,
      "step": 23
    },
    {
      "epoch": 0.096,
      "grad_norm": 1.3290239572525024,
      "learning_rate": 0.00018448979591836735,
      "loss": 1.1846,
      "step": 24
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5696837902069092,
      "learning_rate": 0.00018367346938775512,
      "loss": 1.0558,
      "step": 25
    },
    {
      "epoch": 0.104,
      "grad_norm": 2.2045342922210693,
      "learning_rate": 0.00018285714285714286,
      "loss": 0.9755,
      "step": 26
    },
    {
      "epoch": 0.108,
      "grad_norm": 9.233430862426758,
      "learning_rate": 0.00018204081632653064,
      "loss": 0.9756,
      "step": 27
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.9709423780441284,
      "learning_rate": 0.00018122448979591838,
      "loss": 0.873,
      "step": 28
    },
    {
      "epoch": 0.116,
      "grad_norm": 4.386170387268066,
      "learning_rate": 0.00018040816326530615,
      "loss": 0.9013,
      "step": 29
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.167600631713867,
      "learning_rate": 0.0001795918367346939,
      "loss": 1.0192,
      "step": 30
    },
    {
      "epoch": 0.124,
      "grad_norm": 1.3439100980758667,
      "learning_rate": 0.00017877551020408164,
      "loss": 0.863,
      "step": 31
    },
    {
      "epoch": 0.128,
      "grad_norm": 1.1930443048477173,
      "learning_rate": 0.0001779591836734694,
      "loss": 0.9463,
      "step": 32
    },
    {
      "epoch": 0.132,
      "grad_norm": 1.0466184616088867,
      "learning_rate": 0.00017714285714285713,
      "loss": 0.6836,
      "step": 33
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.5478016138076782,
      "learning_rate": 0.0001763265306122449,
      "loss": 0.7283,
      "step": 34
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7554062008857727,
      "learning_rate": 0.00017551020408163265,
      "loss": 0.7223,
      "step": 35
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.45694664120674133,
      "learning_rate": 0.00017469387755102042,
      "loss": 0.7259,
      "step": 36
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.5719794631004333,
      "learning_rate": 0.00017387755102040816,
      "loss": 0.7127,
      "step": 37
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.3964031934738159,
      "learning_rate": 0.00017306122448979594,
      "loss": 0.702,
      "step": 38
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.6590054035186768,
      "learning_rate": 0.00017224489795918368,
      "loss": 0.6612,
      "step": 39
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3334213197231293,
      "learning_rate": 0.00017142857142857143,
      "loss": 0.5334,
      "step": 40
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.4305734634399414,
      "learning_rate": 0.0001706122448979592,
      "loss": 0.5222,
      "step": 41
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.4013313055038452,
      "learning_rate": 0.00016979591836734694,
      "loss": 0.7067,
      "step": 42
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.40305575728416443,
      "learning_rate": 0.0001689795918367347,
      "loss": 0.6144,
      "step": 43
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.3314030170440674,
      "learning_rate": 0.00016816326530612246,
      "loss": 0.5835,
      "step": 44
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2879536747932434,
      "learning_rate": 0.00016734693877551023,
      "loss": 0.5502,
      "step": 45
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.31086206436157227,
      "learning_rate": 0.00016653061224489797,
      "loss": 0.6222,
      "step": 46
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.2710076868534088,
      "learning_rate": 0.00016571428571428575,
      "loss": 0.6553,
      "step": 47
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.2553877830505371,
      "learning_rate": 0.0001648979591836735,
      "loss": 0.5019,
      "step": 48
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.2515336275100708,
      "learning_rate": 0.00016408163265306124,
      "loss": 0.6052,
      "step": 49
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2524055540561676,
      "learning_rate": 0.00016326530612244898,
      "loss": 0.5674,
      "step": 50
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.20210613310337067,
      "learning_rate": 0.00016244897959183672,
      "loss": 0.618,
      "step": 51
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.19436779618263245,
      "learning_rate": 0.0001616326530612245,
      "loss": 0.544,
      "step": 52
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.29824426770210266,
      "learning_rate": 0.00016081632653061224,
      "loss": 0.5797,
      "step": 53
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.2065683752298355,
      "learning_rate": 0.00016,
      "loss": 0.5592,
      "step": 54
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.27934351563453674,
      "learning_rate": 0.00015918367346938776,
      "loss": 0.6895,
      "step": 55
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.25678732991218567,
      "learning_rate": 0.0001583673469387755,
      "loss": 0.6417,
      "step": 56
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.22281119227409363,
      "learning_rate": 0.00015755102040816327,
      "loss": 0.5118,
      "step": 57
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.2919963598251343,
      "learning_rate": 0.00015673469387755102,
      "loss": 0.5499,
      "step": 58
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.30260658264160156,
      "learning_rate": 0.0001559183673469388,
      "loss": 0.6554,
      "step": 59
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.13473159074783325,
      "learning_rate": 0.00015510204081632654,
      "loss": 0.5723,
      "step": 60
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.37858033180236816,
      "learning_rate": 0.0001542857142857143,
      "loss": 0.6304,
      "step": 61
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.3170276880264282,
      "learning_rate": 0.00015346938775510205,
      "loss": 0.5919,
      "step": 62
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.17649459838867188,
      "learning_rate": 0.00015265306122448982,
      "loss": 0.5343,
      "step": 63
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.30324262380599976,
      "learning_rate": 0.00015183673469387757,
      "loss": 0.5836,
      "step": 64
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.34907227754592896,
      "learning_rate": 0.0001510204081632653,
      "loss": 0.5957,
      "step": 65
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.21065303683280945,
      "learning_rate": 0.00015020408163265306,
      "loss": 0.506,
      "step": 66
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.26487165689468384,
      "learning_rate": 0.00014938775510204083,
      "loss": 0.5896,
      "step": 67
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.299774169921875,
      "learning_rate": 0.00014857142857142857,
      "loss": 0.5897,
      "step": 68
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.17000852525234222,
      "learning_rate": 0.00014775510204081632,
      "loss": 0.5025,
      "step": 69
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.19270920753479004,
      "learning_rate": 0.0001469387755102041,
      "loss": 0.5477,
      "step": 70
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.2046457678079605,
      "learning_rate": 0.00014612244897959183,
      "loss": 0.5778,
      "step": 71
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.40398260951042175,
      "learning_rate": 0.0001453061224489796,
      "loss": 0.5361,
      "step": 72
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.19856426119804382,
      "learning_rate": 0.00014448979591836735,
      "loss": 0.6017,
      "step": 73
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.2116246074438095,
      "learning_rate": 0.0001436734693877551,
      "loss": 0.5523,
      "step": 74
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19902274012565613,
      "learning_rate": 0.00014285714285714287,
      "loss": 0.4897,
      "step": 75
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.1972149759531021,
      "learning_rate": 0.0001420408163265306,
      "loss": 0.4518,
      "step": 76
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.17956916987895966,
      "learning_rate": 0.00014122448979591838,
      "loss": 0.5191,
      "step": 77
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.1833687722682953,
      "learning_rate": 0.00014040816326530613,
      "loss": 0.5828,
      "step": 78
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.1845296025276184,
      "learning_rate": 0.0001395918367346939,
      "loss": 0.5186,
      "step": 79
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.154215469956398,
      "learning_rate": 0.00013877551020408165,
      "loss": 0.5751,
      "step": 80
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.15732625126838684,
      "learning_rate": 0.00013795918367346942,
      "loss": 0.6059,
      "step": 81
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.12062186747789383,
      "learning_rate": 0.00013714285714285716,
      "loss": 0.4736,
      "step": 82
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.15603168308734894,
      "learning_rate": 0.0001363265306122449,
      "loss": 0.5667,
      "step": 83
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.16260381042957306,
      "learning_rate": 0.00013551020408163265,
      "loss": 0.5685,
      "step": 84
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17676235735416412,
      "learning_rate": 0.0001346938775510204,
      "loss": 0.587,
      "step": 85
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.1846715211868286,
      "learning_rate": 0.00013387755102040817,
      "loss": 0.5651,
      "step": 86
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.17045247554779053,
      "learning_rate": 0.0001330612244897959,
      "loss": 0.4749,
      "step": 87
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.18064674735069275,
      "learning_rate": 0.00013224489795918368,
      "loss": 0.549,
      "step": 88
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.1662144660949707,
      "learning_rate": 0.00013142857142857143,
      "loss": 0.5202,
      "step": 89
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.19337685406208038,
      "learning_rate": 0.00013061224489795917,
      "loss": 0.627,
      "step": 90
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.21019504964351654,
      "learning_rate": 0.00012979591836734695,
      "loss": 0.6519,
      "step": 91
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.19239161908626556,
      "learning_rate": 0.0001289795918367347,
      "loss": 0.5242,
      "step": 92
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.20806077122688293,
      "learning_rate": 0.00012816326530612246,
      "loss": 0.6072,
      "step": 93
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.13067655265331268,
      "learning_rate": 0.0001273469387755102,
      "loss": 0.5854,
      "step": 94
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.18837910890579224,
      "learning_rate": 0.00012653061224489798,
      "loss": 0.5423,
      "step": 95
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.19928577542304993,
      "learning_rate": 0.00012571428571428572,
      "loss": 0.5767,
      "step": 96
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.186803936958313,
      "learning_rate": 0.0001248979591836735,
      "loss": 0.5492,
      "step": 97
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.1655290722846985,
      "learning_rate": 0.00012408163265306124,
      "loss": 0.5566,
      "step": 98
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.17198671400547028,
      "learning_rate": 0.00012326530612244898,
      "loss": 0.5432,
      "step": 99
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.15453237295150757,
      "learning_rate": 0.00012244897959183676,
      "loss": 0.5094,
      "step": 100
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.19134452939033508,
      "learning_rate": 0.00012163265306122449,
      "loss": 0.5757,
      "step": 101
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.16652777791023254,
      "learning_rate": 0.00012081632653061226,
      "loss": 0.5664,
      "step": 102
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.19841526448726654,
      "learning_rate": 0.00012,
      "loss": 0.4504,
      "step": 103
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.18285982310771942,
      "learning_rate": 0.00011918367346938777,
      "loss": 0.583,
      "step": 104
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17122147977352142,
      "learning_rate": 0.00011836734693877552,
      "loss": 0.5349,
      "step": 105
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.23629921674728394,
      "learning_rate": 0.00011755102040816328,
      "loss": 0.548,
      "step": 106
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.15151111781597137,
      "learning_rate": 0.00011673469387755102,
      "loss": 0.5469,
      "step": 107
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.14936323463916779,
      "learning_rate": 0.00011591836734693877,
      "loss": 0.5557,
      "step": 108
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.2397521287202835,
      "learning_rate": 0.00011510204081632654,
      "loss": 0.5436,
      "step": 109
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1541062891483307,
      "learning_rate": 0.00011428571428571428,
      "loss": 0.511,
      "step": 110
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.1689310073852539,
      "learning_rate": 0.00011346938775510206,
      "loss": 0.5209,
      "step": 111
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.15553398430347443,
      "learning_rate": 0.0001126530612244898,
      "loss": 0.5565,
      "step": 112
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.1216348260641098,
      "learning_rate": 0.00011183673469387757,
      "loss": 0.5071,
      "step": 113
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.1813047230243683,
      "learning_rate": 0.00011102040816326532,
      "loss": 0.5466,
      "step": 114
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.22529879212379456,
      "learning_rate": 0.00011020408163265306,
      "loss": 0.5309,
      "step": 115
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.2240447700023651,
      "learning_rate": 0.00010938775510204082,
      "loss": 0.5252,
      "step": 116
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.13667145371437073,
      "learning_rate": 0.00010857142857142856,
      "loss": 0.5522,
      "step": 117
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.15867795050144196,
      "learning_rate": 0.00010775510204081634,
      "loss": 0.5027,
      "step": 118
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.14938035607337952,
      "learning_rate": 0.00010693877551020408,
      "loss": 0.547,
      "step": 119
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.23404386639595032,
      "learning_rate": 0.00010612244897959185,
      "loss": 0.598,
      "step": 120
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.16778364777565002,
      "learning_rate": 0.0001053061224489796,
      "loss": 0.6291,
      "step": 121
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.12547670304775238,
      "learning_rate": 0.00010448979591836735,
      "loss": 0.5202,
      "step": 122
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.13975374400615692,
      "learning_rate": 0.00010367346938775511,
      "loss": 0.5123,
      "step": 123
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.1538020223379135,
      "learning_rate": 0.00010285714285714286,
      "loss": 0.4902,
      "step": 124
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.12595690786838531,
      "learning_rate": 0.00010204081632653062,
      "loss": 0.4921,
      "step": 125
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.12131989747285843,
      "learning_rate": 0.00010122448979591836,
      "loss": 0.5394,
      "step": 126
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.13208357989788055,
      "learning_rate": 0.00010040816326530613,
      "loss": 0.486,
      "step": 127
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.10497912764549255,
      "learning_rate": 9.959183673469388e-05,
      "loss": 0.4921,
      "step": 128
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.14280778169631958,
      "learning_rate": 9.877551020408164e-05,
      "loss": 0.4986,
      "step": 129
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1321089267730713,
      "learning_rate": 9.79591836734694e-05,
      "loss": 0.5877,
      "step": 130
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.12530410289764404,
      "learning_rate": 9.714285714285715e-05,
      "loss": 0.555,
      "step": 131
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.14723238348960876,
      "learning_rate": 9.63265306122449e-05,
      "loss": 0.4357,
      "step": 132
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.1152358427643776,
      "learning_rate": 9.551020408163265e-05,
      "loss": 0.5739,
      "step": 133
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.16410396993160248,
      "learning_rate": 9.469387755102041e-05,
      "loss": 0.5392,
      "step": 134
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1684027463197708,
      "learning_rate": 9.387755102040817e-05,
      "loss": 0.6152,
      "step": 135
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.17114311456680298,
      "learning_rate": 9.306122448979592e-05,
      "loss": 0.5845,
      "step": 136
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.16417516767978668,
      "learning_rate": 9.224489795918367e-05,
      "loss": 0.5725,
      "step": 137
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.1602385938167572,
      "learning_rate": 9.142857142857143e-05,
      "loss": 0.4881,
      "step": 138
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.148494690656662,
      "learning_rate": 9.061224489795919e-05,
      "loss": 0.6028,
      "step": 139
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.13454748690128326,
      "learning_rate": 8.979591836734695e-05,
      "loss": 0.4924,
      "step": 140
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.21175049245357513,
      "learning_rate": 8.89795918367347e-05,
      "loss": 0.5612,
      "step": 141
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.1352429986000061,
      "learning_rate": 8.816326530612245e-05,
      "loss": 0.5617,
      "step": 142
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.16280819475650787,
      "learning_rate": 8.734693877551021e-05,
      "loss": 0.556,
      "step": 143
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.1538180708885193,
      "learning_rate": 8.653061224489797e-05,
      "loss": 0.5182,
      "step": 144
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1413004845380783,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.5595,
      "step": 145
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.17218388617038727,
      "learning_rate": 8.489795918367347e-05,
      "loss": 0.5212,
      "step": 146
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.14050185680389404,
      "learning_rate": 8.408163265306123e-05,
      "loss": 0.4657,
      "step": 147
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.15367837250232697,
      "learning_rate": 8.326530612244899e-05,
      "loss": 0.5596,
      "step": 148
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.1322610229253769,
      "learning_rate": 8.244897959183675e-05,
      "loss": 0.583,
      "step": 149
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.18040025234222412,
      "learning_rate": 8.163265306122449e-05,
      "loss": 0.5456,
      "step": 150
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.15796060860157013,
      "learning_rate": 8.081632653061225e-05,
      "loss": 0.5376,
      "step": 151
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.1814972460269928,
      "learning_rate": 8e-05,
      "loss": 0.5841,
      "step": 152
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.19735296070575714,
      "learning_rate": 7.918367346938775e-05,
      "loss": 0.561,
      "step": 153
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.1410239040851593,
      "learning_rate": 7.836734693877551e-05,
      "loss": 0.4839,
      "step": 154
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.12432261556386948,
      "learning_rate": 7.755102040816327e-05,
      "loss": 0.5191,
      "step": 155
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.12248356640338898,
      "learning_rate": 7.673469387755103e-05,
      "loss": 0.529,
      "step": 156
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.17768234014511108,
      "learning_rate": 7.591836734693878e-05,
      "loss": 0.5982,
      "step": 157
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.1417219638824463,
      "learning_rate": 7.510204081632653e-05,
      "loss": 0.4427,
      "step": 158
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.16070011258125305,
      "learning_rate": 7.428571428571429e-05,
      "loss": 0.5567,
      "step": 159
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15185412764549255,
      "learning_rate": 7.346938775510205e-05,
      "loss": 0.5791,
      "step": 160
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.1446957290172577,
      "learning_rate": 7.26530612244898e-05,
      "loss": 0.4938,
      "step": 161
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.17135287821292877,
      "learning_rate": 7.183673469387755e-05,
      "loss": 0.5148,
      "step": 162
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.14700454473495483,
      "learning_rate": 7.10204081632653e-05,
      "loss": 0.4963,
      "step": 163
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.15246860682964325,
      "learning_rate": 7.020408163265306e-05,
      "loss": 0.5,
      "step": 164
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.20133183896541595,
      "learning_rate": 6.938775510204082e-05,
      "loss": 0.4769,
      "step": 165
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.1451103687286377,
      "learning_rate": 6.857142857142858e-05,
      "loss": 0.5755,
      "step": 166
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.27973905205726624,
      "learning_rate": 6.775510204081633e-05,
      "loss": 0.5603,
      "step": 167
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.1960405558347702,
      "learning_rate": 6.693877551020408e-05,
      "loss": 0.4974,
      "step": 168
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.19538722932338715,
      "learning_rate": 6.612244897959184e-05,
      "loss": 0.5361,
      "step": 169
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.19423578679561615,
      "learning_rate": 6.530612244897959e-05,
      "loss": 0.4983,
      "step": 170
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.24552413821220398,
      "learning_rate": 6.448979591836734e-05,
      "loss": 0.5841,
      "step": 171
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.17402523756027222,
      "learning_rate": 6.36734693877551e-05,
      "loss": 0.5226,
      "step": 172
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.22275696694850922,
      "learning_rate": 6.285714285714286e-05,
      "loss": 0.5029,
      "step": 173
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.2607288956642151,
      "learning_rate": 6.204081632653062e-05,
      "loss": 0.5014,
      "step": 174
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.19854478538036346,
      "learning_rate": 6.122448979591838e-05,
      "loss": 0.6098,
      "step": 175
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.1783953458070755,
      "learning_rate": 6.040816326530613e-05,
      "loss": 0.5456,
      "step": 176
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.17014309763908386,
      "learning_rate": 5.959183673469389e-05,
      "loss": 0.5299,
      "step": 177
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.19326822459697723,
      "learning_rate": 5.877551020408164e-05,
      "loss": 0.5097,
      "step": 178
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.18071933090686798,
      "learning_rate": 5.7959183673469384e-05,
      "loss": 0.5277,
      "step": 179
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.18989744782447815,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.5098,
      "step": 180
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.15000763535499573,
      "learning_rate": 5.63265306122449e-05,
      "loss": 0.502,
      "step": 181
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.1506514549255371,
      "learning_rate": 5.551020408163266e-05,
      "loss": 0.4979,
      "step": 182
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.22601044178009033,
      "learning_rate": 5.469387755102041e-05,
      "loss": 0.5084,
      "step": 183
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.19352127611637115,
      "learning_rate": 5.387755102040817e-05,
      "loss": 0.5773,
      "step": 184
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.14853709936141968,
      "learning_rate": 5.3061224489795926e-05,
      "loss": 0.6123,
      "step": 185
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.142411470413208,
      "learning_rate": 5.224489795918368e-05,
      "loss": 0.5629,
      "step": 186
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.18823742866516113,
      "learning_rate": 5.142857142857143e-05,
      "loss": 0.49,
      "step": 187
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.1545192301273346,
      "learning_rate": 5.061224489795918e-05,
      "loss": 0.4651,
      "step": 188
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.22688791155815125,
      "learning_rate": 4.979591836734694e-05,
      "loss": 0.4662,
      "step": 189
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.12840348482131958,
      "learning_rate": 4.89795918367347e-05,
      "loss": 0.5321,
      "step": 190
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.1679680198431015,
      "learning_rate": 4.816326530612245e-05,
      "loss": 0.4765,
      "step": 191
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.11645446717739105,
      "learning_rate": 4.7346938775510206e-05,
      "loss": 0.533,
      "step": 192
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.14847545325756073,
      "learning_rate": 4.653061224489796e-05,
      "loss": 0.5614,
      "step": 193
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.14323154091835022,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.5526,
      "step": 194
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.16476702690124512,
      "learning_rate": 4.4897959183673474e-05,
      "loss": 0.5538,
      "step": 195
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.12969085574150085,
      "learning_rate": 4.4081632653061226e-05,
      "loss": 0.5853,
      "step": 196
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.13394314050674438,
      "learning_rate": 4.3265306122448984e-05,
      "loss": 0.5906,
      "step": 197
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.1914542317390442,
      "learning_rate": 4.2448979591836735e-05,
      "loss": 0.57,
      "step": 198
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.13293485343456268,
      "learning_rate": 4.1632653061224494e-05,
      "loss": 0.4584,
      "step": 199
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1497708261013031,
      "learning_rate": 4.0816326530612245e-05,
      "loss": 0.4793,
      "step": 200
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.20566768944263458,
      "learning_rate": 4e-05,
      "loss": 0.5999,
      "step": 201
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.12084594368934631,
      "learning_rate": 3.9183673469387755e-05,
      "loss": 0.5632,
      "step": 202
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.13470152020454407,
      "learning_rate": 3.836734693877551e-05,
      "loss": 0.523,
      "step": 203
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.1584005504846573,
      "learning_rate": 3.7551020408163264e-05,
      "loss": 0.453,
      "step": 204
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1385882943868637,
      "learning_rate": 3.673469387755102e-05,
      "loss": 0.5309,
      "step": 205
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.1535787433385849,
      "learning_rate": 3.5918367346938774e-05,
      "loss": 0.5597,
      "step": 206
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.10618137568235397,
      "learning_rate": 3.510204081632653e-05,
      "loss": 0.4624,
      "step": 207
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.13100551068782806,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.4789,
      "step": 208
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.14277102053165436,
      "learning_rate": 3.346938775510204e-05,
      "loss": 0.499,
      "step": 209
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.15851964056491852,
      "learning_rate": 3.265306122448979e-05,
      "loss": 0.5333,
      "step": 210
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.13119788467884064,
      "learning_rate": 3.183673469387755e-05,
      "loss": 0.4903,
      "step": 211
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.14315055310726166,
      "learning_rate": 3.102040816326531e-05,
      "loss": 0.5211,
      "step": 212
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.17950916290283203,
      "learning_rate": 3.0204081632653065e-05,
      "loss": 0.544,
      "step": 213
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.0981040820479393,
      "learning_rate": 2.938775510204082e-05,
      "loss": 0.4733,
      "step": 214
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.14878152310848236,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.5253,
      "step": 215
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.1614283323287964,
      "learning_rate": 2.775510204081633e-05,
      "loss": 0.5106,
      "step": 216
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.14351291954517365,
      "learning_rate": 2.6938775510204084e-05,
      "loss": 0.443,
      "step": 217
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.22676117718219757,
      "learning_rate": 2.612244897959184e-05,
      "loss": 0.523,
      "step": 218
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.15666018426418304,
      "learning_rate": 2.530612244897959e-05,
      "loss": 0.5015,
      "step": 219
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.1319330334663391,
      "learning_rate": 2.448979591836735e-05,
      "loss": 0.5327,
      "step": 220
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.13404284417629242,
      "learning_rate": 2.3673469387755103e-05,
      "loss": 0.5201,
      "step": 221
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.14331693947315216,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 0.4968,
      "step": 222
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.23863404989242554,
      "learning_rate": 2.2040816326530613e-05,
      "loss": 0.4611,
      "step": 223
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.16000059247016907,
      "learning_rate": 2.1224489795918368e-05,
      "loss": 0.45,
      "step": 224
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.13332541286945343,
      "learning_rate": 2.0408163265306123e-05,
      "loss": 0.5485,
      "step": 225
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.1573212593793869,
      "learning_rate": 1.9591836734693877e-05,
      "loss": 0.6009,
      "step": 226
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.14402717351913452,
      "learning_rate": 1.8775510204081632e-05,
      "loss": 0.5746,
      "step": 227
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.1592620462179184,
      "learning_rate": 1.7959183673469387e-05,
      "loss": 0.5014,
      "step": 228
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.174628347158432,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.5397,
      "step": 229
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.12855564057826996,
      "learning_rate": 1.6326530612244897e-05,
      "loss": 0.5204,
      "step": 230
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.11141321808099747,
      "learning_rate": 1.5510204081632655e-05,
      "loss": 0.53,
      "step": 231
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.11307206749916077,
      "learning_rate": 1.469387755102041e-05,
      "loss": 0.5224,
      "step": 232
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.13600462675094604,
      "learning_rate": 1.3877551020408165e-05,
      "loss": 0.544,
      "step": 233
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.17537671327590942,
      "learning_rate": 1.306122448979592e-05,
      "loss": 0.5537,
      "step": 234
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.1446647197008133,
      "learning_rate": 1.2244897959183674e-05,
      "loss": 0.5498,
      "step": 235
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.1561524122953415,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.6002,
      "step": 236
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.11400886625051498,
      "learning_rate": 1.0612244897959184e-05,
      "loss": 0.5549,
      "step": 237
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.14577701687812805,
      "learning_rate": 9.795918367346939e-06,
      "loss": 0.5059,
      "step": 238
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.15130911767482758,
      "learning_rate": 8.979591836734694e-06,
      "loss": 0.4849,
      "step": 239
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1417975127696991,
      "learning_rate": 8.163265306122448e-06,
      "loss": 0.5055,
      "step": 240
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.1204877644777298,
      "learning_rate": 7.346938775510205e-06,
      "loss": 0.5516,
      "step": 241
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.13108858466148376,
      "learning_rate": 6.53061224489796e-06,
      "loss": 0.4789,
      "step": 242
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.15150001645088196,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.5077,
      "step": 243
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.09686842560768127,
      "learning_rate": 4.897959183673469e-06,
      "loss": 0.4985,
      "step": 244
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.12303848564624786,
      "learning_rate": 4.081632653061224e-06,
      "loss": 0.4985,
      "step": 245
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.11443424969911575,
      "learning_rate": 3.26530612244898e-06,
      "loss": 0.5019,
      "step": 246
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.12060347944498062,
      "learning_rate": 2.4489795918367347e-06,
      "loss": 0.5192,
      "step": 247
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.11389115452766418,
      "learning_rate": 1.63265306122449e-06,
      "loss": 0.4652,
      "step": 248
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.11887200176715851,
      "learning_rate": 8.16326530612245e-07,
      "loss": 0.5382,
      "step": 249
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.16381104290485382,
      "learning_rate": 0.0,
      "loss": 0.5556,
      "step": 250
    }
  ],
  "logging_steps": 1,
  "max_steps": 250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.418848504929321e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
