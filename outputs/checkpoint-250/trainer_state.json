{
  "best_metric": 0.3614474833011627,
  "best_model_checkpoint": "outputs/checkpoint-250",
  "epoch": 1.0,
  "eval_steps": 5,
  "global_step": 250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.15029749274253845,
      "learning_rate": 4e-05,
      "loss": 0.3536,
      "step": 1
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.17527855932712555,
      "learning_rate": 8e-05,
      "loss": 0.3606,
      "step": 2
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.11360716074705124,
      "learning_rate": 0.00012,
      "loss": 0.3844,
      "step": 3
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.1512840986251831,
      "learning_rate": 0.00016,
      "loss": 0.449,
      "step": 4
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.08557017892599106,
      "learning_rate": 0.0002,
      "loss": 0.3461,
      "step": 5
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.37408676743507385,
      "eval_runtime": 221.5671,
      "eval_samples_per_second": 0.451,
      "eval_steps_per_second": 0.451,
      "step": 5
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.11981623619794846,
      "learning_rate": 0.00019918367346938775,
      "loss": 0.3706,
      "step": 6
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.1250215619802475,
      "learning_rate": 0.00019836734693877553,
      "loss": 0.3851,
      "step": 7
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.12097093462944031,
      "learning_rate": 0.00019755102040816327,
      "loss": 0.4175,
      "step": 8
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.11585056036710739,
      "learning_rate": 0.00019673469387755104,
      "loss": 0.3603,
      "step": 9
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.08880738914012909,
      "learning_rate": 0.0001959183673469388,
      "loss": 0.3052,
      "step": 10
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.37383994460105896,
      "eval_runtime": 221.4618,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 10
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.07437461614608765,
      "learning_rate": 0.00019510204081632656,
      "loss": 0.3608,
      "step": 11
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.10242331773042679,
      "learning_rate": 0.0001942857142857143,
      "loss": 0.3891,
      "step": 12
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.08976824581623077,
      "learning_rate": 0.00019346938775510205,
      "loss": 0.3919,
      "step": 13
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.0872730165719986,
      "learning_rate": 0.0001926530612244898,
      "loss": 0.3844,
      "step": 14
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.08226362615823746,
      "learning_rate": 0.00019183673469387756,
      "loss": 0.334,
      "step": 15
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.37332722544670105,
      "eval_runtime": 221.4898,
      "eval_samples_per_second": 0.451,
      "eval_steps_per_second": 0.451,
      "step": 15
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.09965924918651581,
      "learning_rate": 0.0001910204081632653,
      "loss": 0.3912,
      "step": 16
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.0676131471991539,
      "learning_rate": 0.00019020408163265305,
      "loss": 0.313,
      "step": 17
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.09704477339982986,
      "learning_rate": 0.00018938775510204083,
      "loss": 0.3565,
      "step": 18
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.06698425114154816,
      "learning_rate": 0.00018857142857142857,
      "loss": 0.3014,
      "step": 19
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.07074932754039764,
      "learning_rate": 0.00018775510204081634,
      "loss": 0.3718,
      "step": 20
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.37281718850135803,
      "eval_runtime": 221.375,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 20
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.08171388506889343,
      "learning_rate": 0.0001869387755102041,
      "loss": 0.3449,
      "step": 21
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.1055772602558136,
      "learning_rate": 0.00018612244897959183,
      "loss": 0.3598,
      "step": 22
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.08661850541830063,
      "learning_rate": 0.0001853061224489796,
      "loss": 0.3927,
      "step": 23
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.24731925129890442,
      "learning_rate": 0.00018448979591836735,
      "loss": 0.3752,
      "step": 24
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.09664341062307358,
      "learning_rate": 0.00018367346938775512,
      "loss": 0.2776,
      "step": 25
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.37525370717048645,
      "eval_runtime": 221.4262,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 25
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.10224995762109756,
      "learning_rate": 0.00018285714285714286,
      "loss": 0.3807,
      "step": 26
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.08381960541009903,
      "learning_rate": 0.00018204081632653064,
      "loss": 0.3555,
      "step": 27
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.07225001603364944,
      "learning_rate": 0.00018122448979591838,
      "loss": 0.3575,
      "step": 28
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.09829168766736984,
      "learning_rate": 0.00018040816326530615,
      "loss": 0.3988,
      "step": 29
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.07873652130365372,
      "learning_rate": 0.0001795918367346939,
      "loss": 0.3915,
      "step": 30
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.371017724275589,
      "eval_runtime": 221.4297,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 30
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.060006383806467056,
      "learning_rate": 0.00017877551020408164,
      "loss": 0.3637,
      "step": 31
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.0708240270614624,
      "learning_rate": 0.0001779591836734694,
      "loss": 0.2931,
      "step": 32
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.08088655769824982,
      "learning_rate": 0.00017714285714285713,
      "loss": 0.407,
      "step": 33
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.07089661061763763,
      "learning_rate": 0.0001763265306122449,
      "loss": 0.3793,
      "step": 34
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.05096549913287163,
      "learning_rate": 0.00017551020408163265,
      "loss": 0.289,
      "step": 35
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.37058499455451965,
      "eval_runtime": 221.4606,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 35
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.06619149446487427,
      "learning_rate": 0.00017469387755102042,
      "loss": 0.36,
      "step": 36
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.08023375272750854,
      "learning_rate": 0.00017387755102040816,
      "loss": 0.4192,
      "step": 37
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.05929666757583618,
      "learning_rate": 0.00017306122448979594,
      "loss": 0.2938,
      "step": 38
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.05861495062708855,
      "learning_rate": 0.00017224489795918368,
      "loss": 0.2935,
      "step": 39
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.07037623971700668,
      "learning_rate": 0.00017142857142857143,
      "loss": 0.3249,
      "step": 40
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.3697337806224823,
      "eval_runtime": 221.2796,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 40
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.0641288086771965,
      "learning_rate": 0.0001706122448979592,
      "loss": 0.3601,
      "step": 41
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.0513642318546772,
      "learning_rate": 0.00016979591836734694,
      "loss": 0.2893,
      "step": 42
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.06433547288179398,
      "learning_rate": 0.0001689795918367347,
      "loss": 0.2863,
      "step": 43
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.07794234901666641,
      "learning_rate": 0.00016816326530612246,
      "loss": 0.3554,
      "step": 44
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.06361737102270126,
      "learning_rate": 0.00016734693877551023,
      "loss": 0.3327,
      "step": 45
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.3702550530433655,
      "eval_runtime": 221.4758,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 45
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.08682455867528915,
      "learning_rate": 0.00016653061224489797,
      "loss": 0.37,
      "step": 46
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.09717550873756409,
      "learning_rate": 0.00016571428571428575,
      "loss": 0.431,
      "step": 47
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.06567001342773438,
      "learning_rate": 0.0001648979591836735,
      "loss": 0.4287,
      "step": 48
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.07162940502166748,
      "learning_rate": 0.00016408163265306124,
      "loss": 0.341,
      "step": 49
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.0697123259305954,
      "learning_rate": 0.00016326530612244898,
      "loss": 0.4404,
      "step": 50
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.36918050050735474,
      "eval_runtime": 221.4711,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 50
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.06805318593978882,
      "learning_rate": 0.00016244897959183672,
      "loss": 0.3484,
      "step": 51
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.0796143114566803,
      "learning_rate": 0.0001616326530612245,
      "loss": 0.4211,
      "step": 52
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.08909761160612106,
      "learning_rate": 0.00016081632653061224,
      "loss": 0.473,
      "step": 53
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.06277821958065033,
      "learning_rate": 0.00016,
      "loss": 0.3498,
      "step": 54
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.06833081692457199,
      "learning_rate": 0.00015918367346938776,
      "loss": 0.3849,
      "step": 55
    },
    {
      "epoch": 0.22,
      "eval_loss": 0.36862295866012573,
      "eval_runtime": 221.3995,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 55
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.06960602849721909,
      "learning_rate": 0.0001583673469387755,
      "loss": 0.3081,
      "step": 56
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.06581421196460724,
      "learning_rate": 0.00015755102040816327,
      "loss": 0.4393,
      "step": 57
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.05791709944605827,
      "learning_rate": 0.00015673469387755102,
      "loss": 0.3286,
      "step": 58
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.06630980968475342,
      "learning_rate": 0.0001559183673469388,
      "loss": 0.429,
      "step": 59
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.07690613716840744,
      "learning_rate": 0.00015510204081632654,
      "loss": 0.4098,
      "step": 60
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.36860108375549316,
      "eval_runtime": 221.3113,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 60
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.06129663065075874,
      "learning_rate": 0.0001542857142857143,
      "loss": 0.3002,
      "step": 61
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.08013589680194855,
      "learning_rate": 0.00015346938775510205,
      "loss": 0.3638,
      "step": 62
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.07025833427906036,
      "learning_rate": 0.00015265306122448982,
      "loss": 0.2912,
      "step": 63
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.06753062456846237,
      "learning_rate": 0.00015183673469387757,
      "loss": 0.3704,
      "step": 64
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.06735356897115707,
      "learning_rate": 0.0001510204081632653,
      "loss": 0.3572,
      "step": 65
    },
    {
      "epoch": 0.26,
      "eval_loss": 0.3687366247177124,
      "eval_runtime": 221.3445,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 65
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.07958364486694336,
      "learning_rate": 0.00015020408163265306,
      "loss": 0.3508,
      "step": 66
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.06820222735404968,
      "learning_rate": 0.00014938775510204083,
      "loss": 0.3973,
      "step": 67
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.06562843918800354,
      "learning_rate": 0.00014857142857142857,
      "loss": 0.3634,
      "step": 68
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.06151695176959038,
      "learning_rate": 0.00014775510204081632,
      "loss": 0.3872,
      "step": 69
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.06065370514988899,
      "learning_rate": 0.0001469387755102041,
      "loss": 0.3045,
      "step": 70
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.3683089017868042,
      "eval_runtime": 221.3556,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 70
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.055108945816755295,
      "learning_rate": 0.00014612244897959183,
      "loss": 0.2537,
      "step": 71
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.06727864593267441,
      "learning_rate": 0.0001453061224489796,
      "loss": 0.3174,
      "step": 72
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.058242522180080414,
      "learning_rate": 0.00014448979591836735,
      "loss": 0.3198,
      "step": 73
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.049856044352054596,
      "learning_rate": 0.0001436734693877551,
      "loss": 0.2849,
      "step": 74
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.056385595351457596,
      "learning_rate": 0.00014285714285714287,
      "loss": 0.3736,
      "step": 75
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.3678550720214844,
      "eval_runtime": 220.6521,
      "eval_samples_per_second": 0.453,
      "eval_steps_per_second": 0.453,
      "step": 75
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.048642344772815704,
      "learning_rate": 0.0001420408163265306,
      "loss": 0.2857,
      "step": 76
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.06744807213544846,
      "learning_rate": 0.00014122448979591838,
      "loss": 0.3764,
      "step": 77
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.08616463094949722,
      "learning_rate": 0.00014040816326530613,
      "loss": 0.3852,
      "step": 78
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.05231812968850136,
      "learning_rate": 0.0001395918367346939,
      "loss": 0.3102,
      "step": 79
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.069923996925354,
      "learning_rate": 0.00013877551020408165,
      "loss": 0.405,
      "step": 80
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.3674377202987671,
      "eval_runtime": 221.3648,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 80
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.06949347257614136,
      "learning_rate": 0.00013795918367346942,
      "loss": 0.3379,
      "step": 81
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.0722949430346489,
      "learning_rate": 0.00013714285714285716,
      "loss": 0.3875,
      "step": 82
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.06563323736190796,
      "learning_rate": 0.0001363265306122449,
      "loss": 0.4021,
      "step": 83
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.055254627019166946,
      "learning_rate": 0.00013551020408163265,
      "loss": 0.3235,
      "step": 84
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.06223336607217789,
      "learning_rate": 0.0001346938775510204,
      "loss": 0.3157,
      "step": 85
    },
    {
      "epoch": 0.34,
      "eval_loss": 0.36738258600234985,
      "eval_runtime": 221.4253,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 85
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.06321141868829727,
      "learning_rate": 0.00013387755102040817,
      "loss": 0.3498,
      "step": 86
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.07739663124084473,
      "learning_rate": 0.0001330612244897959,
      "loss": 0.4174,
      "step": 87
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.07329824566841125,
      "learning_rate": 0.00013224489795918368,
      "loss": 0.4285,
      "step": 88
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.06045933812856674,
      "learning_rate": 0.00013142857142857143,
      "loss": 0.3637,
      "step": 89
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.07334692031145096,
      "learning_rate": 0.00013061224489795917,
      "loss": 0.4009,
      "step": 90
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.3667878210544586,
      "eval_runtime": 221.3371,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 90
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.061087410897016525,
      "learning_rate": 0.00012979591836734695,
      "loss": 0.302,
      "step": 91
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.07656548172235489,
      "learning_rate": 0.0001289795918367347,
      "loss": 0.3917,
      "step": 92
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.06877073645591736,
      "learning_rate": 0.00012816326530612246,
      "loss": 0.3829,
      "step": 93
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.05346803739666939,
      "learning_rate": 0.0001273469387755102,
      "loss": 0.3254,
      "step": 94
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.05414804443717003,
      "learning_rate": 0.00012653061224489798,
      "loss": 0.367,
      "step": 95
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.3669804632663727,
      "eval_runtime": 221.4192,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 95
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.0578141063451767,
      "learning_rate": 0.00012571428571428572,
      "loss": 0.3406,
      "step": 96
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.09108977764844894,
      "learning_rate": 0.0001248979591836735,
      "loss": 0.4418,
      "step": 97
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.07011277228593826,
      "learning_rate": 0.00012408163265306124,
      "loss": 0.3241,
      "step": 98
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.07138220965862274,
      "learning_rate": 0.00012326530612244898,
      "loss": 0.384,
      "step": 99
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.06404238939285278,
      "learning_rate": 0.00012244897959183676,
      "loss": 0.3985,
      "step": 100
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.3666223883628845,
      "eval_runtime": 221.3854,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 100
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.1057184562087059,
      "learning_rate": 0.00012163265306122449,
      "loss": 0.3715,
      "step": 101
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.0544685460627079,
      "learning_rate": 0.00012081632653061226,
      "loss": 0.3155,
      "step": 102
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.05592862516641617,
      "learning_rate": 0.00012,
      "loss": 0.3334,
      "step": 103
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.09359190613031387,
      "learning_rate": 0.00011918367346938777,
      "loss": 0.4196,
      "step": 104
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.05394788831472397,
      "learning_rate": 0.00011836734693877552,
      "loss": 0.3144,
      "step": 105
    },
    {
      "epoch": 0.42,
      "eval_loss": 0.366384357213974,
      "eval_runtime": 221.4853,
      "eval_samples_per_second": 0.451,
      "eval_steps_per_second": 0.451,
      "step": 105
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.09087646752595901,
      "learning_rate": 0.00011755102040816328,
      "loss": 0.4787,
      "step": 106
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.05062950775027275,
      "learning_rate": 0.00011673469387755102,
      "loss": 0.308,
      "step": 107
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.07067687064409256,
      "learning_rate": 0.00011591836734693877,
      "loss": 0.4516,
      "step": 108
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.0696410983800888,
      "learning_rate": 0.00011510204081632654,
      "loss": 0.4133,
      "step": 109
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.053390417248010635,
      "learning_rate": 0.00011428571428571428,
      "loss": 0.3464,
      "step": 110
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.36625906825065613,
      "eval_runtime": 221.4663,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 110
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.08226601034402847,
      "learning_rate": 0.00011346938775510206,
      "loss": 0.3514,
      "step": 111
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.06263068318367004,
      "learning_rate": 0.0001126530612244898,
      "loss": 0.3304,
      "step": 112
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.07523027062416077,
      "learning_rate": 0.00011183673469387757,
      "loss": 0.412,
      "step": 113
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.06983984261751175,
      "learning_rate": 0.00011102040816326532,
      "loss": 0.3378,
      "step": 114
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.07407167553901672,
      "learning_rate": 0.00011020408163265306,
      "loss": 0.3525,
      "step": 115
    },
    {
      "epoch": 0.46,
      "eval_loss": 0.3658019006252289,
      "eval_runtime": 221.4536,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 115
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.07463245093822479,
      "learning_rate": 0.00010938775510204082,
      "loss": 0.4075,
      "step": 116
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.06296837329864502,
      "learning_rate": 0.00010857142857142856,
      "loss": 0.341,
      "step": 117
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.05122542753815651,
      "learning_rate": 0.00010775510204081634,
      "loss": 0.2931,
      "step": 118
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.05025261640548706,
      "learning_rate": 0.00010693877551020408,
      "loss": 0.2656,
      "step": 119
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.06720995157957077,
      "learning_rate": 0.00010612244897959185,
      "loss": 0.3279,
      "step": 120
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.3656257390975952,
      "eval_runtime": 221.4242,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 120
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.08091939985752106,
      "learning_rate": 0.0001053061224489796,
      "loss": 0.3565,
      "step": 121
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.06272006779909134,
      "learning_rate": 0.00010448979591836735,
      "loss": 0.3084,
      "step": 122
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.06935545802116394,
      "learning_rate": 0.00010367346938775511,
      "loss": 0.3362,
      "step": 123
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.08544974774122238,
      "learning_rate": 0.00010285714285714286,
      "loss": 0.4109,
      "step": 124
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.06851647794246674,
      "learning_rate": 0.00010204081632653062,
      "loss": 0.3611,
      "step": 125
    },
    {
      "epoch": 0.5,
      "eval_loss": 0.36544203758239746,
      "eval_runtime": 221.4614,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 125
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.04124211147427559,
      "learning_rate": 0.00010122448979591836,
      "loss": 0.2543,
      "step": 126
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.07660084962844849,
      "learning_rate": 0.00010040816326530613,
      "loss": 0.3796,
      "step": 127
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.05955967307090759,
      "learning_rate": 9.959183673469388e-05,
      "loss": 0.368,
      "step": 128
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.08128747344017029,
      "learning_rate": 9.877551020408164e-05,
      "loss": 0.4178,
      "step": 129
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.06035596504807472,
      "learning_rate": 9.79591836734694e-05,
      "loss": 0.3803,
      "step": 130
    },
    {
      "epoch": 0.52,
      "eval_loss": 0.36558592319488525,
      "eval_runtime": 221.4103,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 130
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.06825069338083267,
      "learning_rate": 9.714285714285715e-05,
      "loss": 0.354,
      "step": 131
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.06314413249492645,
      "learning_rate": 9.63265306122449e-05,
      "loss": 0.3943,
      "step": 132
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.06548620015382767,
      "learning_rate": 9.551020408163265e-05,
      "loss": 0.3964,
      "step": 133
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.06133970245718956,
      "learning_rate": 9.469387755102041e-05,
      "loss": 0.3445,
      "step": 134
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.0636979192495346,
      "learning_rate": 9.387755102040817e-05,
      "loss": 0.377,
      "step": 135
    },
    {
      "epoch": 0.54,
      "eval_loss": 0.36545470356941223,
      "eval_runtime": 221.4485,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 135
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.08528140187263489,
      "learning_rate": 9.306122448979592e-05,
      "loss": 0.4909,
      "step": 136
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.05702263489365578,
      "learning_rate": 9.224489795918367e-05,
      "loss": 0.378,
      "step": 137
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.06725594401359558,
      "learning_rate": 9.142857142857143e-05,
      "loss": 0.3623,
      "step": 138
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.08139640837907791,
      "learning_rate": 9.061224489795919e-05,
      "loss": 0.3388,
      "step": 139
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.05536980181932449,
      "learning_rate": 8.979591836734695e-05,
      "loss": 0.3929,
      "step": 140
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.3648947477340698,
      "eval_runtime": 221.4068,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 140
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.04724528267979622,
      "learning_rate": 8.89795918367347e-05,
      "loss": 0.2697,
      "step": 141
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.05378962308168411,
      "learning_rate": 8.816326530612245e-05,
      "loss": 0.3722,
      "step": 142
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.055855248123407364,
      "learning_rate": 8.734693877551021e-05,
      "loss": 0.3242,
      "step": 143
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.06716351211071014,
      "learning_rate": 8.653061224489797e-05,
      "loss": 0.369,
      "step": 144
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.06417680531740189,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.4049,
      "step": 145
    },
    {
      "epoch": 0.58,
      "eval_loss": 0.36438244581222534,
      "eval_runtime": 220.5366,
      "eval_samples_per_second": 0.453,
      "eval_steps_per_second": 0.453,
      "step": 145
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.06565595418214798,
      "learning_rate": 8.489795918367347e-05,
      "loss": 0.3478,
      "step": 146
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.07597843557596207,
      "learning_rate": 8.408163265306123e-05,
      "loss": 0.3812,
      "step": 147
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.07547948509454727,
      "learning_rate": 8.326530612244899e-05,
      "loss": 0.3541,
      "step": 148
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.06296708434820175,
      "learning_rate": 8.244897959183675e-05,
      "loss": 0.3533,
      "step": 149
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.049420952796936035,
      "learning_rate": 8.163265306122449e-05,
      "loss": 0.3082,
      "step": 150
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.3643759787082672,
      "eval_runtime": 217.2407,
      "eval_samples_per_second": 0.46,
      "eval_steps_per_second": 0.46,
      "step": 150
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.05963588505983353,
      "learning_rate": 8.081632653061225e-05,
      "loss": 0.3536,
      "step": 151
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.07388174533843994,
      "learning_rate": 8e-05,
      "loss": 0.3326,
      "step": 152
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.05630302056670189,
      "learning_rate": 7.918367346938775e-05,
      "loss": 0.3383,
      "step": 153
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.06663832813501358,
      "learning_rate": 7.836734693877551e-05,
      "loss": 0.369,
      "step": 154
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.05282837897539139,
      "learning_rate": 7.755102040816327e-05,
      "loss": 0.3469,
      "step": 155
    },
    {
      "epoch": 0.62,
      "eval_loss": 0.3641422986984253,
      "eval_runtime": 217.5147,
      "eval_samples_per_second": 0.46,
      "eval_steps_per_second": 0.46,
      "step": 155
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.06857128441333771,
      "learning_rate": 7.673469387755103e-05,
      "loss": 0.3314,
      "step": 156
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.06368589401245117,
      "learning_rate": 7.591836734693878e-05,
      "loss": 0.4058,
      "step": 157
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.051606569439172745,
      "learning_rate": 7.510204081632653e-05,
      "loss": 0.2859,
      "step": 158
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.06053364649415016,
      "learning_rate": 7.428571428571429e-05,
      "loss": 0.3403,
      "step": 159
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.07237730920314789,
      "learning_rate": 7.346938775510205e-05,
      "loss": 0.3601,
      "step": 160
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.3638666272163391,
      "eval_runtime": 217.4545,
      "eval_samples_per_second": 0.46,
      "eval_steps_per_second": 0.46,
      "step": 160
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.07366285473108292,
      "learning_rate": 7.26530612244898e-05,
      "loss": 0.346,
      "step": 161
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.06003782898187637,
      "learning_rate": 7.183673469387755e-05,
      "loss": 0.3654,
      "step": 162
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.0523100346326828,
      "learning_rate": 7.10204081632653e-05,
      "loss": 0.3253,
      "step": 163
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.05836751312017441,
      "learning_rate": 7.020408163265306e-05,
      "loss": 0.3654,
      "step": 164
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.0775202140212059,
      "learning_rate": 6.938775510204082e-05,
      "loss": 0.3394,
      "step": 165
    },
    {
      "epoch": 0.66,
      "eval_loss": 0.3639233410358429,
      "eval_runtime": 220.7069,
      "eval_samples_per_second": 0.453,
      "eval_steps_per_second": 0.453,
      "step": 165
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.08127891272306442,
      "learning_rate": 6.857142857142858e-05,
      "loss": 0.3747,
      "step": 166
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.0613272488117218,
      "learning_rate": 6.775510204081633e-05,
      "loss": 0.3487,
      "step": 167
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.053227152675390244,
      "learning_rate": 6.693877551020408e-05,
      "loss": 0.3171,
      "step": 168
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.048869308084249496,
      "learning_rate": 6.612244897959184e-05,
      "loss": 0.2893,
      "step": 169
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.06694049388170242,
      "learning_rate": 6.530612244897959e-05,
      "loss": 0.3677,
      "step": 170
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.3635450601577759,
      "eval_runtime": 221.3825,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 170
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.07354197651147842,
      "learning_rate": 6.448979591836734e-05,
      "loss": 0.4026,
      "step": 171
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.07165700942277908,
      "learning_rate": 6.36734693877551e-05,
      "loss": 0.3985,
      "step": 172
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.054480407387018204,
      "learning_rate": 6.285714285714286e-05,
      "loss": 0.3488,
      "step": 173
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.05868424475193024,
      "learning_rate": 6.204081632653062e-05,
      "loss": 0.3582,
      "step": 174
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.09531331807374954,
      "learning_rate": 6.122448979591838e-05,
      "loss": 0.4799,
      "step": 175
    },
    {
      "epoch": 0.7,
      "eval_loss": 0.3635633885860443,
      "eval_runtime": 221.3803,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 175
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.055812496691942215,
      "learning_rate": 6.040816326530613e-05,
      "loss": 0.3252,
      "step": 176
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.06182733178138733,
      "learning_rate": 5.959183673469389e-05,
      "loss": 0.3783,
      "step": 177
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.08184486627578735,
      "learning_rate": 5.877551020408164e-05,
      "loss": 0.4415,
      "step": 178
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.04232722148299217,
      "learning_rate": 5.7959183673469384e-05,
      "loss": 0.2701,
      "step": 179
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.06401538103818893,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.3252,
      "step": 180
    },
    {
      "epoch": 0.72,
      "eval_loss": 0.36319419741630554,
      "eval_runtime": 221.4412,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 180
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.0682922750711441,
      "learning_rate": 5.63265306122449e-05,
      "loss": 0.3696,
      "step": 181
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.06043580174446106,
      "learning_rate": 5.551020408163266e-05,
      "loss": 0.3613,
      "step": 182
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.05572928488254547,
      "learning_rate": 5.469387755102041e-05,
      "loss": 0.3089,
      "step": 183
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.07007647305727005,
      "learning_rate": 5.387755102040817e-05,
      "loss": 0.394,
      "step": 184
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.0689103752374649,
      "learning_rate": 5.3061224489795926e-05,
      "loss": 0.3744,
      "step": 185
    },
    {
      "epoch": 0.74,
      "eval_loss": 0.36317962408065796,
      "eval_runtime": 221.0381,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 185
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.05912269651889801,
      "learning_rate": 5.224489795918368e-05,
      "loss": 0.3454,
      "step": 186
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.05867598205804825,
      "learning_rate": 5.142857142857143e-05,
      "loss": 0.3527,
      "step": 187
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.08473389595746994,
      "learning_rate": 5.061224489795918e-05,
      "loss": 0.3827,
      "step": 188
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.058810509741306305,
      "learning_rate": 4.979591836734694e-05,
      "loss": 0.3385,
      "step": 189
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.07443808764219284,
      "learning_rate": 4.89795918367347e-05,
      "loss": 0.3577,
      "step": 190
    },
    {
      "epoch": 0.76,
      "eval_loss": 0.3627238869667053,
      "eval_runtime": 221.3496,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 190
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.08049368113279343,
      "learning_rate": 4.816326530612245e-05,
      "loss": 0.3303,
      "step": 191
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.07354544848203659,
      "learning_rate": 4.7346938775510206e-05,
      "loss": 0.2981,
      "step": 192
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.06093299761414528,
      "learning_rate": 4.653061224489796e-05,
      "loss": 0.4019,
      "step": 193
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.057304296642541885,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.2731,
      "step": 194
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.04999762028455734,
      "learning_rate": 4.4897959183673474e-05,
      "loss": 0.315,
      "step": 195
    },
    {
      "epoch": 0.78,
      "eval_loss": 0.3626254200935364,
      "eval_runtime": 221.4364,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 195
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.07331797480583191,
      "learning_rate": 4.4081632653061226e-05,
      "loss": 0.3914,
      "step": 196
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.062230899930000305,
      "learning_rate": 4.3265306122448984e-05,
      "loss": 0.4186,
      "step": 197
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.06784031540155411,
      "learning_rate": 4.2448979591836735e-05,
      "loss": 0.3707,
      "step": 198
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.05810564011335373,
      "learning_rate": 4.1632653061224494e-05,
      "loss": 0.3291,
      "step": 199
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.06077291816473007,
      "learning_rate": 4.0816326530612245e-05,
      "loss": 0.3042,
      "step": 200
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.3622746169567108,
      "eval_runtime": 221.4265,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 200
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.051190800964832306,
      "learning_rate": 4e-05,
      "loss": 0.3645,
      "step": 201
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.05804872512817383,
      "learning_rate": 3.9183673469387755e-05,
      "loss": 0.3092,
      "step": 202
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.0780886858701706,
      "learning_rate": 3.836734693877551e-05,
      "loss": 0.3649,
      "step": 203
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.057529669255018234,
      "learning_rate": 3.7551020408163264e-05,
      "loss": 0.3744,
      "step": 204
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.06590468436479568,
      "learning_rate": 3.673469387755102e-05,
      "loss": 0.4036,
      "step": 205
    },
    {
      "epoch": 0.82,
      "eval_loss": 0.36224183440208435,
      "eval_runtime": 221.4331,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 205
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.04177497327327728,
      "learning_rate": 3.5918367346938774e-05,
      "loss": 0.3019,
      "step": 206
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.05943281576037407,
      "learning_rate": 3.510204081632653e-05,
      "loss": 0.3463,
      "step": 207
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.07182443141937256,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.3599,
      "step": 208
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.06409759819507599,
      "learning_rate": 3.346938775510204e-05,
      "loss": 0.34,
      "step": 209
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.059677280485630035,
      "learning_rate": 3.265306122448979e-05,
      "loss": 0.396,
      "step": 210
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.3620786666870117,
      "eval_runtime": 221.0345,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 210
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.06136467307806015,
      "learning_rate": 3.183673469387755e-05,
      "loss": 0.3631,
      "step": 211
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.05549037456512451,
      "learning_rate": 3.102040816326531e-05,
      "loss": 0.3323,
      "step": 212
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.04336882010102272,
      "learning_rate": 3.0204081632653065e-05,
      "loss": 0.3343,
      "step": 213
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.06445617973804474,
      "learning_rate": 2.938775510204082e-05,
      "loss": 0.3159,
      "step": 214
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.04863291233778,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.3633,
      "step": 215
    },
    {
      "epoch": 0.86,
      "eval_loss": 0.3621441125869751,
      "eval_runtime": 221.4564,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 215
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.06465921550989151,
      "learning_rate": 2.775510204081633e-05,
      "loss": 0.4117,
      "step": 216
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.05837178975343704,
      "learning_rate": 2.6938775510204084e-05,
      "loss": 0.4145,
      "step": 217
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.0795375183224678,
      "learning_rate": 2.612244897959184e-05,
      "loss": 0.4268,
      "step": 218
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.05397724732756615,
      "learning_rate": 2.530612244897959e-05,
      "loss": 0.3746,
      "step": 219
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.06564278900623322,
      "learning_rate": 2.448979591836735e-05,
      "loss": 0.3943,
      "step": 220
    },
    {
      "epoch": 0.88,
      "eval_loss": 0.3620915114879608,
      "eval_runtime": 221.419,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 220
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.06899286061525345,
      "learning_rate": 2.3673469387755103e-05,
      "loss": 0.3572,
      "step": 221
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.06487555801868439,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 0.3416,
      "step": 222
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.06315423548221588,
      "learning_rate": 2.2040816326530613e-05,
      "loss": 0.3511,
      "step": 223
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.06545478105545044,
      "learning_rate": 2.1224489795918368e-05,
      "loss": 0.4005,
      "step": 224
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.07035166770219803,
      "learning_rate": 2.0408163265306123e-05,
      "loss": 0.3864,
      "step": 225
    },
    {
      "epoch": 0.9,
      "eval_loss": 0.36189812421798706,
      "eval_runtime": 221.4,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 225
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.07046246528625488,
      "learning_rate": 1.9591836734693877e-05,
      "loss": 0.3926,
      "step": 226
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.06815803050994873,
      "learning_rate": 1.8775510204081632e-05,
      "loss": 0.3639,
      "step": 227
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.05429049953818321,
      "learning_rate": 1.7959183673469387e-05,
      "loss": 0.3613,
      "step": 228
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.05402430146932602,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.3235,
      "step": 229
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.07079155743122101,
      "learning_rate": 1.6326530612244897e-05,
      "loss": 0.3809,
      "step": 230
    },
    {
      "epoch": 0.92,
      "eval_loss": 0.36174288392066956,
      "eval_runtime": 221.3089,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 230
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.06275846064090729,
      "learning_rate": 1.5510204081632655e-05,
      "loss": 0.3908,
      "step": 231
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.06898892670869827,
      "learning_rate": 1.469387755102041e-05,
      "loss": 0.4169,
      "step": 232
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.05501594766974449,
      "learning_rate": 1.3877551020408165e-05,
      "loss": 0.3578,
      "step": 233
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.05152585729956627,
      "learning_rate": 1.306122448979592e-05,
      "loss": 0.3371,
      "step": 234
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.060899753123521805,
      "learning_rate": 1.2244897959183674e-05,
      "loss": 0.3448,
      "step": 235
    },
    {
      "epoch": 0.94,
      "eval_loss": 0.36165592074394226,
      "eval_runtime": 221.4027,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 235
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.06585948169231415,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.4142,
      "step": 236
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.057177621871232986,
      "learning_rate": 1.0612244897959184e-05,
      "loss": 0.3364,
      "step": 237
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.061099156737327576,
      "learning_rate": 9.795918367346939e-06,
      "loss": 0.3794,
      "step": 238
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.06911502778530121,
      "learning_rate": 8.979591836734694e-06,
      "loss": 0.3801,
      "step": 239
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.05213127285242081,
      "learning_rate": 8.163265306122448e-06,
      "loss": 0.2864,
      "step": 240
    },
    {
      "epoch": 0.96,
      "eval_loss": 0.3615199327468872,
      "eval_runtime": 221.3502,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 240
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.07209393382072449,
      "learning_rate": 7.346938775510205e-06,
      "loss": 0.3633,
      "step": 241
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.08473736047744751,
      "learning_rate": 6.53061224489796e-06,
      "loss": 0.3464,
      "step": 242
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.05651533976197243,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.3283,
      "step": 243
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.05367613956332207,
      "learning_rate": 4.897959183673469e-06,
      "loss": 0.358,
      "step": 244
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.05510541424155235,
      "learning_rate": 4.081632653061224e-06,
      "loss": 0.3326,
      "step": 245
    },
    {
      "epoch": 0.98,
      "eval_loss": 0.3615178167819977,
      "eval_runtime": 221.412,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 245
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.037076178938150406,
      "learning_rate": 3.26530612244898e-06,
      "loss": 0.272,
      "step": 246
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.08399928361177444,
      "learning_rate": 2.4489795918367347e-06,
      "loss": 0.4442,
      "step": 247
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.06734912097454071,
      "learning_rate": 1.63265306122449e-06,
      "loss": 0.3486,
      "step": 248
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.053673893213272095,
      "learning_rate": 8.16326530612245e-07,
      "loss": 0.3889,
      "step": 249
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.06118576228618622,
      "learning_rate": 0.0,
      "loss": 0.3734,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.3614474833011627,
      "eval_runtime": 221.2762,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 250
    }
  ],
  "logging_steps": 1,
  "max_steps": 250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.5678749306106675e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
